
<!doctype html>
<html class="">
	 <head>

		<meta charset="utf-8" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />

		<meta name="description" content="We’re on a journey to advance and democratize artificial intelligence through open source and open science." />

		<meta property="fb:app_id" content="1321688464574422" />

		<meta name="twitter:card" content="summary_large_image" />

		<meta name="twitter:site" content="@huggingface" />

		<meta name="twitter:image" content="https://huggingface.co/blog/assets/ocr-open-models/thumbnail.png" />

		<meta property="og:title" content="Supercharge your OCR Pipelines with Open Models" />

		<meta property="og:type" content="website" />

		<meta property="og:url" content="https://huggingface.co/blog/ocr-open-models" />

		<meta property="og:image" content="https://huggingface.co/blog/assets/ocr-open-models/thumbnail.png" />

		<link rel="stylesheet" href="/front/build/kube-aaf1f7b/style.css" />

		<link rel="preconnect" href="https://fonts.gstatic.com" />

		<link
			href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;1,200;1,300;1,400;1,600;1,700&display=swap"
			rel="stylesheet"
		/>

		<link
			href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&display=swap"
			rel="stylesheet"
		/>

		<link
			rel="preload"
			href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"
			as="style"
			onload="this.onload=null;this.rel='stylesheet'"
		/>

		<noscript
			> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" /> </noscript
		>
		 <script>const guestTheme = document.cookie.match(/theme=(\w+)/)?.[1]; document.documentElement.classList.toggle('dark', guestTheme === 'dark' || ( (!guestTheme || guestTheme === 'system') && window.matchMedia('(prefers-color-scheme: dark)').matches));</script>
<link rel="canonical" href="https://huggingface.co/blog/ocr-open-models">  <!-- HEAD_svelte-vwinwk_START --><link rel="alternate" type="application/rss+xml" href="/blog/feed.xml" title="Hugging Face Blog"><!-- HEAD_svelte-vwinwk_END -->
		<title>Supercharge your OCR Pipelines with Open Models</title>

		<script defer src="/js/script.js"></script>

		<script>
			((window.plausible =
				window.plausible ||
				function () {
					(plausible.q = plausible.q || []).push(arguments);
				}),
				(plausible.init =
					plausible.init ||
					function (i) {
						plausible.o = i || {};
					}));
			plausible.init({
				customProperties: {
					loggedIn: "false",
				},
				endpoint: "/api/event",
			});
		</script>

		<script>
			 window.hubConfig = {"features":{"signupDisabled":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https:\/\/huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","datasetViewerPublicUrl":"https:\/\/datasets-server.huggingface.co","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)","spacesIframeDomain":"hf.space","spacesApiUrl":"https:\/\/api.hf.space","docSearchKey":"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6","logoDev":{"apiUrl":"https:\/\/img.logo.dev\/","apiKey":"pk_UHS2HZOeRnaSOdDp7jbd5w"}};
		</script>
		 <script type="text/javascript" src="https://de5282c3ca0c.edge.sdk.awswaf.com/de5282c3ca0c/526cf06acb0d/challenge.js" defer></script>  </head
	>
	<body class="flex flex-col min-h-dvh bg-white dark:bg-gray-950 text-black BlogPage">
		 

<div class="flex min-h-dvh flex-col"><div class="SVELTE_HYDRATER contents" data-target="SystemThemeMonitor" data-props="{&quot;isLoggedIn&quot;:false}"></div>

	<div class="SVELTE_HYDRATER contents" data-target="MainHeader" data-props="{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:false,&quot;isZh&quot;:false,&quot;isPro&quot;:false}"><header class="border-b border-gray-100 "><div class="w-full px-4 container flex h-16 items-center"><div class="flex flex-1 items-center"><a class="mr-5 flex flex-none items-center lg:mr-6" href="/"><img alt="Hugging Face's logo" class="w-7 md:mr-2" src="/front/assets/huggingface_logo-noborder.svg">
				<span class="hidden whitespace-nowrap text-lg font-bold md:block">Hugging Face</span></a>
			<div class="relative flex-1 lg:max-w-sm mr-2 sm:mr-4 md:mr-3 xl:mr-6"><input autocomplete="off" class="w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl " name="" placeholder="Search models, datasets, users..."   spellcheck="false" type="text" value="">
	<svg class="absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
	</div>
			<div class="flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden"><button class="relative z-40 flex h-6 w-8 items-center justify-center" type="button"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-xl" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg>
		</button>

	</div></div>
		<nav aria-label="Main" class="ml-auto hidden lg:block"><ul class="flex items-center gap-x-1 2xl:gap-x-2"><li class="hover:text-indigo-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/models"><svg class="mr-1.5 text-gray-400 group-hover:text-indigo-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
						Models</a>
				</li><li class="hover:text-red-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/datasets"><svg class="mr-1.5 text-gray-400 group-hover:text-red-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
						Datasets</a>
				</li><li class="hover:text-blue-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/spaces"><svg class="mr-1.5 text-gray-400 group-hover:text-blue-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 25 25"><path opacity=".5" d="M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z" fill="currentColor"></path><path opacity=".75" fill-rule="evenodd" clip-rule="evenodd" d="M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z" fill="currentColor"></path><path opacity=".25" d="M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z" fill="currentColor"></path></svg>
						Spaces</a>
				</li><li class="max-xl:hidden relative"><div class="relative ">
	<button class="group flex items-center px-2 py-0.5 dark:text-gray-300 hover:text-yellow-700 dark:hover:text-gray-100 " type="button">
		<svg class="mr-1.5 mr-1.5 text-gray-400 text-yellow-500! group-hover:text-yellow-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M20.6081 3C21.7684 3 22.8053 3.49196 23.5284 4.38415C23.9756 4.93678 24.4428 5.82749 24.4808 7.16133C24.9674 7.01707 25.4353 6.93643 25.8725 6.93643C26.9833 6.93643 27.9865 7.37587 28.696 8.17411C29.6075 9.19872 30.0124 10.4579 29.8361 11.7177C29.7523 12.3177 29.5581 12.8555 29.2678 13.3534C29.8798 13.8646 30.3306 14.5763 30.5485 15.4322C30.719 16.1032 30.8939 17.5006 29.9808 18.9403C30.0389 19.0342 30.0934 19.1319 30.1442 19.2318C30.6932 20.3074 30.7283 21.5229 30.2439 22.6548C29.5093 24.3704 27.6841 25.7219 24.1397 27.1727C21.9347 28.0753 19.9174 28.6523 19.8994 28.6575C16.9842 29.4379 14.3477 29.8345 12.0653 29.8345C7.87017 29.8345 4.8668 28.508 3.13831 25.8921C0.356375 21.6797 0.754104 17.8269 4.35369 14.1131C6.34591 12.058 7.67023 9.02782 7.94613 8.36275C8.50224 6.39343 9.97271 4.20438 12.4172 4.20438H12.4179C12.6236 4.20438 12.8314 4.2214 13.0364 4.25468C14.107 4.42854 15.0428 5.06476 15.7115 6.02205C16.4331 5.09583 17.134 4.359 17.7682 3.94323C18.7242 3.31737 19.6794 3 20.6081 3ZM20.6081 5.95917C20.2427 5.95917 19.7963 6.1197 19.3039 6.44225C17.7754 7.44319 14.8258 12.6772 13.7458 14.7131C13.3839 15.3952 12.7655 15.6837 12.2086 15.6837C11.1036 15.6837 10.2408 14.5497 12.1076 13.1085C14.9146 10.9402 13.9299 7.39584 12.5898 7.1776C12.5311 7.16799 12.4731 7.16355 12.4172 7.16355C11.1989 7.16355 10.6615 9.33114 10.6615 9.33114C10.6615 9.33114 9.0863 13.4148 6.38031 16.206C3.67434 18.998 3.5346 21.2388 5.50675 24.2246C6.85185 26.2606 9.42666 26.8753 12.0653 26.8753C14.8021 26.8753 17.6077 26.2139 19.1799 25.793C19.2574 25.7723 28.8193 22.984 27.6081 20.6107C27.4046 20.212 27.0693 20.0522 26.6471 20.0522C24.9416 20.0522 21.8393 22.6726 20.5057 22.6726C20.2076 22.6726 19.9976 22.5416 19.9116 22.222C19.3433 20.1173 28.552 19.2325 27.7758 16.1839C27.639 15.6445 27.2677 15.4256 26.746 15.4263C24.4923 15.4263 19.4358 19.5181 18.3759 19.5181C18.2949 19.5181 18.2368 19.4937 18.2053 19.4419C17.6743 18.557 17.9653 17.9394 21.7082 15.6009C25.4511 13.2617 28.0783 11.8545 26.5841 10.1752C26.4121 9.98141 26.1684 9.8956 25.8725 9.8956C23.6001 9.89634 18.2311 14.9403 18.2311 14.9403C18.2311 14.9403 16.7821 16.496 15.9057 16.496C15.7043 16.496 15.533 16.4139 15.4169 16.2112C14.7956 15.1296 21.1879 10.1286 21.5484 8.06535C21.7928 6.66715 21.3771 5.95917 20.6081 5.95917Z" fill="#FF9D00"></path><path d="M5.50686 24.2246C3.53472 21.2387 3.67446 18.9979 6.38043 16.206C9.08641 13.4147 10.6615 9.33111 10.6615 9.33111C10.6615 9.33111 11.2499 6.95933 12.59 7.17757C13.93 7.39581 14.9139 10.9401 12.1069 13.1084C9.29997 15.276 12.6659 16.7489 13.7459 14.713C14.8258 12.6772 17.7747 7.44316 19.304 6.44221C20.8326 5.44128 21.9089 6.00204 21.5484 8.06532C21.188 10.1286 14.795 15.1295 15.4171 16.2118C16.0391 17.2934 18.2312 14.9402 18.2312 14.9402C18.2312 14.9402 25.0907 8.49588 26.5842 10.1752C28.0776 11.8545 25.4512 13.2616 21.7082 15.6008C17.9646 17.9393 17.6744 18.557 18.2054 19.4418C18.7372 20.3266 26.9998 13.1351 27.7759 16.1838C28.5513 19.2324 19.3434 20.1173 19.9117 22.2219C20.48 24.3274 26.3979 18.2382 27.6082 20.6107C28.8193 22.9839 19.2574 25.7722 19.18 25.7929C16.0914 26.62 8.24723 28.3726 5.50686 24.2246Z" fill="#FFD21E"></path></svg>
			Community
		</button>
	
	
	</div>
				</li><li class="hover:text-yellow-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/docs"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="mr-1.5 text-gray-400 group-hover:text-yellow-500" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 16 16"><path d="m2.28 3.7-.3.16a.67.67 0 0 0-.34.58v8.73l.01.04.02.07.01.04.03.06.02.04.02.03.04.06.05.05.04.04.06.04.06.04.08.04.08.02h.05l.07.02h.11l.04-.01.07-.02.03-.01.07-.03.22-.12a5.33 5.33 0 0 1 5.15.1.67.67 0 0 0 .66 0 5.33 5.33 0 0 1 5.33 0 .67.67 0 0 0 1-.58V4.36a.67.67 0 0 0-.34-.5l-.3-.17v7.78a.63.63 0 0 1-.87.59 4.9 4.9 0 0 0-4.35.35l-.65.39a.29.29 0 0 1-.15.04.29.29 0 0 1-.16-.04l-.65-.4a4.9 4.9 0 0 0-4.34-.34.63.63 0 0 1-.87-.59V3.7Z" fill="currentColor" class="dark:opacity-40"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M8 3.1a5.99 5.99 0 0 0-5.3-.43.66.66 0 0 0-.42.62v8.18c0 .45.46.76.87.59a4.9 4.9 0 0 1 4.34.35l.65.39c.05.03.1.04.16.04.05 0 .1-.01.15-.04l.65-.4a4.9 4.9 0 0 1 4.35-.34.63.63 0 0 0 .86-.59V3.3a.67.67 0 0 0-.41-.62 5.99 5.99 0 0 0-5.3.43l-.3.17L8 3.1Zm.73 1.87a.43.43 0 1 0-.86 0v5.48a.43.43 0 0 0 .86 0V4.97Z" fill="currentColor" class="opacity-40 dark:opacity-100"></path><path d="M8.73 4.97a.43.43 0 1 0-.86 0v5.48a.43.43 0 1 0 .86 0V4.96Z" fill="currentColor" class="dark:opacity-40"></path></svg>
						Docs</a>
				</li><li class="hover:text-black dark:hover:text-white max-2xl:hidden"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/enterprise"><svg class="mr-1.5 text-gray-400 group-hover:text-black dark:group-hover:text-white" xmlns="http://www.w3.org/2000/svg" fill="none" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.9 1.35a3.16 3.16 0 0 0-2.8 2.07L.37 8.58C0 9.71.7 10.65 1.86 10.65H7.3a3.2 3.2 0 0 0 2.84-2.07l1.67-5.16c.36-1.13-.3-2.07-1.46-2.07H4.91Zm.4 2.07L3.57 8.47h3.57l.36-1.12H5.4l.28-.91h1.75l.4-1.1H6.07l.3-.83h2l.36-1.1H5.27h.04Z" fill="currentColor"></path></svg>
						Enterprise</a>
				</li>

		<li><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/pricing">Pricing
			</a></li>

		<li><div class="relative group">
	<button class="px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center " type="button">
		<svg class=" text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-100" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 18" preserveAspectRatio="xMidYMid meet"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z" fill="currentColor"></path></svg>
			
		</button>
	
	
	</div></li>
		<li><hr class="h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800"></li>
		<li><a class="block cursor-pointer whitespace-nowrap px-2 py-0.5 hover:text-gray-500 dark:text-gray-300 dark:hover:text-gray-100" href="/login">Log In
				</a></li>
			<li><a class="whitespace-nowrap rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black" href="/join">Sign Up
					</a></li></ul></nav></div></header></div>
	
	
	
	<div class="SVELTE_HYDRATER contents" data-target="SSOBanner" data-props="{}"></div>
	

	<main class="flex flex-1 flex-col"><div class="container relative flex flex-row justify-center gap-4"><div class="max-w-full pb-16 pt-6 lg:max-w-3xl lg:flex-1 lg:pt-16 2xl:max-w-4xl"><div class="max-lg:overflow-hidden"><div class="blog-content copiable-code-container [&_h1]:mr-0! prose mx-auto mb-8 lg:prose-lg 2xl:prose-lg prose-h1:mb-3 lg:px-8"><div class="SVELTE_HYDRATER contents" data-target="RepoCodeCopy" data-props="{}"><div></div></div>
					<div class="mb-4"><a href="/blog" class="text-gray-500! no-underline! hover:underline! flex items-center font-sans"><svg class="mr-2 h-3 w-3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M14 26l1.41-1.41L7.83 17H28v-2H7.83l7.58-7.59L14 6L4 16l10 10z" fill="currentColor"></path></svg>
							Back to Articles</a></div>

					<h1 class="group relative flex items-center"><!-- HTML_TAG_START -->
	<a 
		id="supercharge-your-ocr-pipelines-with-open-models" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#supercharge-your-ocr-pipelines-with-open-models"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Supercharge your OCR Pipelines with Open Models
	</span>
<!-- HTML_TAG_END --></h1>
					<div><div class="mb-6 flex items-center gap-x-4 text-base">
		<span class="text-sm sm:text-base">Published
				October 21, 2025</span></div>
	<a target="_blank" class="btn mb-5 font-sans text-sm no-underline" href="https://github.com/huggingface/blog/blob/main/ocr-open-models.md">Update on GitHub</a></div>
					<div class="not-prose mb-6 lg:hidden"><div class="SVELTE_HYDRATER contents" data-target="UpvoteControl" data-props="{&quot;maxShown&quot;:6,&quot;apiUrlPrefix&quot;:&quot;/api/blog/ocr-open-models&quot;,&quot;postLoginRedirectUrl&quot;:&quot;/blog/ocr-open-models&quot;,&quot;size&quot;:&quot;sm&quot;,&quot;style&quot;:&quot;horizontal&quot;,&quot;color&quot;:&quot;gray&quot;,&quot;upvotedColor&quot;:&quot;orange&quot;,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;_id&quot;:&quot;5df82bcada6d0311fd3d5402&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1589104979708-5df82bcada6d0311fd3d5402.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Chuanming Liu&quot;,&quot;user&quot;:&quot;Chuanming&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5e4318d616b09a31220980d6&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;Manuel Romero&quot;,&quot;user&quot;:&quot;mrm8488&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5e6a3d4ea9afd5125d9ec064&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1584020801691-noauth.jpeg&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;Stefan Schweter&quot;,&quot;user&quot;:&quot;stefan-it&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5ee3a7cd2a3eae3cbdad1305&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1594144055859-5ee3a7cd2a3eae3cbdad1305.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Yacine Jernite&quot;,&quot;user&quot;:&quot;yjernite&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f106ce5348d4c7346cd19ab&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f106ce5348d4c7346cd19ab/Uu08yZZlFuj3dtG4wld3n.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Abdullah Abdelrhim&quot;,&quot;user&quot;:&quot;abdullah&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f1ba750cb8f993fa01f4678&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f1ba750cb8f993fa01f4678/4-dAcvedO-tIxYJm6aLTL.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Behrooz Azarkhalili&quot;,&quot;user&quot;:&quot;ermiaazarkhalili&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f3cfe71a4dd343b63a63130&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f3cfe71a4dd343b63a63130/eNIOy863HpZfj2OZf9mUB.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Ahmed Khalil Boulahia&quot;,&quot;user&quot;:&quot;AhmedBou&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f4066e079c1ba4c353d0c75&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1654555959564-5f4066e079c1ba4c353d0c75.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Snehal&quot;,&quot;user&quot;:&quot;spate141&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f43448a79c1ba4c353d0d8f&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f43448a79c1ba4c353d0d8f/DiSygV3dn7A_OjmGVTrHD.jpeg&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;Sugato Ray&quot;,&quot;user&quot;:&quot;sugatoray&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f82373af0801648bf88447d&quot;,&quot;avatarUrl&quot;:&quot;/avatars/01c93f7de113cdb34ef3e7012c915ade.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Eugene Girtcius&quot;,&quot;user&quot;:&quot;girtcius&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f93087acf95e81b6854e184&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1645260898596-5f93087acf95e81b6854e184.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Sławomir Dadas&quot;,&quot;user&quot;:&quot;sdadas&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f97802bcf95e81b6854e335&quot;,&quot;avatarUrl&quot;:&quot;/avatars/f902e784de4f8ae1f5742292baf6fc65.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Daryl Maeda&quot;,&quot;user&quot;:&quot;djmaeda&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;upvotes&quot;:212}"><div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"><a href="/login?next=%2Fblog%2Focr-open-models" class="self-start">
	<div class="shadow-alternate group flex h-9 cursor-pointer select-none items-center gap-2 rounded-lg border pl-3 pr-3.5 border-gray-300 bg-white dark:bg-gray-850 "><input disabled type="checkbox"  class="peer hidden">
		<svg class="text-xs text-gray-500 peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg>
		Upvote

		<div class="font-semibold text-orange-500">212</div></div>

</a>
	<ul class="flex items-center  flex-row  text-base   "><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="Chuanming" style="content-visibility:auto;"><a href="/Chuanming" title="Chuanming"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1589104979708-5df82bcada6d0311fd3d5402.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="mrm8488" style="content-visibility:auto;"><a href="/mrm8488" title="mrm8488"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="stefan-it" style="content-visibility:auto;"><a href="/stefan-it" title="stefan-it"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1584020801691-noauth.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="yjernite" style="content-visibility:auto;"><a href="/yjernite" title="yjernite"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1594144055859-5ee3a7cd2a3eae3cbdad1305.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="abdullah" style="content-visibility:auto;"><a href="/abdullah" title="abdullah"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5f106ce5348d4c7346cd19ab/Uu08yZZlFuj3dtG4wld3n.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="ermiaazarkhalili" style="content-visibility:auto;"><a href="/ermiaazarkhalili" title="ermiaazarkhalili"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5f1ba750cb8f993fa01f4678/4-dAcvedO-tIxYJm6aLTL.jpeg" loading="lazy">
					</a>
			</li>

		<li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"><button class="btn bg-linear-to-br -ml-3 translate-x-px rounded-full border-2 border-white px-1.5 py-0.5 text-xs">+206</button></li></ul></div>



</div></div>
					<div class="not-prose"><div class="SVELTE_HYDRATER contents" data-target="BlogAuthorsByline" data-props="{&quot;authors&quot;:[{&quot;author&quot;:{&quot;_id&quot;:&quot;6141a88b3a0ec78603c9e784&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg&quot;,&quot;fullname&quot;:&quot;merve&quot;,&quot;name&quot;:&quot;merve&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:9147}},{&quot;author&quot;:{&quot;_id&quot;:&quot;608aabf24955d2bfc3cd99c6&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/608aabf24955d2bfc3cd99c6/T762Ut0Y-w0sZB2ynvfbJ.jpeg&quot;,&quot;fullname&quot;:&quot;Aritra Roy Gosthipaty&quot;,&quot;name&quot;:&quot;ariG23498&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:425}},{&quot;author&quot;:{&quot;_id&quot;:&quot;60107b385ac3e86b3ea4fc34&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg&quot;,&quot;fullname&quot;:&quot;Daniel van Strien&quot;,&quot;name&quot;:&quot;davanstrien&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:751}},{&quot;author&quot;:{&quot;_id&quot;:&quot;626ede24d2fa9e7d598c8709&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/626ede24d2fa9e7d598c8709/JKS8-Y2Jw87EgNQZBRswq.jpeg&quot;,&quot;fullname&quot;:&quot;Hynek Kydlicek&quot;,&quot;name&quot;:&quot;hynky&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:149}},{&quot;author&quot;:{&quot;_id&quot;:&quot;65d66b494bbd0d92b641cdbb&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg&quot;,&quot;fullname&quot;:&quot;Andres Marafioti&quot;,&quot;name&quot;:&quot;andito&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:452}},{&quot;author&quot;:{&quot;_id&quot;:&quot;61b85ce86eb1f2c5e6233736&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg&quot;,&quot;fullname&quot;:&quot;Vaibhav Srivastav&quot;,&quot;name&quot;:&quot;reach-vb&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1766}},{&quot;author&quot;:{&quot;_id&quot;:&quot;603d25b75f9d390ab190b777&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg&quot;,&quot;fullname&quot;:&quot;Pedro Cuenca&quot;,&quot;name&quot;:&quot;pcuenq&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1391}}],&quot;translators&quot;:[],&quot;proofreaders&quot;:[],&quot;lang&quot;:&quot;en&quot;}"><div class="not-prose"><div class="mb-12 flex flex-wrap items-center gap-x-5 gap-y-3.5"><div class="flex items-center font-sans leading-tight">

<span class="inline-block "><span class="contents"><a href="/merve"><img class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" alt="merve's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg"></a>
				</span>
	</span>

				<div class="text-gray-900 dark:text-gray-300"><a href="/merve"><span class="fullname font-sans font-semibold max-sm:text-sm">merve</span>
						<div class="my-0.5 flex items-center gap-x-2">

<span class="inline-block "><span class="contents"><span class="leading-tight! block font-mono text-xs underline">merve</span>
							</span>
	</span>
							
							
							
							<div><div class="relative flex items-center gap-1.5  "><button class="flex items-center justify-center rounded-full border-[1.5px] transition-colors duration-200   w-18 h-[20px] text-xs  border-transparent bg-black text-white dark:bg-white dark:text-black" type="button" >
	<div class="flex h-full flex-1 items-center justify-center rounded-full">Follow</div></button>

		</div></div>
						</div></a>
					<div class="flex items-center pt-0.5">
					</div></div>
			</div><div class="flex items-center font-sans leading-tight">

<span class="inline-block "><span class="contents"><a href="/ariG23498"><img class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" alt="Aritra Roy Gosthipaty's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/608aabf24955d2bfc3cd99c6/T762Ut0Y-w0sZB2ynvfbJ.jpeg"></a>
				</span>
	</span>

				<div class="text-gray-900 dark:text-gray-300"><a href="/ariG23498"><span class="fullname font-sans font-semibold max-sm:text-sm">Aritra Roy Gosthipaty</span>
						<div class="my-0.5 flex items-center gap-x-2">

<span class="inline-block "><span class="contents"><span class="leading-tight! block font-mono text-xs underline">ariG23498</span>
							</span>
	</span>
							
							
							
							<div><div class="relative flex items-center gap-1.5  "><button class="flex items-center justify-center rounded-full border-[1.5px] transition-colors duration-200   w-18 h-[20px] text-xs  border-transparent bg-black text-white dark:bg-white dark:text-black" type="button" >
	<div class="flex h-full flex-1 items-center justify-center rounded-full">Follow</div></button>

		</div></div>
						</div></a>
					<div class="flex items-center pt-0.5">
					</div></div>
			</div><div class="flex items-center font-sans leading-tight">

<span class="inline-block "><span class="contents"><a href="/davanstrien"><img class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" alt="Daniel van Strien's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg"></a>
				</span>
	</span>

				<div class="text-gray-900 dark:text-gray-300"><a href="/davanstrien"><span class="fullname font-sans font-semibold max-sm:text-sm">Daniel van Strien</span>
						<div class="my-0.5 flex items-center gap-x-2">

<span class="inline-block "><span class="contents"><span class="leading-tight! block font-mono text-xs underline">davanstrien</span>
							</span>
	</span>
							
							
							
							<div><div class="relative flex items-center gap-1.5  "><button class="flex items-center justify-center rounded-full border-[1.5px] transition-colors duration-200   w-18 h-[20px] text-xs  border-transparent bg-black text-white dark:bg-white dark:text-black" type="button" >
	<div class="flex h-full flex-1 items-center justify-center rounded-full">Follow</div></button>

		</div></div>
						</div></a>
					<div class="flex items-center pt-0.5">
					</div></div>
			</div><div class="flex items-center font-sans leading-tight">

<span class="inline-block "><span class="contents"><a href="/hynky"><img class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" alt="Hynek Kydlicek's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/626ede24d2fa9e7d598c8709/JKS8-Y2Jw87EgNQZBRswq.jpeg"></a>
				</span>
	</span>

				<div class="text-gray-900 dark:text-gray-300"><a href="/hynky"><span class="fullname font-sans font-semibold max-sm:text-sm">Hynek Kydlicek</span>
						<div class="my-0.5 flex items-center gap-x-2">

<span class="inline-block "><span class="contents"><span class="leading-tight! block font-mono text-xs underline">hynky</span>
							</span>
	</span>
							
							
							
							<div><div class="relative flex items-center gap-1.5  "><button class="flex items-center justify-center rounded-full border-[1.5px] transition-colors duration-200   w-18 h-[20px] text-xs  border-transparent bg-black text-white dark:bg-white dark:text-black" type="button" >
	<div class="flex h-full flex-1 items-center justify-center rounded-full">Follow</div></button>

		</div></div>
						</div></a>
					<div class="flex items-center pt-0.5">
					</div></div>
			</div><div class="flex items-center font-sans leading-tight">

<span class="inline-block "><span class="contents"><a href="/andito"><img class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" alt="Andres Marafioti's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg"></a>
				</span>
	</span>

				<div class="text-gray-900 dark:text-gray-300"><a href="/andito"><span class="fullname font-sans font-semibold max-sm:text-sm">Andres Marafioti</span>
						<div class="my-0.5 flex items-center gap-x-2">

<span class="inline-block "><span class="contents"><span class="leading-tight! block font-mono text-xs underline">andito</span>
							</span>
	</span>
							
							
							
							<div><div class="relative flex items-center gap-1.5  "><button class="flex items-center justify-center rounded-full border-[1.5px] transition-colors duration-200   w-18 h-[20px] text-xs  border-transparent bg-black text-white dark:bg-white dark:text-black" type="button" >
	<div class="flex h-full flex-1 items-center justify-center rounded-full">Follow</div></button>

		</div></div>
						</div></a>
					<div class="flex items-center pt-0.5">
					</div></div>
			</div><div class="flex items-center font-sans leading-tight">

<span class="inline-block "><span class="contents"><a href="/reach-vb"><img class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" alt="Vaibhav Srivastav's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg"></a>
				</span>
	</span>

				<div class="text-gray-900 dark:text-gray-300"><a href="/reach-vb"><span class="fullname font-sans font-semibold max-sm:text-sm">Vaibhav Srivastav</span>
						<div class="my-0.5 flex items-center gap-x-2">

<span class="inline-block "><span class="contents"><span class="leading-tight! block font-mono text-xs underline">reach-vb</span>
							</span>
	</span>
							
							
							
							<div><div class="relative flex items-center gap-1.5  "><button class="flex items-center justify-center rounded-full border-[1.5px] transition-colors duration-200   w-18 h-[20px] text-xs  border-transparent bg-black text-white dark:bg-white dark:text-black" type="button" >
	<div class="flex h-full flex-1 items-center justify-center rounded-full">Follow</div></button>

		</div></div>
						</div></a>
					<div class="flex items-center pt-0.5">
					</div></div>
			</div><div class="flex items-center font-sans leading-tight">

<span class="inline-block "><span class="contents"><a href="/pcuenq"><img class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" alt="Pedro Cuenca's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg"></a>
				</span>
	</span>

				<div class="text-gray-900 dark:text-gray-300"><a href="/pcuenq"><span class="fullname font-sans font-semibold max-sm:text-sm">Pedro Cuenca</span>
						<div class="my-0.5 flex items-center gap-x-2">

<span class="inline-block "><span class="contents"><span class="leading-tight! block font-mono text-xs underline">pcuenq</span>
							</span>
	</span>
							
							
							
							<div><div class="relative flex items-center gap-1.5  "><button class="flex items-center justify-center rounded-full border-[1.5px] transition-colors duration-200   w-18 h-[20px] text-xs  border-transparent bg-black text-white dark:bg-white dark:text-black" type="button" >
	<div class="flex h-full flex-1 items-center justify-center rounded-full">Follow</div></button>

		</div></div>
						</div></a>
					<div class="flex items-center pt-0.5">
					</div></div>
			</div></div>
	</div></div></div>
					

					<!-- HTML_TAG_START --><blockquote class="tip">
<p>

<div class="absolute -left-12 bottom-0 top-0 z-10 not-prose hidden lg:block"><div class="sticky top-4 flex"><div class="h-7 pt-[0.175rem]">
				<span class="peer" tabindex="0"><button class="select-none text-gray-400 hover:cursor-pointer hover:text-gray-800 dark:text-gray-500 dark:hover:text-gray-400"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-lg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg></button></span>
				<div class="invisible w-0 -translate-x-8 -translate-y-6 overflow-hidden rounded-xl border bg-white transition-transform hover:visible hover:w-52 hover:translate-x-0 peer-focus-within:visible peer-focus-within:w-52 peer-focus-within:translate-x-0"><nav aria-label="Secondary" class="max-h-[550px] overflow-y-auto p-3"><ul><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#table-of-contents" title="Table-of-Contents"><!-- HTML_TAG_START -->Table-of-Contents<!-- HTML_TAG_END --></a>
									<ul class="pl-1"></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#brief-introduction-to-modern-ocr" title="Brief Introduction to Modern OCR"><!-- HTML_TAG_START -->Brief Introduction to Modern OCR<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#model-capabilities" title="Model Capabilities"><!-- HTML_TAG_START -->Model Capabilities<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#cutting-edge-open-ocr-models" title="Cutting-edge Open OCR Models"><!-- HTML_TAG_START -->Cutting-edge Open OCR Models<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#comparing-latest-models" title="Comparing Latest Models"><!-- HTML_TAG_START -->Comparing Latest Models<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#evaluating-models" title="Evaluating Models"><!-- HTML_TAG_START -->Evaluating Models<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#tools-to-run-models" title="Tools to Run Models"><!-- HTML_TAG_START -->Tools to Run Models<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#locally" title="Locally"><!-- HTML_TAG_START -->Locally<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#remotely" title="Remotely"><!-- HTML_TAG_START -->Remotely<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#going-beyond-ocr" title="Going Beyond OCR"><!-- HTML_TAG_START -->Going Beyond OCR<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#wrapping-up" title="Wrapping up"><!-- HTML_TAG_START -->Wrapping up<!-- HTML_TAG_END --></a>
									<ul class="pl-1"></ul>
								</li></ul></nav></div></div></div></div>We have added <a href="https://huggingface.co/datalab-to/chandra">Chandra</a> and <a href="https://huggingface.co/allenai/olmOCR-2-7B-1025">OlmOCR-2</a> to this blog, as well as OlmOCR Scores of the models 🫡</p>
</blockquote>

<p>TL;DR: The rise of powerful vision-language models has transformed document AI. Each model comes with unique strengths, making it tricky to choose the right one. Open-weight models offer better cost efficiency and privacy. To help you get started with them, we’ve put together this guide.</p>
<p>In this guide, you’ll learn:</p>
<ul>
<li>The landscape of current models and their capabilities  </li>
<li>When to fine-tune models vs. use models out-of-the-box  </li>
<li>Key factors to consider when selecting a model for your use case  </li>
<li>How to move beyond OCR with multimodal retrieval and document QA</li>
</ul>
<p>By the end, you’ll know how to choose the right OCR model, start building with it, and gain deeper insights into document AI. Let’s go!</p>
<h2 class="relative group flex items-center">
	<a 
		id="table-of-contents" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#table-of-contents"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Table-of-Contents
	</span>
</h2>
<ul>
<li><a href="#supercharge-your-ocr-pipelines-with-open-models">Supercharge your OCR Pipelines with Open Models</a><ul>
<li><a href="#brief-introduction-to-modern-ocr">Brief Introduction to Modern OCR</a><ul>
<li><a href="#model-capabilities">Model Capabilities</a><ul>
<li><a href="#transcription">Transcription</a></li>
<li><a href="#handling-complex-components-in-documents">Handling complex components in documents</a></li>
<li><a href="#output-formats">Output formats</a></li>
<li><a href="#locality-awareness-in-ocr">Locality Awareness in OCR</a></li>
<li><a href="#model-prompting">Model Prompting</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#cutting-edge-open-ocr-models">Cutting-edge Open OCR Models</a><ul>
<li><a href="#comparing-latest-models">Comparing Latest Models</a></li>
<li><a href="#evaluating-models">Evaluating Models</a><ul>
<li><a href="#benchmarks">Benchmarks</a></li>
<li><a href="#cost-efficiency">Cost-efficiency</a></li>
<li><a href="#open-ocr-datasets">Open OCR Datasets</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#tools-to-run-models">Tools to Run Models</a><ul>
<li><a href="#locally">Locally</a></li>
<li><a href="#remotely">Remotely</a></li>
</ul>
</li>
<li><a href="#going-beyond-ocr">Going Beyond OCR</a><ul>
<li><a href="#visual-document-retrievers">Visual Document Retrievers</a></li>
<li><a href="#using-vision-language-models-for-document-question-answering">Using Vision Language Models for Document Question Answering</a></li>
</ul>
</li>
<li><a href="#wrapping-up">Wrapping up</a></li>
</ul>
</li>
</ul>
<h2 class="relative group flex items-center">
	<a 
		id="brief-introduction-to-modern-ocr" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#brief-introduction-to-modern-ocr"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Brief Introduction to Modern OCR
	</span>
</h2>
<p>Optical Character Recognition (OCR) is one of the earliest and longest running challenges in computer vision.  Many of AI’s first practical applications focused on turning printed text into digital form.</p>
<p>With the surge of <a href="https://huggingface.co/blog/vlms">vision-language models</a> (VLMs), OCR has advanced significantly. Recently, many OCR models have been developed by fine-tuning existing VLMs. But today’s capabilities extend far beyond OCR: you can retrieve documents by query or answer questions about them directly. Thanks to stronger vision features, these models can also handle low-quality scans, interpret complex elements like tables, charts, and images, and fuse text with visuals to answer open-ended questions across documents.</p>
<h3 class="relative group flex items-center">
	<a 
		id="model-capabilities" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#model-capabilities"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Model Capabilities
	</span>
</h3>
<h4 class="relative group flex items-center">
	<a 
		id="transcription" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#transcription"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Transcription
	</span>
</h4>
<p>Recent models transcribe texts into a machine-readable format.<br>The input can include: </p>
<ul>
<li>Handwritten text   </li>
<li>Various scripts like Latin, Arabic, and Japanese characters  </li>
<li>Mathematical expressions   </li>
<li>Chemical formulas  </li>
<li>Image/Layout/Page number tags</li>
</ul>
<p>OCR models convert them into machine-readable text that comes in many different formats like HTML, Markdown and more.  </p>
<h4 class="relative group flex items-center">
	<a 
		id="handling-complex-components-in-documents" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#handling-complex-components-in-documents"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Handling complex components in documents
	</span>
</h4>
<p>On top of text, some models can also recognize:</p>
<ul>
<li>Images  </li>
<li>Charts  </li>
<li>Tables</li>
</ul>
<p>Some models know where images are inside the document, extract their coordinates, and insert them appropriately between texts. Other models generate captions for images and insert them where they appear. This is especially useful if you are feeding the machine-readable output into an LLM. Example models are <a href="https://huggingface.co/allenai/olmOCR-7B-0825">OlmOCR by AllenAI</a>, or <a href="https://huggingface.co/PaddlePaddle/PaddleOCR-VL">PaddleOCR-VL by PaddlePaddle</a>.</p>
<p>Models use different machine-readable output formats, such as <strong>DocTags</strong>, <strong>HTML</strong> or <strong>Markdown</strong> (explained in the next section <em>Output Formats</em>). The way a model handles tables and charts often depends on the output format they are using. Some models treat charts like images: they are kept as is. Other models convert charts into markdown tables or JSON, e.g., a bar chart can be converted as follows. </p>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/chart-rendering.png" rel="nofollow"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/chart-rendering.png" alt="Chart Rendering"></a></p>
<p>Similarly for tables, cells are converted into a machine-readable format while retaining context from headings and columns. </p>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/table-rendering.png" rel="nofollow"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/table-rendering.png" alt="Table Rendering"></a></p>
<h4 class="relative group flex items-center">
	<a 
		id="output-formats" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#output-formats"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Output formats
	</span>
</h4>
<p>Different OCR models have different output formats. Briefly, here are the common output formats used by modern models.<br><strong>DocTag:</strong> DocTag is an XML-like format for documents that expresses location, text format, component-level information, and more. Below is an illustration of a paper parsed into DocTags. This format is employed by the open Docling models.  </p>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/doctags_v2.png" rel="nofollow"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/doctags_v2.png" alt="DocTags"></a>  </p>
<ul>
<li><strong>HTML:</strong> HTML is one of the most popular output formats used for document parsing as it properly encodes structure and hierarchical information.   </li>
<li><strong>Markdown:</strong> Markdown is the most human-readable format. It’s simpler than HTML but not as expressive. For example, it can’t represent split-column tables.  </li>
<li><strong>JSON:</strong> JSON is not a format that models use for the entire output, but it can be used to represent information in tables or charts.</li>
</ul>
<p>The right model depends on how you plan to use its outputs:</p>
<ul>
<li><strong>Digital reconstruction</strong>: To reconstruct documents digitally, choose a model with a layout-preserving format (e.g., DocTags or HTML).  </li>
<li><strong>LLM input or Q&amp;A</strong>: If the use case involves passing outputs to LLM, pick a model that outputs Markdown and image captions, since they’re closer to natural language.  </li>
<li><strong>Programmatic use</strong>: If you want to pass your outputs to a program (like data analysis), opt for a model that generates structured outputs like JSON.</li>
</ul>
<h4 class="relative group flex items-center">
	<a 
		id="locality-awareness" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#locality-awareness"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Locality Awareness
	</span>
</h4>
<p>Documents can have complex structures, like multi-column text blocks and floating figures. Older OCR models handled these documents by detecting words and then the layout of pages manually in post-processing to have the text rendered in reading order, which is brittle.  Modern OCR models, on the other hand, incorporate layout metadata to help preserve reading order and accuracy. This metadata is called “anchor”, it can come in bounding boxes. This process is also called as “grounding/anchoring” because it helps with reducing hallucination.</p>
<h4 class="relative group flex items-center">
	<a 
		id="model-prompting" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#model-prompting"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Model Prompting
	</span>
</h4>
<p>OCR models can either take in images and an optional text prompt, this depends on the model architecture and the pre-training setup.<br>Some OCR models support prompt-based task switching, e.g. <a href="https://huggingface.co/ibm-granite/granite-docling-258M">granite-docling</a> can parse an entire page with the prompt “Convert this page to Docling” while it can also take prompts like “Convert this formula to LaTeX” along with a page full of formulas.<br>Other models, however, are trained only for parsing entire pages, and they are conditioned to do this through a system prompt.<br>For instance, <a href="https://huggingface.co/collections/allenai/olmocr-67af8630b0062a25bf1b54a1">OlmOCR by AllenAI</a> takes a long conditioning prompt. Like many others, OlmOCR is technically an OCR fine-tuned version of a VLM (Qwen2.5VL in this case), so you can prompt for other tasks, but its performance will not be on par with the OCR capabilities. </p>
<h2 class="relative group flex items-center">
	<a 
		id="cutting-edge-open-ocr-models" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#cutting-edge-open-ocr-models"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Cutting-edge Open OCR Models
	</span>
</h2>
<p>We’ve seen an incredible wave of new models this past year. Because so much work is happening in the open, these players build on and benefit from each other’s work. A great example is AllenAI’s release of OlmOCR, which not only released a model but also the dataset used to train it. With these, others can build upon them in new directions. The field is incredibly active, but it’s not always obvious which model to use. </p>
<h3 class="relative group flex items-center">
	<a 
		id="comparing-latest-models" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#comparing-latest-models"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Comparing Latest Models
	</span>
</h3>
<p>To make things a bit easier, we’re putting together a non-exhaustive comparison of some of our current favorite models. All of the models below are layout-aware and can parse tables, charts, and math equations. The full list of languages each model supports are detailed in their model cards, so make sure to check them if you’re interested. All models below have open-source license except for Chandra having OpenRAIL license and Nanonets license being unclear. The average scores are taken from model cards of Chandra, OlmOCR, evaluated on OlmOCR Benchmark, which is English-only.
Many of the models in this collection have been fine-tuned from Qwen2.5-VL or Qwen3-VL, so we also provide Qwen3-VL model below as well. </p>
<div class="max-w-full overflow-auto">
	<table>
		<thead><tr>
<th align="left">Model Name</th>
<th align="left">Output formats</th>
<th align="left">Features</th>
<th align="left">Model Size</th>
<th align="left">Multilingual?</th>
<th align="left">Average Score on OlmOCR Benchmark</th>
</tr>
</theader>
		<tbody><tr>
<td align="left"><a href="https://huggingface.co/collections/nanonets/nanonets-ocr2-68ed207f17ee6c31d226319e">Nanonets-OCR2-3B</a></td>
<td align="left">structured Markdown with semantic tagging (plus HTML tables, etc.)</td>
<td align="left">Captions images in the documents<br>Signature &amp; watermark extraction<br>Handles checkboxes, flowcharts, and handwriting</td>
<td align="left">4B</td>
<td align="left">✅Supports English, Chinese, French, Arabic and more.</td>
<td align="left">N/A</td>
</tr>
<tr>
<td align="left"><a href="https://huggingface.co/collections/PaddlePaddle/paddleocr-vl-68f0db852483c7af0bc86849">PaddleOCR-VL</a></td>
<td align="left">Markdown, JSON, HTML tables and charts</td>
<td align="left">Handles handwriting, old documents<br>Allows prompting<br>Converts tables &amp; charts to HTML<br>Extracts and inserts images directly</td>
<td align="left">0.9B</td>
<td align="left">✅Supports 109 languages</td>
<td align="left">N/A</td>
</tr>
<tr>
<td align="left"><a href="https://huggingface.co/rednote-hilab/dots.ocr">dots.ocr</a></td>
<td align="left">Markdown, JSON</td>
<td align="left">Grounding<br>Extracts and inserts images<br>Handles handwriting</td>
<td align="left">3B</td>
<td align="left">✅Multilingual with language info not available</td>
<td align="left">79.1 ± 1.0</td>
</tr>
<tr>
<td align="left"><a href="https://huggingface.co/allenai/olmOCR-2-7B-1025">OlmOCR-2</a></td>
<td align="left">Markdown, HTML, LaTeX</td>
<td align="left">Grounding<br>Optimized for large-scale batch processing</td>
<td align="left">8B</td>
<td align="left">❎English-only</td>
<td align="left">82.3 ± 1.1</td>
</tr>
<tr>
<td align="left"><a href="https://huggingface.co/ibm-granite/granite-docling-258M">Granite-Docling-258M</a></td>
<td align="left">DocTags</td>
<td align="left">Prompt-based task switching<br>Ability to prompt element locations with location tokens<br>Rich output</td>
<td align="left">258M</td>
<td align="left">✅Supports English, Japanese, Arabic and Chinese.</td>
<td align="left">N/A</td>
</tr>
<tr>
<td align="left"><a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR">DeepSeek-OCR</a></td>
<td align="left">Markdown, HTML</td>
<td align="left">Supports general visual understanding<br>Can parse and re-render all charts, tables, and more into HTML<br>Handles handwriting<br>Memory-efficient, solves text through image</td>
<td align="left">3B</td>
<td align="left">✅Supports nearly 100 languages</td>
<td align="left">75.4 ± 1.0</td>
</tr>
<tr>
<td align="left"><a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR">Chandra</a></td>
<td align="left">Markdown, HTML, JSON</td>
<td align="left">Grounding<br>Extracts and inserts images as is</td>
<td align="left">9B</td>
<td align="left">✅Supports 40+ languages</td>
<td align="left">83.1 ± 0.9</td>
</tr>
<tr>
<td align="left"><a href="https://huggingface.co/collections/Qwen/qwen3-vl">Qwen3-VL</a></td>
<td align="left">Vision Language Model can output in all formats</td>
<td align="left">Can recognize ancient text<br>Handles handwriting<br>Extracts and inserts images as is</td>
<td align="left">9B</td>
<td align="left">✅Supports 32 languages</td>
<td align="left">N/A</td>
</tr>
</tbody>
	</table>
</div>
<p>While Qwen3-VL itself is a powerful and versatile vision-language model post-trained for document understanding and other tasks, it isn’t optimized for a single, universal OCR prompt. In contrast, the other models were fine-tuned using one or a few fixed prompts specifically designed for OCR tasks. So to use Qwen3-VL, we recommend experimenting with prompts.</p>
<p>Here’s a <a href="https://prithivMLmods-Multimodal-OCR3.hf.space">small demo</a> for you to try some of the latest models and compare their outputs.   </p>
<iframe  
    src="https://prithivMLmods-Multimodal-OCR3.hf.space"  
    frameborder="0"  
    width="850"  
    height="450"

<blockquote>
</iframe>
</blockquote>
<h3 class="relative group flex items-center">
	<a 
		id="evaluating-models" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#evaluating-models"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Evaluating Models
	</span>
</h3>
<h4 class="relative group flex items-center">
	<a 
		id="benchmarks" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#benchmarks"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Benchmarks
	</span>
</h4>
<p>There’s no single best model, as every problem has different needs. Should tables be rendered in Markdown or HTML? Which elements should we extract? How should we quantify text accuracy and error rates? 👀<br>While there are many evaluation datasets and tools, many don’t answer these questions. So we suggest using the following benchmarks:</p>
<ol>
<li><a href="https://huggingface.co/datasets/opendatalab/OmniDocBench"><strong>OmniDocBenchmark</strong></a><strong>:</strong> This widely used benchmark stands out for its diverse document types: books, magazines, and textbooks. Its evaluation criteria are well designed, accepting tables in both HTML and Markdown formats. A novel matching algorithm evaluates the reading order, and formulas are normalized before evaluation. Most metrics rely on edit distance or tree edit distance (tables). Notably, the annotations used for evaluation are not solely human-generated but are acquired through SoTA VLMs or conventional OCR methods.  </li>
<li><a href="https://huggingface.co/datasets/allenai/olmOCR-bench"><strong>OlmOCR-Bench</strong></a>: OlmOCR-Bench takes a different approach: they treat the evaluation as a set of unit tests. For example, table evaluation is done by checking the relation between selected cells of a given table. They use PDFs from public sources, and annotations are done using a wide range of closed-source VLMs. This benchmark is quite successful to evaluate on the English language.  </li>
<li><a href="https://huggingface.co/datasets/wulipc/CC-OCR"><strong>CC-OCR (Multilingual)</strong>:</a> Compared to the previous benchmarks, CC-OCR is less preferred when picking models, due to lower document quality and diversity. However, it’s the only benchmark that contains evaluation beyond English and Chinese! While the evaluation is far from perfect (images are photos with few words), it’s still the best you can do for multilingual evaluation.</li>
</ol>
<p>When testing different OCR models, we&#39;ve found that the performance across different document types, languages, etc., varies a lot. Your domain may not be well represented in existing benchmarks! To make effective use of this new generation of VLM-based OCR models we suggest aiming to collect a dataset of representative examples of your task domain and testing a few different models to compare their performance. </p>
<h4 class="relative group flex items-center">
	<a 
		id="cost-efficiency" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#cost-efficiency"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Cost-efficiency
	</span>
</h4>
<p>Most OCR models are small, having between 3B and 7B parameters; you can even find models with fewer than 1B parameters, like PaddleOCR-VL. However, the cost also depends on the availability of optimized implementations for specialized inference frameworks. For example, OlmOCR-2 comes with vLLM and SGLang implementations, and the cost per million pages is 178 dollars (assuming on H100 for $2.69/hour). DeepSeek-OCR can process 200k+ pages per day on a single A100 with 40GB VRAM.  With napkin math, we see that the cost per million pages is more or less similar to OlmOCR (although it depends on your A100 provider). If your use case remains unaffected, you can also opt for quantized versions of the models. The cost of running open-source models heavily depends on the hourly cost of the instance and the optimizations the model includes, but it’s guaranteed to be cheaper than many closed-source models out there on a larger scale.</p>
<h4 class="relative group flex items-center">
	<a 
		id="open-ocr-datasets" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#open-ocr-datasets"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Open OCR Datasets
	</span>
</h4>
<p>While the past year has seen a surge in open OCR models, this hasn&#39;t been matched by as many open training and evaluation datasets. An exception is AllenAI&#39;s <a href="https://huggingface.co/datasets/allenai/olmOCR-mix-0225">olmOCR-mix-0225</a>, which has been used to train at least <a href="https://huggingface.co/models?dataset=dataset:allenai/olmOCR-mix-0225">72 models on the Hub</a> – likely more, since not all models document their training data.</p>
<p>Sharing more datasets could unlock even greater advances in open OCR models. There are several promising approaches for creating these datasets:</p>
<ul>
<li><strong>Synthetic data generation</strong> (e.g., <a href="https://huggingface.co/datasets/Sigurdur/isl_synthetic_ocr">isl_synthetic_ocr</a>)  </li>
<li><strong>VLM-generated transcriptions</strong> filtered manually or through heuristics  </li>
<li><strong>Using existing OCR models</strong> to generate training data for new, potentially more efficient models in specific domains  </li>
<li><strong>Leveraging existing corrected datasets</strong> like the <a href="https://huggingface.co/NationalLibraryOfScotland">Medical History of British India Dataset</a>, which contains extensively human-corrected OCR for historic documents</li>
</ul>
<p>It&#39;s worth noting that many such datasets exist but remain unused. Making them more readily available as &#39;training-ready&#39; datasets carries a considerable potential for the open-source community.</p>
<h2 class="relative group flex items-center">
	<a 
		id="tools-to-run-models" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#tools-to-run-models"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Tools to Run Models
	</span>
</h2>
<p>We have received many questions about getting started with OCR models, so here are a few ways you can use local inference tools and host remotely with Hugging Face.</p>
<h3 class="relative group flex items-center">
	<a 
		id="locally" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#locally"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Locally
	</span>
</h3>
<p>Most cutting-edge models come with vLLM support and transformers implementation. You can get more info about how to serve each from the models’ own cards. For convenience, we show how to infer locally using vLLM here. The code below can differ from model to model, but for most models it looks like the following. </p>
<pre><code class="language-shell">vllm serve nanonets/Nanonets-OCR2-3B
</code></pre>
<p>And then you can query as follows using e.g. OpenAI client. </p>
<pre><code class="language-py"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">import</span> base64

client = OpenAI(base_url=<span class="hljs-string">&quot;http://localhost:8000/v1&quot;</span>)

model = <span class="hljs-string">&quot;nanonets/Nanonets-OCR2-3B&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_image</span>(<span class="hljs-params">image_path</span>):
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(image_path, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> image_file:
        <span class="hljs-keyword">return</span> base64.b64encode(image_file.read()).decode(<span class="hljs-string">&quot;utf-8&quot;</span>)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">infer</span>(<span class="hljs-params">img_base64</span>):
    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
                <span class="hljs-string">&quot;content&quot;</span>: [
                    {
                        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image_url&quot;</span>,
                        <span class="hljs-string">&quot;image_url&quot;</span>: {<span class="hljs-string">&quot;url&quot;</span>: <span class="hljs-string">f&quot;data:image/png;base64,<span class="hljs-subst">{img_base64}</span>&quot;</span>},
                    },
                    {
                        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>,
                        <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;Extract the text from the above document as if you were reading it naturally.&quot;</span>,
                    },
                ],
            }
        ],
        temperature=<span class="hljs-number">0.0</span>,
        max_tokens=<span class="hljs-number">15000</span>
    )
    <span class="hljs-keyword">return</span> response.choices[<span class="hljs-number">0</span>].message.content

img_base64 = encode_image(your_img_path)
<span class="hljs-built_in">print</span>(infer(img_base64))
</code></pre>
<p><strong>Transformers</strong></p>
<p>Transformers provides standard model definitions for easy inference and fine-tuning. Models available in transformers come with either official transformers implementation (model definitions within the library) or “remote code” implementations. Latter is defined by the model owners to enable easy loading of models into transformers interface, so you don’t have to go through the model implementation. Below is an example loading Nanonets model using transformers implementation.</p>
<pre><code class="language-py"><span class="hljs-comment"># make sure to install flash-attn and transformers</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor, AutoModelForImageTextToText

model = AutoModelForImageTextToText.from_pretrained(
    <span class="hljs-string">&quot;nanonets/Nanonets-OCR2-3B&quot;</span>, 
    torch_dtype=<span class="hljs-string">&quot;auto&quot;</span>, 
    device_map=<span class="hljs-string">&quot;auto&quot;</span>, 
    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span>
)
model.<span class="hljs-built_in">eval</span>()
processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;nanonets/Nanonets-OCR2-3B&quot;</span>)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">infer</span>(<span class="hljs-params">image_url, model, processor, max_new_tokens=<span class="hljs-number">4096</span></span>):
    prompt = <span class="hljs-string">&quot;&quot;&quot;Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the &lt;img&gt;&lt;/img&gt; tag; otherwise, add the image caption inside &lt;img&gt;&lt;/img&gt;. Watermarks should be wrapped in brackets. Ex: &lt;watermark&gt;OFFICIAL COPY&lt;/watermark&gt;. Page numbers should be wrapped in brackets. Ex: &lt;page_number&gt;14&lt;/page_number&gt; or &lt;page_number&gt;9/22&lt;/page_number&gt;. Prefer using ☐ and ☑ for check boxes.&quot;&quot;&quot;</span>
    image = Image.<span class="hljs-built_in">open</span>(image_path)
    messages = [
        {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>},
        {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: [
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;image&quot;</span>: image_url},
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: prompt},
        ]},
    ]
    text = processor.apply_chat_template(messages, tokenize=<span class="hljs-literal">False</span>, add_generation_prompt=<span class="hljs-literal">True</span>)
    inputs = processor(text=[text], images=[image], padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(model.device)
    
    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=<span class="hljs-literal">False</span>)
    generated_ids = [output_ids[<span class="hljs-built_in">len</span>(input_ids):] <span class="hljs-keyword">for</span> input_ids, output_ids <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(inputs.input_ids, output_ids)]
    
    output_text = processor.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>, clean_up_tokenization_spaces=<span class="hljs-literal">True</span>)
    <span class="hljs-keyword">return</span> output_text[<span class="hljs-number">0</span>]

result = infer(image_path, model, processor, max_new_tokens=<span class="hljs-number">15000</span>)
<span class="hljs-built_in">print</span>(result)
</code></pre>
<p><strong>MLX</strong><br>MLX is an open-source machine learning framework for Apple Silicon. <a href="https://github.com/Blaizzy/mlx-vlm">MLX-VLM</a> is built on top of MLX to serve vision language models easily. You can explore all the OCR models available in MLX format <a href="https://huggingface.co/models?sort=trending&amp;search=ocr">here</a>. They also come in quantized versions.<br>You can install MLX-VLM as follows.</p>
<pre><code>pip install -U mlx-vlm
</code></pre>
<pre><code>wget https://huggingface.co/datasets/merve/vlm_test_images/resolve/main/throughput_smolvlm.png

python -m mlx_vlm.generate --model ibm-granite/granite-docling-258M-mlx --max-tokens 4096 --temperature 0.0 --prompt &quot;Convert this chart to JSON.&quot; --image throughput_smolvlm.png 
</code></pre>
<h3 class="relative group flex items-center">
	<a 
		id="remotely" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#remotely"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Remotely
	</span>
</h3>
<p><strong>Inference Endpoints for Managed Deployment</strong><br>You can deploy OCR models compatible with vLLM or SGLang on Hugging Face Inference Endpoints, either from a model repository “Deploy” option or directly through <a href="https://endpoints.huggingface.co/">Inference Endpoints interface</a>. Inference Endpoints serve the cutting-edge models in a fully managed environment with GPU acceleration, auto-scaling, and monitoring without manually managing the infrastructure.  </p>
<p>Here is a simple method of deploying <code>nanonets</code> using vLLM as the inference engine.</p>
<ol>
<li>Navigate to the model repository <a href="https://huggingface.co/nanonets/Nanonets-OCR2-3B"><code>nanonets/Nanonets-OCR2-3B</code></a>  </li>
<li>Click on the “Deploy” button and select the “HF Inference Endpoints”</li>
</ol>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/IE.png" rel="nofollow"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/IE.png" alt="Inference Endpoints"></a></p>
<ol start="3">
<li>Configure the deployment setup within seconds</li>
</ol>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/IE2.png" rel="nofollow"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/ocr/IE2.png" alt="Inference Endpoints"></a></p>
<ol start="4">
<li>After the endpoint is created, you can consume it using the OpenAI client snippet we provided in the previous section.</li>
</ol>
<p>You can learn more about it <a href="https://huggingface.co/docs/inference-endpoints/engines/vllm">here</a>.</p>
<p><strong>Hugging Face Jobs for Batch Inference</strong> </p>
<p>For many OCR applications, you want to do efficient batch inference, i.e., running a model across thousands of images as cheaply and efficiently as possible. A good approach is to use vLLM&#39;s offline inference mode. As discussed above, many recent VLM-based OCR models are supported by vLLM, which efficiently batches images and generates OCR outputs at scale.</p>
<p>To make this even easier, we&#39;ve created <a href="https://huggingface.co/datasets/uv-scripts/ocr">uv-scripts/ocr</a>, a collection of ready-to-run OCR scripts that work with Hugging Face Jobs. These scripts let you run OCR on any dataset without needing your own GPU. Simply point the script at your input dataset, and it will:</p>
<ul>
<li>Process all images in a dataset column using many different open OCR models  </li>
<li>Add OCR results as a new markdown column to the dataset  </li>
<li>Push the updated dataset with OCR results to the Hub</li>
</ul>
<p>For example, to run OCR on 100 images:</p>
<pre><code class="language-bash">hf <span class="hljs-built_in">jobs</span> uv run --flavor l4x1 \
  https://huggingface.co/datasets/uv-scripts/ocr/raw/main/nanonets-ocr.py \
  your-input-dataset your-output-dataset \
  --max-samples 100
</code></pre>
<p>The scripts handle all the vLLM configuration and batching automatically, making batch OCR accessible without infrastructure setup.</p>
<h3 class="relative group flex items-center">
	<a 
		id="going-beyond-ocr" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#going-beyond-ocr"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Going Beyond OCR
	</span>
</h3>
<p>If you are interested in document AI, not just OCR, here are some of our recommendations. </p>
<h4 class="relative group flex items-center">
	<a 
		id="visual-document-retrievers" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#visual-document-retrievers"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Visual Document Retrievers
	</span>
</h4>
<p>Visual document retrieval is to retrieve the most relevant top-k documents when given a text query. If you have previously worked with retriever models, the difference is that you search directly on a stack of PDFs. Aside from using them standalone, you can also build multimodal RAG pipelines by combining them with a vision language model (find how to do so <a href="https://huggingface.co/merve/smol-vision/blob/main/ColPali_%2B_Qwen2_VL.ipynb">here</a>). You can find <a href="https://huggingface.co/models?pipeline_tag=visual-document-retrieval&amp;sort=trending">all of them on Hugging Face Hub</a>.</p>
<p>There are two types of visual document retrievers, single-vector and multi-vector models. Single-vector models are more memory efficient and less performant; meanwhile, multi-vector models are more memory hungry and more performant. Most of these models often come with vLLM and transformers integrations, so you can index documents using them and then do a search easily using a vector DB.</p>
<h4 class="relative group flex items-center">
	<a 
		id="using-vision-language-models-for-document-question-answering" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#using-vision-language-models-for-document-question-answering"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Using Vision Language Models for Document Question Answering
	</span>
</h4>
<p>If you have a task at hand that only requires answering questions based on documents, you can use some of the vision language models that had document tasks in their training tasks. We’ve observed users trying to convert documents into text and passing the output to LLMs, but if your document has a complex layout, and your converted document outputs charts and so on in HTML, or images are captioned incorrectly, the LLM will miss out. Instead, feed your document and query to one of the advanced vision language models like <a href="https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe">Qwen3-VL</a> not to miss out on any context. </p>
<h2 class="relative group flex items-center">
	<a 
		id="wrapping-up" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#wrapping-up"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Wrapping up
	</span>
</h2>
<p>In this blog post, we wanted to give you an overview of how to pick your OCR model, existing cutting-edge models and capabilities, and the tools to get you started with OCR.<br>If you want to learn more about OCR and vision language models, we encourage you to read the resources below. </p>
<ul>
<li><a href="https://huggingface.co/blog/vlms">Vision Language Models Explained</a>  </li>
<li><a href="https://huggingface.co/blog/vlms-2025">Vision Language Models 2025 Update</a>  </li>
<li><a href="https://huggingface.co/blog/baidu/ppocrv5">Blog on PP-OCR-v5</a></li>
<li><a href="https://huggingface.co/merve/smol-vision/blob/main/Grounded_Fine_tuning.ipynb">Tutorial: Fine-tuning Kosmos2.5 on Grounded OCR</a></li>
<li><a href="https://huggingface.co/merve/smol-vision/blob/main/Fine_tune_Florence_2.ipynb">Tutorial: Fine-tuning Florence-2 on DocVQA</a></li>
<li><a href="https://huggingface.co/blog/dots-ocr-ne">SOTA OCR on-device with Core ML and dots.ocr</a></li>
</ul>
<!-- HTML_TAG_END --></div></div>
			<div class="mx-auto mt-16 max-w-7xl border-t border-gray-200"><div class="grid gap-4 px-4 py-8 sm:px-6 lg:px-8"><div class="grid grid-cols-1 gap-6"><p class="col-span-1 mb-4 text-center text-lg font-semibold">More Articles from our Blog</p>
							<div class="SVELTE_HYDRATER contents" data-target="BlogThumbnail" data-props="{&quot;blog&quot;:{&quot;_id&quot;:&quot;68d2a2e2b7df8370d2d86c40&quot;,&quot;canonical&quot;:true,&quot;isUpvotedByUser&quot;:false,&quot;numCoauthors&quot;:4,&quot;publishedAt&quot;:&quot;2025-09-23T00:00:00.632Z&quot;,&quot;slug&quot;:&quot;smol2operator&quot;,&quot;title&quot;:&quot;Smol2Operator: Post-Training GUI Agents for Computer Use&quot;,&quot;tags&quot;:[&quot;agents&quot;,&quot;gui&quot;,&quot;vlm&quot;,&quot;vision&quot;,&quot;training&quot;,&quot;post-training&quot;,&quot;computer-use&quot;,&quot;agentic&quot;,&quot;community&quot;,&quot;open-source&quot;],&quot;upvotes&quot;:123,&quot;thumbnail&quot;:&quot;/blog/assets/smol2operator/thumbnail.png&quot;,&quot;authorsData&quot;:[{&quot;_id&quot;:&quot;67f2f500e329a81a62a05d44&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/67f2f500e329a81a62a05d44/DOlzc8GFQzrnfVrsOdtbN.png&quot;,&quot;fullname&quot;:&quot;Amir Mahla&quot;,&quot;name&quot;:&quot;A-Mahla&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:75},{&quot;_id&quot;:&quot;6141a88b3a0ec78603c9e784&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg&quot;,&quot;fullname&quot;:&quot;merve&quot;,&quot;name&quot;:&quot;merve&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:9147},{&quot;_id&quot;:&quot;61929226ded356549e20c5da&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/61929226ded356549e20c5da/ONUjP2S5fUWd07BiFXm0i.jpeg&quot;,&quot;fullname&quot;:&quot;Sergio Paniego&quot;,&quot;name&quot;:&quot;sergiopaniego&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1344},{&quot;_id&quot;:&quot;61b85ce86eb1f2c5e6233736&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg&quot;,&quot;fullname&quot;:&quot;Vaibhav Srivastav&quot;,&quot;name&quot;:&quot;reach-vb&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1766},{&quot;_id&quot;:&quot;5f0c746619cb630495b814fd&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1594651707950-noauth.jpeg&quot;,&quot;fullname&quot;:&quot;Lewis Tunstall&quot;,&quot;name&quot;:&quot;lewtun&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1234}]},&quot;blogUrl&quot;:&quot;/blog&quot;,&quot;lang&quot;:&quot;en&quot;}"><a class="shadow-xs group relative flex flex-col overflow-hidden rounded-xl border border-gray-100 transition-shadow hover:shadow-inner dark:border-gray-800 lg:col-span-1 lg:flex-row lg:items-stretch " href="/blog/smol2operator"><div class="shadow-alternate relative aspect-[2/1] w-full flex-none overflow-hidden lg:aspect-[1.91/1] lg:w-72"><img src="/blog/assets/smol2operator/thumbnail.png" class="group-hover:scale-102 absolute inset-0 h-full w-full object-cover transition-transform duration-300 ease-in-out" alt=""></div>

	<div class="flex flex-1 flex-col justify-center px-4 py-4 lg:py-2 lg:pl-8 lg:pr-5"><div class="mb-2 flex flex-wrap gap-1.5"><span class="rounded-full bg-gray-100 px-2 py-0.5 font-mono text-xs capitalize text-gray-600 dark:bg-gray-800 dark:text-gray-300">agents</span><span class="rounded-full bg-gray-100 px-2 py-0.5 font-mono text-xs capitalize text-gray-600 dark:bg-gray-800 dark:text-gray-300">gui</span><span class="rounded-full bg-gray-100 px-2 py-0.5 font-mono text-xs capitalize text-gray-600 dark:bg-gray-800 dark:text-gray-300">vlm</span></div>
		<h2 class="text-pretty font-serif text-xl font-semibold decoration-gray-400 group-hover:underline dark:decoration-gray-600 lg:line-clamp-2 lg:text-2xl">Smol2Operator: Post-Training GUI Agents for Computer Use</h2>

		<div class="mt-1.5 flex max-w-full items-center gap-2 font-mono text-xs text-gray-500">
			<div class="flex-none"><ul class="flex items-center  flex-row  text-base   "><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="A-Mahla" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/67f2f500e329a81a62a05d44/DOlzc8GFQzrnfVrsOdtbN.png" loading="lazy">
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="merve" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg" loading="lazy">
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sergiopaniego" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/61929226ded356549e20c5da/ONUjP2S5fUWd07BiFXm0i.jpeg" loading="lazy">
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="reach-vb" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg" loading="lazy">
			</li>

		<li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"><span class="mr-1.5">+1</span></li></ul></div>

			
			

			
			<div class="ml-auto flex flex-none items-center gap-3">
				<div class="flex items-center"><svg class="flex-none w-3 mr-1 text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12" fill="transparent"><path d="M9.30013 9.29152H9.3H2.7H2.69987C2.62308 9.29154 2.54762 9.27146 2.481 9.23328C2.41437 9.1951 2.3589 9.14015 2.32009 9.07389C2.28128 9.00763 2.26048 8.93237 2.25977 8.85558C2.25907 8.7798 2.27796 8.70513 2.31458 8.63882L5.62238 2.9426L5.67518 2.85168C5.7059 2.81806 5.74178 2.78928 5.78164 2.76649C5.84813 2.72848 5.9234 2.70848 6 2.70848C6.0766 2.70848 6.15187 2.72848 6.21836 2.76649C6.28441 2.80425 6.33953 2.85848 6.37836 2.92389L9.68527 8.63855C9.72199 8.70493 9.74093 8.7797 9.74023 8.85558C9.73952 8.93237 9.71872 9.00763 9.67991 9.07389C9.6411 9.14015 9.58563 9.1951 9.519 9.23328C9.45238 9.27146 9.37692 9.29154 9.30013 9.29152Z" stroke="currentColor"></path></svg>
						123</div>

				
				<span class="whitespace-nowrap">September 23, 2025</span>

				
				</div></div>

		
		<span class="invisible absolute whitespace-nowrap font-mono text-sm" aria-hidden="true"></span></div></a></div><div class="SVELTE_HYDRATER contents" data-target="BlogThumbnail" data-props="{&quot;blog&quot;:{&quot;_id&quot;:&quot;685d77dd194bc82c1223345f&quot;,&quot;canonical&quot;:true,&quot;isUpvotedByUser&quot;:false,&quot;numCoauthors&quot;:7,&quot;publishedAt&quot;:&quot;2025-06-26T00:00:00.589Z&quot;,&quot;slug&quot;:&quot;gemma3n&quot;,&quot;title&quot;:&quot;Gemma 3n fully available in the open-source ecosystem!&quot;,&quot;tags&quot;:[&quot;audio&quot;,&quot;vision&quot;,&quot;llm&quot;,&quot;vlm&quot;,&quot;community&quot;,&quot;research&quot;,&quot;multimodal&quot;],&quot;upvotes&quot;:118,&quot;thumbnail&quot;:&quot;/blog/assets/gemma3n/thumbnail.png&quot;,&quot;authorsData&quot;:[{&quot;_id&quot;:&quot;608aabf24955d2bfc3cd99c6&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/608aabf24955d2bfc3cd99c6/T762Ut0Y-w0sZB2ynvfbJ.jpeg&quot;,&quot;fullname&quot;:&quot;Aritra Roy Gosthipaty&quot;,&quot;name&quot;:&quot;ariG23498&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:425},{&quot;_id&quot;:&quot;603d25b75f9d390ab190b777&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg&quot;,&quot;fullname&quot;:&quot;Pedro Cuenca&quot;,&quot;name&quot;:&quot;pcuenq&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1391},{&quot;_id&quot;:&quot;61929226ded356549e20c5da&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/61929226ded356549e20c5da/ONUjP2S5fUWd07BiFXm0i.jpeg&quot;,&quot;fullname&quot;:&quot;Sergio Paniego&quot;,&quot;name&quot;:&quot;sergiopaniego&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1344},{&quot;_id&quot;:&quot;61b85ce86eb1f2c5e6233736&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg&quot;,&quot;fullname&quot;:&quot;Vaibhav Srivastav&quot;,&quot;name&quot;:&quot;reach-vb&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1766},{&quot;_id&quot;:&quot;6597e9f42235d4056bc6980a&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6597e9f42235d4056bc6980a/6N_Eira5Rj5e8ZdgekKPQ.jpeg&quot;,&quot;fullname&quot;:&quot;Christopher Fleetwood&quot;,&quot;name&quot;:&quot;FL33TW00D-HF&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:177},{&quot;_id&quot;:&quot;61b253b7ac5ecaae3d1efe0c&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png&quot;,&quot;fullname&quot;:&quot;Joshua&quot;,&quot;name&quot;:&quot;Xenova&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:7039},{&quot;_id&quot;:&quot;654bcb6fae75d15300d48205&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/654bcb6fae75d15300d48205/T4L1RZUgCZgdik4ZhEWCq.jpeg&quot;,&quot;fullname&quot;:&quot;Steven Zheng&quot;,&quot;name&quot;:&quot;Steveeeeeeen&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:165},{&quot;_id&quot;:&quot;629f3b18ee05727ce328ccbe&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1669189789447-629f3b18ee05727ce328ccbe.jpeg&quot;,&quot;fullname&quot;:&quot;Kashif Rasul&quot;,&quot;name&quot;:&quot;kashif&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:337}]},&quot;blogUrl&quot;:&quot;/blog&quot;,&quot;lang&quot;:&quot;en&quot;}"><a class="shadow-xs group relative flex flex-col overflow-hidden rounded-xl border border-gray-100 transition-shadow hover:shadow-inner dark:border-gray-800 lg:col-span-1 lg:flex-row lg:items-stretch " href="/blog/gemma3n"><div class="shadow-alternate relative aspect-[2/1] w-full flex-none overflow-hidden lg:aspect-[1.91/1] lg:w-72"><img src="/blog/assets/gemma3n/thumbnail.png" class="group-hover:scale-102 absolute inset-0 h-full w-full object-cover transition-transform duration-300 ease-in-out" alt=""></div>

	<div class="flex flex-1 flex-col justify-center px-4 py-4 lg:py-2 lg:pl-8 lg:pr-5"><div class="mb-2 flex flex-wrap gap-1.5"><span class="rounded-full bg-gray-100 px-2 py-0.5 font-mono text-xs capitalize text-gray-600 dark:bg-gray-800 dark:text-gray-300">audio</span><span class="rounded-full bg-gray-100 px-2 py-0.5 font-mono text-xs capitalize text-gray-600 dark:bg-gray-800 dark:text-gray-300">vision</span><span class="rounded-full bg-gray-100 px-2 py-0.5 font-mono text-xs capitalize text-gray-600 dark:bg-gray-800 dark:text-gray-300">llm</span></div>
		<h2 class="text-pretty font-serif text-xl font-semibold decoration-gray-400 group-hover:underline dark:decoration-gray-600 lg:line-clamp-2 lg:text-2xl">Gemma 3n fully available in the open-source ecosystem!</h2>

		<div class="mt-1.5 flex max-w-full items-center gap-2 font-mono text-xs text-gray-500">
			<div class="flex-none"><ul class="flex items-center  flex-row  text-base   "><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="ariG23498" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/608aabf24955d2bfc3cd99c6/T762Ut0Y-w0sZB2ynvfbJ.jpeg" loading="lazy">
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="pcuenq" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg" loading="lazy">
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sergiopaniego" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/61929226ded356549e20c5da/ONUjP2S5fUWd07BiFXm0i.jpeg" loading="lazy">
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="reach-vb" style="content-visibility:auto;"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg" loading="lazy">
			</li>

		<li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"><span class="mr-1.5">+4</span></li></ul></div>

			
			

			
			<div class="ml-auto flex flex-none items-center gap-3">
				<div class="flex items-center"><svg class="flex-none w-3 mr-1 text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12" fill="transparent"><path d="M9.30013 9.29152H9.3H2.7H2.69987C2.62308 9.29154 2.54762 9.27146 2.481 9.23328C2.41437 9.1951 2.3589 9.14015 2.32009 9.07389C2.28128 9.00763 2.26048 8.93237 2.25977 8.85558C2.25907 8.7798 2.27796 8.70513 2.31458 8.63882L5.62238 2.9426L5.67518 2.85168C5.7059 2.81806 5.74178 2.78928 5.78164 2.76649C5.84813 2.72848 5.9234 2.70848 6 2.70848C6.0766 2.70848 6.15187 2.72848 6.21836 2.76649C6.28441 2.80425 6.33953 2.85848 6.37836 2.92389L9.68527 8.63855C9.72199 8.70493 9.74093 8.7797 9.74023 8.85558C9.73952 8.93237 9.71872 9.00763 9.67991 9.07389C9.6411 9.14015 9.58563 9.1951 9.519 9.23328C9.45238 9.27146 9.37692 9.29154 9.30013 9.29152Z" stroke="currentColor"></path></svg>
						118</div>

				
				<span class="whitespace-nowrap">June 26, 2025</span>

				
				</div></div>

		
		<span class="invisible absolute whitespace-nowrap font-mono text-sm" aria-hidden="true"></span></div></a></div></div></div></div>
			<div class="mx-auto my-8 max-w-5xl border-t border-gray-200 py-8"><h3 class="mb-6 flex items-center text-lg font-semibold"><svg class="mr-2" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M20.6081 3C21.7684 3 22.8053 3.49196 23.5284 4.38415C23.9756 4.93678 24.4428 5.82749 24.4808 7.16133C24.9674 7.01707 25.4353 6.93643 25.8725 6.93643C26.9833 6.93643 27.9865 7.37587 28.696 8.17411C29.6075 9.19872 30.0124 10.4579 29.8361 11.7177C29.7523 12.3177 29.5581 12.8555 29.2678 13.3534C29.8798 13.8646 30.3306 14.5763 30.5485 15.4322C30.719 16.1032 30.8939 17.5006 29.9808 18.9403C30.0389 19.0342 30.0934 19.1319 30.1442 19.2318C30.6932 20.3074 30.7283 21.5229 30.2439 22.6548C29.5093 24.3704 27.6841 25.7219 24.1397 27.1727C21.9347 28.0753 19.9174 28.6523 19.8994 28.6575C16.9842 29.4379 14.3477 29.8345 12.0653 29.8345C7.87017 29.8345 4.8668 28.508 3.13831 25.8921C0.356375 21.6797 0.754104 17.8269 4.35369 14.1131C6.34591 12.058 7.67023 9.02782 7.94613 8.36275C8.50224 6.39343 9.97271 4.20438 12.4172 4.20438H12.4179C12.6236 4.20438 12.8314 4.2214 13.0364 4.25468C14.107 4.42854 15.0428 5.06476 15.7115 6.02205C16.4331 5.09583 17.134 4.359 17.7682 3.94323C18.7242 3.31737 19.6794 3 20.6081 3ZM20.6081 5.95917C20.2427 5.95917 19.7963 6.1197 19.3039 6.44225C17.7754 7.44319 14.8258 12.6772 13.7458 14.7131C13.3839 15.3952 12.7655 15.6837 12.2086 15.6837C11.1036 15.6837 10.2408 14.5497 12.1076 13.1085C14.9146 10.9402 13.9299 7.39584 12.5898 7.1776C12.5311 7.16799 12.4731 7.16355 12.4172 7.16355C11.1989 7.16355 10.6615 9.33114 10.6615 9.33114C10.6615 9.33114 9.0863 13.4148 6.38031 16.206C3.67434 18.998 3.5346 21.2388 5.50675 24.2246C6.85185 26.2606 9.42666 26.8753 12.0653 26.8753C14.8021 26.8753 17.6077 26.2139 19.1799 25.793C19.2574 25.7723 28.8193 22.984 27.6081 20.6107C27.4046 20.212 27.0693 20.0522 26.6471 20.0522C24.9416 20.0522 21.8393 22.6726 20.5057 22.6726C20.2076 22.6726 19.9976 22.5416 19.9116 22.222C19.3433 20.1173 28.552 19.2325 27.7758 16.1839C27.639 15.6445 27.2677 15.4256 26.746 15.4263C24.4923 15.4263 19.4358 19.5181 18.3759 19.5181C18.2949 19.5181 18.2368 19.4937 18.2053 19.4419C17.6743 18.557 17.9653 17.9394 21.7082 15.6009C25.4511 13.2617 28.0783 11.8545 26.5841 10.1752C26.4121 9.98141 26.1684 9.8956 25.8725 9.8956C23.6001 9.89634 18.2311 14.9403 18.2311 14.9403C18.2311 14.9403 16.7821 16.496 15.9057 16.496C15.7043 16.496 15.533 16.4139 15.4169 16.2112C14.7956 15.1296 21.1879 10.1286 21.5484 8.06535C21.7928 6.66715 21.3771 5.95917 20.6081 5.95917Z" fill="#FF9D00"></path><path d="M5.50686 24.2246C3.53472 21.2387 3.67446 18.9979 6.38043 16.206C9.08641 13.4147 10.6615 9.33111 10.6615 9.33111C10.6615 9.33111 11.2499 6.95933 12.59 7.17757C13.93 7.39581 14.9139 10.9401 12.1069 13.1084C9.29997 15.276 12.6659 16.7489 13.7459 14.713C14.8258 12.6772 17.7747 7.44316 19.304 6.44221C20.8326 5.44128 21.9089 6.00204 21.5484 8.06532C21.188 10.1286 14.795 15.1295 15.4171 16.2118C16.0391 17.2934 18.2312 14.9402 18.2312 14.9402C18.2312 14.9402 25.0907 8.49588 26.5842 10.1752C28.0776 11.8545 25.4512 13.2616 21.7082 15.6008C17.9646 17.9393 17.6744 18.557 18.2054 19.4418C18.7372 20.3266 26.9998 13.1351 27.7759 16.1838C28.5513 19.2324 19.3434 20.1173 19.9117 22.2219C20.48 24.3274 26.3979 18.2382 27.6082 20.6107C28.8193 22.9839 19.2574 25.7722 19.18 25.7929C16.0914 26.62 8.24723 28.3726 5.50686 24.2246Z" fill="#FFD21E"></path></svg>Community</h3>

					<div class="SVELTE_HYDRATER contents" data-target="DiscussionEvents" data-props="{&quot;apiBaseUrl&quot;:&quot;/api/blog/ocr-open-models&quot;,&quot;classNames&quot;:&quot;-mx-2.5&quot;,&quot;currentUrl&quot;:&quot;/blog/ocr-open-models&quot;,&quot;inputPlaceholder&quot;:&quot;Start discussing this article&quot;,&quot;discussion&quot;:{&quot;_id&quot;:&quot;68f7b85bca9bb99a258d8cd2&quot;,&quot;title&quot;:&quot;Start discussing this article&quot;,&quot;isPullRequest&quot;:false,&quot;events&quot;:[{&quot;id&quot;:&quot;68f9fbc21e077fda028f9dfb&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;61aefb0dc28a2195d504a1bc&quot;,&quot;avatarUrl&quot;:&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;,&quot;fullname&quot;:&quot;firas snake&quot;,&quot;name&quot;:&quot;abol3z&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:2},&quot;createdAt&quot;:&quot;2025-10-23T09:56:18.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;If only this came last week! I spent the last week learning about about and benchmarking all these plus extra models, and I wanna point out a correction. OlmOCR isn't an English language only model, in fact, it produced the best results across all VLM and none VLM frameworks on my Arabic language corpus.&quot;,&quot;html&quot;:&quot;<p>If only this came last week! I spent the last week learning about about and benchmarking all these plus extra models, and I wanna point out a correction. OlmOCR isn't an English language only model, in fact, it produced the best results across all VLM and none VLM frameworks on my Arabic language corpus.</p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-23T09:56:18.494Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;61aefb0dc28a2195d504a1bc&quot;,&quot;avatarUrl&quot;:&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;,&quot;fullname&quot;:&quot;firas snake&quot;,&quot;name&quot;:&quot;abol3z&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:2}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.923672616481781},&quot;editors&quot;:[&quot;abol3z&quot;],&quot;editorAvatarUrls&quot;:[&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;👍&quot;,&quot;users&quot;:[&quot;sofdog&quot;,&quot;imweijh&quot;],&quot;count&quot;:2}],&quot;isReport&quot;:false},&quot;replies&quot;:[{&quot;id&quot;:&quot;68fab1894f42f6839d809265&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;68136c36060494e99e70dce0&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png&quot;,&quot;fullname&quot;:&quot;mat pokora&quot;,&quot;name&quot;:&quot;doladoo&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false},&quot;createdAt&quot;:&quot;2025-10-23T22:51:53.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:true,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;Which VLM did you test ?&quot;,&quot;html&quot;:&quot;<p>Which VLM did you test ?</p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-23T22:52:42.176Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;68136c36060494e99e70dce0&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png&quot;,&quot;fullname&quot;:&quot;mat pokora&quot;,&quot;name&quot;:&quot;doladoo&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false}},&quot;numEdits&quot;:1,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.9725390672683716},&quot;editors&quot;:[&quot;doladoo&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false,&quot;parentCommentId&quot;:&quot;68f9fbc21e077fda028f9dfb&quot;}},{&quot;id&quot;:&quot;68fb3feab1ab68112a0e5f40&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;6141a88b3a0ec78603c9e784&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg&quot;,&quot;fullname&quot;:&quot;merve&quot;,&quot;name&quot;:&quot;merve&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:9147},&quot;createdAt&quot;:&quot;2025-10-24T08:59:22.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;@abol3z the base model of OlmOCR is Qwen2.5-VL which is multilingual, but the model itself is trained and evaluated on English-only PDFs, so we just state that. &quot;,&quot;html&quot;:&quot;<p><span data-props=\&quot;{&amp;quot;user&amp;quot;:&amp;quot;abol3z&amp;quot;}\&quot; data-target=\&quot;UserMention\&quot; class=\&quot;SVELTE_PARTIAL_HYDRATER contents\&quot;>\n\n<span class=\&quot;inline-block\&quot;><span class=\&quot;contents\&quot;><a href=\&quot;/abol3z\&quot;>@<span class=\&quot;underline\&quot;>abol3z</span></a></span>\n\t</span></span> the base model of OlmOCR is Qwen2.5-VL which is multilingual, but the model itself is trained and evaluated on English-only PDFs, so we just state that. </p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-24T08:59:22.811Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;6141a88b3a0ec78603c9e784&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg&quot;,&quot;fullname&quot;:&quot;merve&quot;,&quot;name&quot;:&quot;merve&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:9147}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.9582025408744812},&quot;editors&quot;:[&quot;merve&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false,&quot;parentCommentId&quot;:&quot;68f9fbc21e077fda028f9dfb&quot;}},{&quot;id&quot;:&quot;68fb9f39c6640dbeb79ea926&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;61aefb0dc28a2195d504a1bc&quot;,&quot;avatarUrl&quot;:&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;,&quot;fullname&quot;:&quot;firas snake&quot;,&quot;name&quot;:&quot;abol3z&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:2},&quot;createdAt&quot;:&quot;2025-10-24T15:46:01.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;@doladoo both version 1 and 2\n@merve from my testing, it didn't lose its multi lingual skills, in fact it made them much better. I tested both Qwen2.5-VL and OlmOCR and the latter is the best on arabic text. &quot;,&quot;html&quot;:&quot;<p><span data-props=\&quot;{&amp;quot;user&amp;quot;:&amp;quot;doladoo&amp;quot;}\&quot; data-target=\&quot;UserMention\&quot; class=\&quot;SVELTE_PARTIAL_HYDRATER contents\&quot;>\n\n<span class=\&quot;inline-block\&quot;><span class=\&quot;contents\&quot;><a href=\&quot;/doladoo\&quot;>@<span class=\&quot;underline\&quot;>doladoo</span></a></span>\n\t</span></span> both version 1 and 2<br><span data-props=\&quot;{&amp;quot;user&amp;quot;:&amp;quot;merve&amp;quot;}\&quot; data-target=\&quot;UserMention\&quot; class=\&quot;SVELTE_PARTIAL_HYDRATER contents\&quot;>\n\n<span class=\&quot;inline-block\&quot;><span class=\&quot;contents\&quot;><a href=\&quot;/merve\&quot;>@<span class=\&quot;underline\&quot;>merve</span></a></span>\n\t</span></span> from my testing, it didn't lose its multi lingual skills, in fact it made them much better. I tested both Qwen2.5-VL and OlmOCR and the latter is the best on arabic text. </p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-24T15:46:01.004Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;61aefb0dc28a2195d504a1bc&quot;,&quot;avatarUrl&quot;:&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;,&quot;fullname&quot;:&quot;firas snake&quot;,&quot;name&quot;:&quot;abol3z&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:2}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.9733607769012451},&quot;editors&quot;:[&quot;abol3z&quot;],&quot;editorAvatarUrls&quot;:[&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false,&quot;parentCommentId&quot;:&quot;68f9fbc21e077fda028f9dfb&quot;}},{&quot;id&quot;:&quot;68fba089497eebf808967fbd&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;68136c36060494e99e70dce0&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png&quot;,&quot;fullname&quot;:&quot;mat pokora&quot;,&quot;name&quot;:&quot;doladoo&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false},&quot;createdAt&quot;:&quot;2025-10-24T15:51:37.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;Did you try paddle ocr vl ?&quot;,&quot;html&quot;:&quot;<p>Did you try paddle ocr vl ?</p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-24T15:51:37.297Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;68136c36060494e99e70dce0&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png&quot;,&quot;fullname&quot;:&quot;mat pokora&quot;,&quot;name&quot;:&quot;doladoo&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.683573842048645},&quot;editors&quot;:[&quot;doladoo&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false,&quot;parentCommentId&quot;:&quot;68f9fbc21e077fda028f9dfb&quot;}},{&quot;id&quot;:&quot;68fcbd59e5e3ee5e5a686e1f&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;61aefb0dc28a2195d504a1bc&quot;,&quot;avatarUrl&quot;:&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;,&quot;fullname&quot;:&quot;firas snake&quot;,&quot;name&quot;:&quot;abol3z&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:2},&quot;createdAt&quot;:&quot;2025-10-25T12:06:49.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;@doladoo yes. I tried Paddle, Miner, Marker, OlmOCR, Chandra-OCR, Docling without VL.\n\nOverall for Arabic, VLM approach showed better performance, and the best was OlmOCR. \n\nNote that my documents are mostly scanned text and tables, nothing more.\n&quot;,&quot;html&quot;:&quot;<p><span data-props=\&quot;{&amp;quot;user&amp;quot;:&amp;quot;doladoo&amp;quot;}\&quot; data-target=\&quot;UserMention\&quot; class=\&quot;SVELTE_PARTIAL_HYDRATER contents\&quot;>\n\n<span class=\&quot;inline-block\&quot;><span class=\&quot;contents\&quot;><a href=\&quot;/doladoo\&quot;>@<span class=\&quot;underline\&quot;>doladoo</span></a></span>\n\t</span></span> yes. I tried Paddle, Miner, Marker, OlmOCR, Chandra-OCR, Docling without VL.</p>\n<p>Overall for Arabic, VLM approach showed better performance, and the best was OlmOCR. </p>\n<p>Note that my documents are mostly scanned text and tables, nothing more.</p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-25T12:06:49.103Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;61aefb0dc28a2195d504a1bc&quot;,&quot;avatarUrl&quot;:&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;,&quot;fullname&quot;:&quot;firas snake&quot;,&quot;name&quot;:&quot;abol3z&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:2}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.923150897026062},&quot;editors&quot;:[&quot;abol3z&quot;],&quot;editorAvatarUrls&quot;:[&quot;/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false,&quot;parentCommentId&quot;:&quot;68f9fbc21e077fda028f9dfb&quot;}}]},{&quot;id&quot;:&quot;68fa8244c7b83d1cd1d57a66&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;630904f2c038bf42d56d9d11&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/630904f2c038bf42d56d9d11/S8mYgFpPSHYOiifBnNfwG.jpeg&quot;,&quot;fullname&quot;:&quot;Harpreet Sahota&quot;,&quot;name&quot;:&quot;harpreetsahota&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:70},&quot;createdAt&quot;:&quot;2025-10-23T19:30:12.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;Great summary! Don't forget, DeepSeek OCR also supports grounding OCR!&quot;,&quot;html&quot;:&quot;<p>Great summary! Don't forget, DeepSeek OCR also supports grounding OCR!</p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-23T19:30:12.940Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;630904f2c038bf42d56d9d11&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/630904f2c038bf42d56d9d11/S8mYgFpPSHYOiifBnNfwG.jpeg&quot;,&quot;fullname&quot;:&quot;Harpreet Sahota&quot;,&quot;name&quot;:&quot;harpreetsahota&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:70}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.8816938996315002},&quot;editors&quot;:[&quot;harpreetsahota&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/630904f2c038bf42d56d9d11/S8mYgFpPSHYOiifBnNfwG.jpeg&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;❤️&quot;,&quot;users&quot;:[&quot;merve&quot;],&quot;count&quot;:1}],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;68fed65d297f9e82c44040cb&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;67b591354dde7e635dd96d5d&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/CSpl8hvY6WTVTxo6Nxtim.png&quot;,&quot;fullname&quot;:&quot;Zheng&quot;,&quot;name&quot;:&quot;janus-zheng-sg&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1},&quot;createdAt&quot;:&quot;2025-10-27T02:18:05.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;wondering why minerU 2.5 model was not included in the comparison? [MinerU2.5-2509-1.2B](https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B) &quot;,&quot;html&quot;:&quot;<p>wondering why minerU 2.5 model was not included in the comparison? <a href=\&quot;https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B\&quot;>MinerU2.5-2509-1.2B</a> </p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-27T02:18:05.067Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;67b591354dde7e635dd96d5d&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/CSpl8hvY6WTVTxo6Nxtim.png&quot;,&quot;fullname&quot;:&quot;Zheng&quot;,&quot;name&quot;:&quot;janus-zheng-sg&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.8342345356941223},&quot;editors&quot;:[&quot;janus-zheng-sg&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/CSpl8hvY6WTVTxo6Nxtim.png&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;690075bdada8f1842d8c6e57&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;68ff4d7a34025a65430f5d90&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/68ff4d7a34025a65430f5d90/Oiy-7WOgfuXGeDMBMnfWw.jpeg&quot;,&quot;fullname&quot;:&quot;Daya Shankar&quot;,&quot;name&quot;:&quot;daya-shankar&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1},&quot;createdAt&quot;:&quot;2025-10-28T07:50:21.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;Super helpful breakdown. The layout-awareness and cost benefits really stand out. Thanks for sharing!&quot;,&quot;html&quot;:&quot;<p>Super helpful breakdown. The layout-awareness and cost benefits really stand out. Thanks for sharing!</p>\n&quot;,&quot;updatedAt&quot;:&quot;2025-10-28T07:50:21.097Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;68ff4d7a34025a65430f5d90&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/68ff4d7a34025a65430f5d90/Oiy-7WOgfuXGeDMBMnfWw.jpeg&quot;,&quot;fullname&quot;:&quot;Daya Shankar&quot;,&quot;name&quot;:&quot;daya-shankar&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:1}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.9393153190612793},&quot;editors&quot;:[&quot;daya-shankar&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/68ff4d7a34025a65430f5d90/Oiy-7WOgfuXGeDMBMnfWw.jpeg&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;🔥&quot;,&quot;users&quot;:[&quot;ariG23498&quot;],&quot;count&quot;:1}],&quot;isReport&quot;:false}}],&quot;status&quot;:&quot;open&quot;,&quot;isReport&quot;:false,&quot;pinned&quot;:false,&quot;locked&quot;:false,&quot;collection&quot;:&quot;canonical_blogs&quot;},&quot;contextAuthors&quot;:[&quot;merve&quot;,&quot;ariG23498&quot;,&quot;davanstrien&quot;,&quot;hynky&quot;,&quot;andito&quot;,&quot;reach-vb&quot;,&quot;pcuenq&quot;],&quot;primaryEmailConfirmed&quot;:false,&quot;discussionRole&quot;:0,&quot;acceptLanguages&quot;:[&quot;ko&quot;,&quot;en&quot;],&quot;withThread&quot;:true,&quot;cardDisplay&quot;:false,&quot;repoDiscussionsLocked&quot;:false}"><div class="relative -mx-2.5">

		<div class="relative">

			

			<div class="relative pt-0 pb-3">







<div id="68f9fbc21e077fda028f9dfb" class="scroll-mt-4 "><div class="flex h-10 items-center justify-between gap-1 px-3 "><div class="flex max-w-full items-center overflow-hidden">

<span class="inline-block "><span class="contents"><div class="mr-2 flex shrink-0 items-center"><img src="/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg" alt="" class="mr-2 select-none h-3.5 w-3.5 rounded-full" loading="lazy">
						<a class="whitespace-nowrap font-semibold hover:underline " href="/abol3z">abol3z</a></div></span>
	</span>
				
				
				
				
				
			<a href="#68f9fbc21e077fda028f9dfb" class="truncate text-xs text-gray-400 hover:underline sm:text-sm"><time datetime="2025-10-23T09:56:18" title="Thu, 23 Oct 2025 09:56:18 GMT">7 days ago</time></a>
			
			</div>
		<div class="flex items-center space-x-2">
				<div class="relative flex items-center">
	<button class="text-gray-500 focus:text-gray-900 dark:focus:text-gray-400 " type="button">
		
						<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><circle cx="16" cy="7" r="3" fill="currentColor"></circle><circle cx="16" cy="16" r="3" fill="currentColor"></circle><circle cx="16" cy="25" r="3" fill="currentColor"></circle></svg>
					
		</button>
	
	
	</div></div></div>

	<div class="break-words rounded-b-lg bg-white px-3.5 pb-2.5 pt-1"><div class="prose text-smd/6 sm:text-base/[1.6rem] prose-card hf-sanitized copiable-code-container">
	<!-- HTML_TAG_START --><p>If only this came last week! I spent the last week learning about about and benchmarking all these plus extra models, and I wanna point out a correction. OlmOCR isn't an English language only model, in fact, it produced the best results across all VLM and none VLM frameworks on my Arabic language corpus.</p>
<!-- HTML_TAG_END --></div>

			

			<div class="mt-3 flex items-center gap-2"><ul class="flex items-center  flex-row    text-xs mr-1.5"><li class="   -mr-1.5 h-3 w-3 md:h-4 md:w-4 bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="doladoo" style="content-visibility:auto;"><a href="/doladoo" title="doladoo"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png" loading="lazy">
					</a>
			</li><li class="   -mr-1.5 h-3 w-3 md:h-4 md:w-4 bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="merve" style="content-visibility:auto;"><a href="/merve" title="merve"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/6141a88b3a0ec78603c9e784/DJsxSmWV39M33JFheLobC.jpeg" loading="lazy">
					</a>
			</li><li class="   -mr-1.5 h-3 w-3 md:h-4 md:w-4 bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="abol3z" style="content-visibility:auto;"><a href="/abol3z" title="abol3z"><img class="overflow-hidden rounded-full" alt="" src="/avatars/4bafb3c3ba6295cae8346e562b25d34b.svg" loading="lazy">
					</a>
			</li>

		<li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-2"><button class="ml-1 whitespace-nowrap text-sm text-gray-500 underline decoration-gray-200 underline-offset-2 hover:decoration-gray-400 dark:decoration-gray-600 dark:hover:decoration-gray-400">5 replies</button></li></ul>
					<span class="mr-2 text-gray-300">·</span>
				<div class="peer-first:mt-2! -ml-1 flex gap-y-1.5 space-x-1 overflow-hidden text-sm"><div class="scrollbar-hidden mr-1 flex select-none gap-x-1 overflow-x-auto overflow-y-hidden text-sm"><div>

<span class="inline-block "><span class="contents"><button slot="anchor" class="bg-linear-to-r group relative flex h-[28px] flex-none items-center rounded-full border-none px-2 leading-none ring-1 ring-inset shadow-xs from-gray-50 to-transparent text-gray-500 ring-gray-100 hover:bg-gray-100 dark:bg-gray-900 dark:from-gray-950 dark:to-transparent dark:ring-gray-800 dark:hover:bg-gray-800"><div class="mr-2 text-[0.9rem]">👍</div>
					<div class="invisible">2</div>
					<div class="absolute right-2">2
						</div>
				</button></span>
	</span>
		</div></div>


					





<div><div class="flex" slot="anchor"><button class="group z-10 select-none"><span class="group relative flex aspect-1 size-7 flex-none select-none items-center justify-center rounded-full border-none text-lg leading-none text-gray-500/80 ring-1 ring-inset ring-gray-100 hover:bg-gray-100 hover:text-gray-700 active:ring-gray-300 dark:ring-gray-800 dark:hover:bg-gray-900 dark:hover:text-yellow-500 dark:active:ring-orange-500/30">+</span></button></div>
	
	</div></div>
				</div></div>

	<div class="mt-4 flex flex-col ml-2"><div class="border-l pl-1 xl:pl-2">







<div id="68fab1894f42f6839d809265" class="scroll-mt-4 "><div class="flex h-10 items-center justify-between gap-1 px-3 "><div class="flex max-w-full items-center overflow-hidden">

<span class="inline-block "><span class="contents"><div class="mr-2 flex shrink-0 items-center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6zJ4RDYmlhX4Sev1Lw8Em.png" alt="" class="mr-2 select-none h-3.5 w-3.5 rounded-full" loading="lazy">
						<a class="whitespace-nowrap font-semibold hover:underline " href="/doladoo">doladoo</a></div></span>
	</span>
				
				
				
				
				
			<a href="#68fab1894f42f6839d809265" class="truncate text-xs text-gray-400 hover:underline sm:text-sm"><time datetime="2025-10-23T22:51:53" title="Thu, 23 Oct 2025 22:51:53 GMT">7 days ago</time></a>
			<div class="mx-1 text-xs text-gray-300 lg:mx-2">•</div>
				<a class="flex-1 truncate text-xs text-gray-400 hover:underline sm:text-sm" title="Edited by doladoo" href="#68fab1894f42f6839d809265">edited 7 days ago</a>
			</div>
		<div class="flex items-center space-x-2">
				<div class="relative flex items-center">
	<button class="text-gray-500 focus:text-gray-900 dark:focus:text-gray-400 " type="button">
		
						<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><circle cx="16" cy="7" r="3" fill="currentColor"></circle><circle cx="16" cy="16" r="3" fill="currentColor"></circle><circle cx="16" cy="25" r="3" fill="currentColor"></circle></svg>
					
		</button>
	
	
	</div></div></div>

	<div class="break-words rounded-b-lg bg-white px-3.5 pb-2.5 pt-1"><div class="prose text-smd/6 sm:text-base/[1.6rem] prose-card hf-sanitized copiable-code-container">
	<!-- HTML_TAG_START --><p>Which VLM did you test ?</p>
<!-- HTML_TAG_END --></div>

			

			<div class="mt-3 flex items-center gap-2">
				<div class="peer-first:mt-2! -ml-1 flex gap-y-1.5 space-x-1 overflow-hidden text-sm"><div class="scrollbar-hidden mr-1 flex select-none gap-x-1 overflow-x-auto overflow-y-hidden text-sm"></div>


					





<div><div class="flex" slot="anchor"><button class="group z-10 select-none"><span class="group relative flex aspect-1 size-7 flex-none select-none items-center justify-center rounded-full border-none text-lg leading-none text-gray-500/80 ring-1 ring-inset ring-gray-100 hover:bg-gray-100 hover:text-gray-700 active:ring-gray-300 dark:ring-gray-800 dark:hover:bg-gray-900 dark:hover:text-yellow-500 dark:active:ring-orange-500/30"><svg class="size-5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M12.33 2.74c1.49.07 2.88.5 4.1 1.19h-.14c-.65 0-1.24.23-1.7.61A7.93 7.93 0 0 0 3.91 12a7.94 7.94 0 0 0 15.89.07c.5-.13.96-.4 1.3-.77.02.23.03.46.03.7l-.01.48a9.28 9.28 0 0 1-9.26 8.8l-.48-.02a9.28 9.28 0 0 1-8.79-8.78V12a9.28 9.28 0 0 1 9.27-9.27h.47Zm-.52 10.24c2.3 0 4.17-2.17 4.17.13a4.17 4.17 0 0 1-8.34 0c0-2.3 1.87-.13 4.17-.13ZM9.53 8.24a1.09 1.09 0 1 1 0 2.17 1.09 1.09 0 0 1 0-2.17Zm4.66 0a1.09 1.09 0 1 1 0 2.18 1.09 1.09 0 0 1 0-2.18Zm4.95-5.38c.48 0 .87.4.87.87v2.02h2a.87.87 0 0 1 0 1.74h-2V9.5a.87.87 0 0 1-1.73 0V7.49h-2a.87.87 0 0 1 0-1.74h2V3.73c0-.48.39-.86.86-.87Z" fill="currentColor"></path></svg></span></button></div>
	
	</div></div>
				</div></div>

	

	

</div>
					</div>
				<button class="inline-flex h-10 items-center gap-1 text-sm text-gray-500 underline decoration-gray-200 underline-offset-2 hover:decoration-gray-400 dark:decoration-gray-600 dark:hover:decoration-gray-400"><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M22 16L12 26l-1.4-1.4l8.6-8.6l-8.6-8.6L12 6z" fill="currentColor"></path></svg> Expand 4
						replies</button>
				<div class="mx-2 mt-1"><input type="text" class="form-input w-full cursor-pointer py-1.5" placeholder="Reply in thread"></div></div>

		

	

</div></div>
		</div>

		<div class="relative">

			

			<div class="relative pt-3! pb-3">







<div id="68fa8244c7b83d1cd1d57a66" class="scroll-mt-4 "><div class="flex h-10 items-center justify-between gap-1 px-3 "><div class="flex max-w-full items-center overflow-hidden">

<span class="inline-block "><span class="contents"><div class="mr-2 flex shrink-0 items-center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/630904f2c038bf42d56d9d11/S8mYgFpPSHYOiifBnNfwG.jpeg" alt="" class="mr-2 select-none h-3.5 w-3.5 rounded-full" loading="lazy">
						<a class="whitespace-nowrap font-semibold hover:underline " href="/harpreetsahota">harpreetsahota</a></div></span>
	</span>
				
				
				
				
				
			<a href="#68fa8244c7b83d1cd1d57a66" class="truncate text-xs text-gray-400 hover:underline sm:text-sm"><time datetime="2025-10-23T19:30:12" title="Thu, 23 Oct 2025 19:30:12 GMT">7 days ago</time></a>
			
			</div>
		<div class="flex items-center space-x-2">
				<div class="relative flex items-center">
	<button class="text-gray-500 focus:text-gray-900 dark:focus:text-gray-400 " type="button">
		
						<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><circle cx="16" cy="7" r="3" fill="currentColor"></circle><circle cx="16" cy="16" r="3" fill="currentColor"></circle><circle cx="16" cy="25" r="3" fill="currentColor"></circle></svg>
					
		</button>
	
	
	</div></div></div>

	<div class="break-words rounded-b-lg bg-white px-3.5 pb-2.5 pt-1"><div class="prose text-smd/6 sm:text-base/[1.6rem] prose-card hf-sanitized copiable-code-container">
	<!-- HTML_TAG_START --><p>Great summary! Don't forget, DeepSeek OCR also supports grounding OCR!</p>
<!-- HTML_TAG_END --></div>

			

			<div class="mt-3 flex items-center gap-2">
				<div class="peer-first:mt-2! -ml-1 flex gap-y-1.5 space-x-1 overflow-hidden text-sm"><div class="scrollbar-hidden mr-1 flex select-none gap-x-1 overflow-x-auto overflow-y-hidden text-sm"><div>

<span class="inline-block "><span class="contents"><button slot="anchor" class="bg-linear-to-r group relative flex h-[28px] flex-none items-center rounded-full border-none px-2 leading-none ring-1 ring-inset shadow-xs from-gray-50 to-transparent text-gray-500 ring-gray-100 hover:bg-gray-100 dark:bg-gray-900 dark:from-gray-950 dark:to-transparent dark:ring-gray-800 dark:hover:bg-gray-800"><div class="mr-2 text-[0.9rem]">❤️</div>
					<div class="invisible">1</div>
					<div class="absolute right-2">1
						</div>
				</button></span>
	</span>
		</div></div>


					





<div><div class="flex" slot="anchor"><button class="group z-10 select-none"><span class="group relative flex aspect-1 size-7 flex-none select-none items-center justify-center rounded-full border-none text-lg leading-none text-gray-500/80 ring-1 ring-inset ring-gray-100 hover:bg-gray-100 hover:text-gray-700 active:ring-gray-300 dark:ring-gray-800 dark:hover:bg-gray-900 dark:hover:text-yellow-500 dark:active:ring-orange-500/30">+</span></button></div>
	
	</div></div>
				<div class="ml-auto"><button class="shadow-xs ml-1.5 flex items-center gap-1.5 rounded-md border px-2 py-1 text-sm leading-none text-gray-500 hover:bg-gray-50 hover:text-gray-700 hover:shadow-inner dark:border-gray-800 dark:hover:bg-gray-900 dark:hover:text-gray-200"><svg class="text-[.7rem]" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 117 109" preserveAspectRatio="xMidYMid meet"><path d="M46.8457 0.686121C49.4736 1.92691 51.1875 4.72478 51.1875 7.79027V23.361H76.7812C98.993 23.361 117 42.5325 117 66.1805C117 93.7456 98.376 106.056 94.1027 108.538C93.5314 108.878 92.8916 109 92.2518 109C89.7609 109 87.75 106.835 87.75 104.207C87.75 102.382 88.7326 100.704 89.9895 99.4629C92.1375 97.322 95.0625 93.04 95.0625 85.6682C95.0625 72.7737 85.2363 62.3122 73.125 62.3122H51.1875V77.8829C51.1875 80.9484 49.4965 83.7462 46.8457 84.987C44.1949 86.2278 41.1328 85.7169 38.9848 83.6732L2.42227 48.6391C0.891211 47.1307 0 45.0384 0 42.8244C0 40.6104 0.891211 38.5181 2.42227 37.034L38.9848 1.9999C41.1328 -0.068086 44.2178 -0.579001 46.8457 0.686121Z" fill="currentColor"></path></svg>Reply</button></div></div></div>

	

		

	

</div></div>
		</div>

		<div class="relative">

			

			<div class="relative pt-3! pb-3">







<div id="68fed65d297f9e82c44040cb" class="scroll-mt-4 "><div class="flex h-10 items-center justify-between gap-1 px-3 "><div class="flex max-w-full items-center overflow-hidden">

<span class="inline-block "><span class="contents"><div class="mr-2 flex shrink-0 items-center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/CSpl8hvY6WTVTxo6Nxtim.png" alt="" class="mr-2 select-none h-3.5 w-3.5 rounded-full" loading="lazy">
						<a class="whitespace-nowrap font-semibold hover:underline " href="/janus-zheng-sg">janus-zheng-sg</a></div></span>
	</span>
				
				
				
				
				
			<a href="#68fed65d297f9e82c44040cb" class="truncate text-xs text-gray-400 hover:underline sm:text-sm"><time datetime="2025-10-27T02:18:05" title="Mon, 27 Oct 2025 02:18:05 GMT">3 days ago</time></a>
			
			</div>
		<div class="flex items-center space-x-2">
				<div class="relative flex items-center">
	<button class="text-gray-500 focus:text-gray-900 dark:focus:text-gray-400 " type="button">
		
						<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><circle cx="16" cy="7" r="3" fill="currentColor"></circle><circle cx="16" cy="16" r="3" fill="currentColor"></circle><circle cx="16" cy="25" r="3" fill="currentColor"></circle></svg>
					
		</button>
	
	
	</div></div></div>

	<div class="break-words rounded-b-lg bg-white px-3.5 pb-2.5 pt-1"><div class="prose text-smd/6 sm:text-base/[1.6rem] prose-card hf-sanitized copiable-code-container">
	<!-- HTML_TAG_START --><p>wondering why minerU 2.5 model was not included in the comparison? <a href="https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B">MinerU2.5-2509-1.2B</a> </p>
<!-- HTML_TAG_END --></div>

			

			<div class="mt-3 flex items-center gap-2">
				<div class="peer-first:mt-2! -ml-1 flex gap-y-1.5 space-x-1 overflow-hidden text-sm"><div class="scrollbar-hidden mr-1 flex select-none gap-x-1 overflow-x-auto overflow-y-hidden text-sm"></div>


					





<div><div class="flex" slot="anchor"><button class="group z-10 select-none"><span class="group relative flex aspect-1 size-7 flex-none select-none items-center justify-center rounded-full border-none text-lg leading-none text-gray-500/80 ring-1 ring-inset ring-gray-100 hover:bg-gray-100 hover:text-gray-700 active:ring-gray-300 dark:ring-gray-800 dark:hover:bg-gray-900 dark:hover:text-yellow-500 dark:active:ring-orange-500/30"><svg class="size-5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M12.33 2.74c1.49.07 2.88.5 4.1 1.19h-.14c-.65 0-1.24.23-1.7.61A7.93 7.93 0 0 0 3.91 12a7.94 7.94 0 0 0 15.89.07c.5-.13.96-.4 1.3-.77.02.23.03.46.03.7l-.01.48a9.28 9.28 0 0 1-9.26 8.8l-.48-.02a9.28 9.28 0 0 1-8.79-8.78V12a9.28 9.28 0 0 1 9.27-9.27h.47Zm-.52 10.24c2.3 0 4.17-2.17 4.17.13a4.17 4.17 0 0 1-8.34 0c0-2.3 1.87-.13 4.17-.13ZM9.53 8.24a1.09 1.09 0 1 1 0 2.17 1.09 1.09 0 0 1 0-2.17Zm4.66 0a1.09 1.09 0 1 1 0 2.18 1.09 1.09 0 0 1 0-2.18Zm4.95-5.38c.48 0 .87.4.87.87v2.02h2a.87.87 0 0 1 0 1.74h-2V9.5a.87.87 0 0 1-1.73 0V7.49h-2a.87.87 0 0 1 0-1.74h2V3.73c0-.48.39-.86.86-.87Z" fill="currentColor"></path></svg></span></button></div>
	
	</div></div>
				<div class="ml-auto"><button class="shadow-xs ml-1.5 flex items-center gap-1.5 rounded-md border px-2 py-1 text-sm leading-none text-gray-500 hover:bg-gray-50 hover:text-gray-700 hover:shadow-inner dark:border-gray-800 dark:hover:bg-gray-900 dark:hover:text-gray-200"><svg class="text-[.7rem]" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 117 109" preserveAspectRatio="xMidYMid meet"><path d="M46.8457 0.686121C49.4736 1.92691 51.1875 4.72478 51.1875 7.79027V23.361H76.7812C98.993 23.361 117 42.5325 117 66.1805C117 93.7456 98.376 106.056 94.1027 108.538C93.5314 108.878 92.8916 109 92.2518 109C89.7609 109 87.75 106.835 87.75 104.207C87.75 102.382 88.7326 100.704 89.9895 99.4629C92.1375 97.322 95.0625 93.04 95.0625 85.6682C95.0625 72.7737 85.2363 62.3122 73.125 62.3122H51.1875V77.8829C51.1875 80.9484 49.4965 83.7462 46.8457 84.987C44.1949 86.2278 41.1328 85.7169 38.9848 83.6732L2.42227 48.6391C0.891211 47.1307 0 45.0384 0 42.8244C0 40.6104 0.891211 38.5181 2.42227 37.034L38.9848 1.9999C41.1328 -0.068086 44.2178 -0.579001 46.8457 0.686121Z" fill="currentColor"></path></svg>Reply</button></div></div></div>

	

		

	

</div></div>
		</div>

		<div class="relative">

			

			<div class="relative pt-3! pb-0">







<div id="690075bdada8f1842d8c6e57" class="scroll-mt-4 "><div class="flex h-10 items-center justify-between gap-1 px-3 "><div class="flex max-w-full items-center overflow-hidden">

<span class="inline-block "><span class="contents"><div class="mr-2 flex shrink-0 items-center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/68ff4d7a34025a65430f5d90/Oiy-7WOgfuXGeDMBMnfWw.jpeg" alt="" class="mr-2 select-none h-3.5 w-3.5 rounded-full" loading="lazy">
						<a class="whitespace-nowrap font-semibold hover:underline " href="/daya-shankar">daya-shankar</a></div></span>
	</span>
				
				
				
				
				
			<a href="#690075bdada8f1842d8c6e57" class="truncate text-xs text-gray-400 hover:underline sm:text-sm"><time datetime="2025-10-28T07:50:21" title="Tue, 28 Oct 2025 07:50:21 GMT">2 days ago</time></a>
			
			</div>
		<div class="flex items-center space-x-2">
				<div class="relative flex items-center">
	<button class="text-gray-500 focus:text-gray-900 dark:focus:text-gray-400 " type="button">
		
						<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><circle cx="16" cy="7" r="3" fill="currentColor"></circle><circle cx="16" cy="16" r="3" fill="currentColor"></circle><circle cx="16" cy="25" r="3" fill="currentColor"></circle></svg>
					
		</button>
	
	
	</div></div></div>

	<div class="break-words rounded-b-lg bg-white px-3.5 pb-2.5 pt-1"><div class="prose text-smd/6 sm:text-base/[1.6rem] prose-card hf-sanitized copiable-code-container">
	<!-- HTML_TAG_START --><p>Super helpful breakdown. The layout-awareness and cost benefits really stand out. Thanks for sharing!</p>
<!-- HTML_TAG_END --></div>

			

			<div class="mt-3 flex items-center gap-2">
				<div class="peer-first:mt-2! -ml-1 flex gap-y-1.5 space-x-1 overflow-hidden text-sm"><div class="scrollbar-hidden mr-1 flex select-none gap-x-1 overflow-x-auto overflow-y-hidden text-sm"><div>

<span class="inline-block "><span class="contents"><button slot="anchor" class="bg-linear-to-r group relative flex h-[28px] flex-none items-center rounded-full border-none px-2 leading-none ring-1 ring-inset shadow-xs from-gray-50 to-transparent text-gray-500 ring-gray-100 hover:bg-gray-100 dark:bg-gray-900 dark:from-gray-950 dark:to-transparent dark:ring-gray-800 dark:hover:bg-gray-800"><div class="mr-2 text-[0.9rem]">🔥</div>
					<div class="invisible">1</div>
					<div class="absolute right-2">1
						</div>
				</button></span>
	</span>
		</div></div>


					





<div><div class="flex" slot="anchor"><button class="group z-10 select-none"><span class="group relative flex aspect-1 size-7 flex-none select-none items-center justify-center rounded-full border-none text-lg leading-none text-gray-500/80 ring-1 ring-inset ring-gray-100 hover:bg-gray-100 hover:text-gray-700 active:ring-gray-300 dark:ring-gray-800 dark:hover:bg-gray-900 dark:hover:text-yellow-500 dark:active:ring-orange-500/30">+</span></button></div>
	
	</div></div>
				<div class="ml-auto"><button class="shadow-xs ml-1.5 flex items-center gap-1.5 rounded-md border px-2 py-1 text-sm leading-none text-gray-500 hover:bg-gray-50 hover:text-gray-700 hover:shadow-inner dark:border-gray-800 dark:hover:bg-gray-900 dark:hover:text-gray-200"><svg class="text-[.7rem]" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 117 109" preserveAspectRatio="xMidYMid meet"><path d="M46.8457 0.686121C49.4736 1.92691 51.1875 4.72478 51.1875 7.79027V23.361H76.7812C98.993 23.361 117 42.5325 117 66.1805C117 93.7456 98.376 106.056 94.1027 108.538C93.5314 108.878 92.8916 109 92.2518 109C89.7609 109 87.75 106.835 87.75 104.207C87.75 102.382 88.7326 100.704 89.9895 99.4629C92.1375 97.322 95.0625 93.04 95.0625 85.6682C95.0625 72.7737 85.2363 62.3122 73.125 62.3122H51.1875V77.8829C51.1875 80.9484 49.4965 83.7462 46.8457 84.987C44.1949 86.2278 41.1328 85.7169 38.9848 83.6732L2.42227 48.6391C0.891211 47.1307 0 45.0384 0 42.8244C0 40.6104 0.891211 38.5181 2.42227 37.034L38.9848 1.9999C41.1328 -0.068086 44.2178 -0.579001 46.8457 0.686121Z" fill="currentColor"></path></svg>Reply</button></div></div></div>

	

		

	

</div></div>
		</div></div>

<div class="overflow-hidden rounded-lg border border-gray-200 bg-white  rounded-b-none border-b-0 mt-6"><div class="flex h-9 items-center justify-between border-b border-gray-200 from-gray-100-to-white bg-linear-to-t"><div class="flex h-full items-stretch"><button class="tab active" type="button">Edit</button><button class="tab " type="button">Preview</button></div>
	<div></div></div>
	<div class="p-4">

<div class="contents">

<div class="contents"><textarea class="form-input peer relative !mt-0 min-h-[140px] w-full resize-none overflow-y-hidden !rounded-b-none !border-b-0 px-3 pb-3 pt-2 " name="comment" placeholder="Start discussing this article" required disabled rows="3"></textarea>

	</div>

	</div>
		<label class="border-t-1 flex cursor-default items-center rounded-b-lg border-b-2 border-l-2 border-r-2 border-gray-200 px-2.5 py-1.5 text-sm text-gray-400 shadow-sm cursor-not-allowed opacity-70"><svg class="flex-none text-sm mr-1.5 text-gray-300 dark:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path fill="currentColor" d="M19 2H5a3.009 3.009 0 0 0-3 3v8.86l3.88-3.88a3.075 3.075 0 0 1 4.24 0l2.871 2.887l.888-.888a3.008 3.008 0 0 1 4.242 0L22 15.86V5a3.009 3.009 0 0 0-3-3z" opacity=".5"></path><path fill="currentColor" d="M10.12 9.98a3.075 3.075 0 0 0-4.24 0L2 13.86V19a3.009 3.009 0 0 0 3 3h14a3 3 0 0 0 2.16-.92L10.12 9.98z"></path><path fill="currentColor" d="m22 15.858l-3.879-3.879a3.008 3.008 0 0 0-4.242 0l-.888.888l8.165 8.209c.542-.555.845-1.3.844-2.076v-3.142z" opacity=".25"></path></svg>
			<div class="hidden md:block">Upload images, audio, and videos by dragging in the text input, pasting, or <span class="cursor-pointer underline">clicking here</span>.
			</div>
			<div class="md:hidden">Tap or paste here to upload images</div>
			<input accept="image/png, image/jpeg, image/gif, image/webp, video/mp4, video/quicktime, video/webm, audio/mpeg, audio/wav" class="hidden" disabled type="file" multiple></label></div>
	

	</div>
<div class="mb-4 overflow-hidden rounded-lg rounded-t-none border border-gray-200"><div class="p-4">

		

		

		<div class="flex flex-col space-y-2 md:flex-row md:items-center md:space-x-2 md:space-y-0"><button class="btn btn-large" disabled><svg class="text-gray-400 mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-primary" d="M17 13H7a1 1 0 0 1 0-2h10a1 1 0 0 1 0 2z" fill="currentColor"></path><path class="uim-tertiary" d="M12 2a10 10 0 0 0-7.743 16.33l-1.964 1.963A1 1 0 0 0 3 22h9a10 10 0 0 0 0-20zM9 7h6a1 1 0 0 1 0 2H9a1 1 0 0 1 0-2zm6 10H9a1 1 0 0 1 0-2h6a1 1 0 0 1 0 2zm2-4H7a1 1 0 0 1 0-2h10a1 1 0 0 1 0 2z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M15 17H9a1 1 0 0 1 0-2h6a1 1 0 0 1 0 2zm0-8H9a1 1 0 0 1 0-2h6a1 1 0 0 1 0 2z" fill="currentColor"></path></svg>
				Comment
			</button>

			<p class="py-1 text-gray-800"><span class="ml-2 mr-3.5 hidden text-gray-400 md:inline">·</span>
					<a class="underline hover:text-gray-500" href="/join?next=%2Fblog%2Focr-open-models">Sign up</a> or
					<a class="underline hover:text-gray-500" href="/login?next=%2Fblog%2Focr-open-models">log in</a> to comment
				</p></div></div></div></div></div></div>
		<div class="w-56 flex-none pt-28 max-lg:hidden"><div class="SVELTE_HYDRATER contents" data-target="UpvoteControl" data-props="{&quot;classNames&quot;:&quot;lg:max-w-60 lg:flex-col lg:items-start!&quot;,&quot;maxShown&quot;:12,&quot;apiUrlPrefix&quot;:&quot;/api/blog/ocr-open-models&quot;,&quot;postLoginRedirectUrl&quot;:&quot;/blog/ocr-open-models&quot;,&quot;style&quot;:&quot;horizontal&quot;,&quot;color&quot;:&quot;gray&quot;,&quot;upvotedColor&quot;:&quot;orange&quot;,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;_id&quot;:&quot;5df82bcada6d0311fd3d5402&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1589104979708-5df82bcada6d0311fd3d5402.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Chuanming Liu&quot;,&quot;user&quot;:&quot;Chuanming&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5e4318d616b09a31220980d6&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;Manuel Romero&quot;,&quot;user&quot;:&quot;mrm8488&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5e6a3d4ea9afd5125d9ec064&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1584020801691-noauth.jpeg&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;Stefan Schweter&quot;,&quot;user&quot;:&quot;stefan-it&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5ee3a7cd2a3eae3cbdad1305&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1594144055859-5ee3a7cd2a3eae3cbdad1305.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Yacine Jernite&quot;,&quot;user&quot;:&quot;yjernite&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f106ce5348d4c7346cd19ab&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f106ce5348d4c7346cd19ab/Uu08yZZlFuj3dtG4wld3n.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Abdullah Abdelrhim&quot;,&quot;user&quot;:&quot;abdullah&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f1ba750cb8f993fa01f4678&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f1ba750cb8f993fa01f4678/4-dAcvedO-tIxYJm6aLTL.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Behrooz Azarkhalili&quot;,&quot;user&quot;:&quot;ermiaazarkhalili&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f3cfe71a4dd343b63a63130&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f3cfe71a4dd343b63a63130/eNIOy863HpZfj2OZf9mUB.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Ahmed Khalil Boulahia&quot;,&quot;user&quot;:&quot;AhmedBou&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f4066e079c1ba4c353d0c75&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1654555959564-5f4066e079c1ba4c353d0c75.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Snehal&quot;,&quot;user&quot;:&quot;spate141&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f43448a79c1ba4c353d0d8f&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/5f43448a79c1ba4c353d0d8f/DiSygV3dn7A_OjmGVTrHD.jpeg&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;Sugato Ray&quot;,&quot;user&quot;:&quot;sugatoray&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f82373af0801648bf88447d&quot;,&quot;avatarUrl&quot;:&quot;/avatars/01c93f7de113cdb34ef3e7012c915ade.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Eugene Girtcius&quot;,&quot;user&quot;:&quot;girtcius&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f93087acf95e81b6854e184&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1645260898596-5f93087acf95e81b6854e184.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Sławomir Dadas&quot;,&quot;user&quot;:&quot;sdadas&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;5f97802bcf95e81b6854e335&quot;,&quot;avatarUrl&quot;:&quot;/avatars/f902e784de4f8ae1f5742292baf6fc65.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Daryl Maeda&quot;,&quot;user&quot;:&quot;djmaeda&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;upvotes&quot;:212}"><div class="flex flex-wrap items-center gap-2.5 pt-1 lg:max-w-60 lg:flex-col lg:items-start! z-1 lg:sticky lg:top-8"><a href="/login?next=%2Fblog%2Focr-open-models" class="self-start">
	<div class="shadow-alternate group flex h-9 cursor-pointer select-none items-center gap-2 rounded-lg border pl-3 pr-3.5 border-gray-300 bg-white dark:bg-gray-850 "><input disabled type="checkbox"  class="peer hidden">
		<svg class="text-xs text-gray-500 peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg>
		Upvote

		<div class="font-semibold text-orange-500">212</div></div>

</a>
	<ul class="flex items-center  flex-row  text-base   "><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="Chuanming" style="content-visibility:auto;"><a href="/Chuanming" title="Chuanming"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1589104979708-5df82bcada6d0311fd3d5402.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="mrm8488" style="content-visibility:auto;"><a href="/mrm8488" title="mrm8488"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="stefan-it" style="content-visibility:auto;"><a href="/stefan-it" title="stefan-it"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1584020801691-noauth.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="yjernite" style="content-visibility:auto;"><a href="/yjernite" title="yjernite"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1594144055859-5ee3a7cd2a3eae3cbdad1305.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="abdullah" style="content-visibility:auto;"><a href="/abdullah" title="abdullah"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5f106ce5348d4c7346cd19ab/Uu08yZZlFuj3dtG4wld3n.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="ermiaazarkhalili" style="content-visibility:auto;"><a href="/ermiaazarkhalili" title="ermiaazarkhalili"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5f1ba750cb8f993fa01f4678/4-dAcvedO-tIxYJm6aLTL.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="AhmedBou" style="content-visibility:auto;"><a href="/AhmedBou" title="AhmedBou"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5f3cfe71a4dd343b63a63130/eNIOy863HpZfj2OZf9mUB.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="spate141" style="content-visibility:auto;"><a href="/spate141" title="spate141"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1654555959564-5f4066e079c1ba4c353d0c75.png" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sugatoray" style="content-visibility:auto;"><a href="/sugatoray" title="sugatoray"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/5f43448a79c1ba4c353d0d8f/DiSygV3dn7A_OjmGVTrHD.jpeg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="girtcius" style="content-visibility:auto;"><a href="/girtcius" title="girtcius"><img class="overflow-hidden rounded-full" alt="" src="/avatars/01c93f7de113cdb34ef3e7012c915ade.svg" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sdadas" style="content-visibility:auto;"><a href="/sdadas" title="sdadas"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1645260898596-5f93087acf95e81b6854e184.png" loading="lazy">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="djmaeda" style="content-visibility:auto;"><a href="/djmaeda" title="djmaeda"><img class="overflow-hidden rounded-full" alt="" src="/avatars/f902e784de4f8ae1f5742292baf6fc65.svg" loading="lazy">
					</a>
			</li>

		<li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"><button class="btn bg-linear-to-br -ml-3 translate-x-px rounded-full border-2 border-white px-1.5 py-0.5 text-xs">+200</button></li></ul></div>



</div></div></div></main>

	<footer class="b-12 mb-2 flex border-t border-gray-100 md:h-14"><nav class="container relative flex flex-col justify-between space-y-2 py-6 text-gray-500 max-md:*:self-start md:flex-row md:items-center md:space-y-0 md:py-0 md:text-sm"><div class="SVELTE_HYDRATER contents" data-target="ThemeSwitcher" data-props="{&quot;theme&quot;:&quot;system&quot;,&quot;isLoggedIn&quot;:false,&quot;menuClassNames&quot;:&quot;md:-top-24&quot;,&quot;classNames&quot;:&quot;max-md:mb-5 max-md:*:self-start&quot;}">
<div class="relative inline-block max-md:mb-5 max-md:*:self-start">
	<button class="rounded-full border border-gray-100 pl-2 py-1 pr-2.5  flex items-center text-sm text-gray-500 bg-white hover:bg-purple-50 hover:border-purple-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 dark:border-gray-800 " type="button">
		<svg class="mr-1.5 text-gray-500" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M29 25H3a1 1 0 1 0 0 2h26a1 1 0 1 0 0-2Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6 22.5h20a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2H6a2 2 0 0 0-2 2v13.5a2 2 0 0 0 2 2ZM7 7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h18a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1H7Z" fill="currentColor"></path><path d="M6 8a1 1 0 0 1 1-1h18a1 1 0 0 1 1 1v11a1 1 0 0 1-1 1H7a1 1 0 0 1-1-1V8Z" fill="currentColor" fill-opacity=".4"></path><path d="M29 25H3a1 1 0 1 0 0 2h26a1 1 0 1 0 0-2Z" fill="currentColor"></path></svg>
			System theme
		</button>
	
	
	</div></div>
		<div class="font-semibold text-black md:hidden">Company</div>
		<a class="hover:underline" href="/terms-of-service">TOS</a>
		<a class="hover:underline" href="/privacy">Privacy</a>
		<a class="hover:underline" href="/huggingface">About</a>
		<a class="hover:underline" href="https://apply.workable.com/huggingface/">Jobs</a>
		<a href="/" class="max-md:mb-4! max-md:mt-8! group flex-none max-md:order-last" aria-label="Hugging Face"><svg class="h-7 w-7 transition-transform group-hover:-translate-y-px" viewBox="0 0 95 88" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5Z" fill="#FFD21E"></path><path d="M81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75ZM8.46185 41.75C8.46185 20.349 25.8108 3 47.2119 3C68.6129 3 85.9619 20.349 85.9619 41.75C85.9619 63.151 68.6129 80.5 47.2119 80.5C25.8108 80.5 8.46185 63.151 8.46185 41.75Z" fill="#FF9D0B"></path><path d="M58.5024 32.2915C59.7768 32.7415 60.2839 35.3615 61.5713 34.6769C64.0095 33.3805 64.9351 30.353 63.6387 27.9148C62.3423 25.4767 59.3148 24.5511 56.8766 25.8475C54.4384 27.1439 53.5128 30.1714 54.8092 32.6096C55.4211 33.7604 57.3632 31.8892 58.5024 32.2915Z" fill="#3A3B45"></path><path d="M34.9454 32.2915C33.671 32.7415 33.164 35.3615 31.8766 34.6769C29.4384 33.3805 28.5128 30.353 29.8092 27.9148C31.1056 25.4767 34.1331 24.5511 36.5713 25.8475C39.0095 27.1439 39.9351 30.1714 38.6387 32.6096C38.0268 33.7604 36.0846 31.8892 34.9454 32.2915Z" fill="#3A3B45"></path><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="#3A3B45"></path><mask id="mask0" style="mask-type:alpha" maskUnits="userSpaceOnUse" x="33" y="41" width="27" height="16"><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="white"></path></mask><g mask="url(#mask0)"><path d="M47.2119 66.5C52.0018 66.5 55.8848 62.617 55.8848 57.8271C55.8848 54.0962 53.5291 50.9156 50.224 49.6915C50.1023 49.6464 49.9794 49.604 49.8553 49.5643C49.0219 49.2979 48.1337 52.1623 47.2119 52.1623C46.3506 52.1623 45.5186 49.2797 44.7332 49.5135C41.151 50.5799 38.5389 53.8984 38.5389 57.8271C38.5389 62.617 42.4219 66.5 47.2119 66.5Z" fill="#F94040"></path></g><path d="M70.7119 37C72.5068 37 73.9619 35.5449 73.9619 33.75C73.9619 31.9551 72.5068 30.5 70.7119 30.5C68.9169 30.5 67.4619 31.9551 67.4619 33.75C67.4619 35.5449 68.9169 37 70.7119 37Z" fill="#FF9D0B"></path><path d="M24.2119 37C26.0068 37 27.4619 35.5449 27.4619 33.75C27.4619 31.9551 26.0068 30.5 24.2119 30.5C22.4169 30.5 20.9619 31.9551 20.9619 33.75C20.9619 35.5449 22.4169 37 24.2119 37Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M17.5238 48C15.9048 48 14.4578 48.665 13.4488 49.871C12.8248 50.618 12.1728 51.822 12.1198 53.625C11.4408 53.43 10.7878 53.321 10.1778 53.321C8.6278 53.321 7.2278 53.915 6.2378 54.994C4.9658 56.379 4.4008 58.081 4.6468 59.784C4.7638 60.595 5.0348 61.322 5.4398 61.995C4.5858 62.686 3.9568 63.648 3.6528 64.805C3.4148 65.712 3.1708 67.601 4.4448 69.547C4.3638 69.674 4.2878 69.806 4.2168 69.941C3.4508 71.395 3.4018 73.038 4.0778 74.568C5.1028 76.887 7.6498 78.714 12.5958 80.675C15.6728 81.895 18.4878 82.675 18.5128 82.682C22.5808 83.737 26.2598 84.273 29.4448 84.273C35.2988 84.273 39.4898 82.48 41.9018 78.944C45.7838 73.25 45.2288 68.042 40.2058 63.022C37.4258 60.244 35.5778 56.148 35.1928 55.249C34.4168 52.587 32.3648 49.628 28.9538 49.628H28.9528C28.6658 49.628 28.3758 49.651 28.0898 49.696C26.5958 49.931 25.2898 50.791 24.3568 52.085C23.3498 50.833 22.3718 49.837 21.4868 49.275C20.1528 48.429 18.8198 48 17.5238 48ZM17.5238 52C18.0338 52 18.6568 52.217 19.3438 52.653C21.4768 54.006 25.5928 61.081 27.0998 63.833C27.6048 64.755 28.4678 65.145 29.2448 65.145C30.7868 65.145 31.9908 63.612 29.3858 61.664C25.4688 58.733 26.8428 53.942 28.7128 53.647C28.7948 53.634 28.8758 53.628 28.9538 53.628C30.6538 53.628 31.4038 56.558 31.4038 56.558C31.4038 56.558 33.6018 62.078 37.3778 65.851C41.1538 69.625 41.3488 72.654 38.5968 76.69C36.7198 79.442 33.1268 80.273 29.4448 80.273C25.6258 80.273 21.7108 79.379 19.5168 78.81C19.4088 78.782 6.0658 75.013 7.7558 71.805C8.0398 71.266 8.5078 71.05 9.0968 71.05C11.4768 71.05 15.8058 74.592 17.6668 74.592C18.0828 74.592 18.3758 74.415 18.4958 73.983C19.2888 71.138 6.4388 69.942 7.5218 65.821C7.7128 65.092 8.2308 64.796 8.9588 64.797C12.1038 64.797 19.1598 70.328 20.6388 70.328C20.7518 70.328 20.8328 70.295 20.8768 70.225C21.6178 69.029 21.2118 68.194 15.9888 65.033C10.7658 61.871 7.0998 59.969 9.1848 57.699C9.4248 57.437 9.7648 57.321 10.1778 57.321C13.3488 57.322 20.8408 64.14 20.8408 64.14C20.8408 64.14 22.8628 66.243 24.0858 66.243C24.3668 66.243 24.6058 66.132 24.7678 65.858C25.6348 64.396 16.7148 57.636 16.2118 54.847C15.8708 52.957 16.4508 52 17.5238 52Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M38.5967 76.6898C41.3487 72.6538 41.1537 69.6248 37.3777 65.8508C33.6017 62.0778 31.4037 56.5578 31.4037 56.5578C31.4037 56.5578 30.5827 53.3518 28.7127 53.6468C26.8427 53.9418 25.4697 58.7328 29.3867 61.6638C33.3037 64.5938 28.6067 66.5848 27.0997 63.8328C25.5927 61.0808 21.4777 54.0058 19.3437 52.6528C17.2107 51.2998 15.7087 52.0578 16.2117 54.8468C16.7147 57.6358 25.6357 64.3958 24.7677 65.8588C23.8997 67.3208 20.8407 64.1398 20.8407 64.1398C20.8407 64.1398 11.2687 55.4288 9.18465 57.6988C7.10065 59.9688 10.7657 61.8708 15.9887 65.0328C21.2127 68.1938 21.6177 69.0288 20.8767 70.2248C20.1347 71.4208 8.60465 61.6998 7.52165 65.8208C6.43965 69.9418 19.2887 71.1378 18.4957 73.9828C17.7027 76.8288 9.44465 68.5978 7.75565 71.8048C6.06565 75.0128 19.4087 78.7818 19.5167 78.8098C23.8267 79.9278 34.7727 82.2968 38.5967 76.6898Z" fill="#FFD21E"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M77.3999 48C79.0189 48 80.4659 48.665 81.4749 49.871C82.0989 50.618 82.7509 51.822 82.8039 53.625C83.4829 53.43 84.1359 53.321 84.7459 53.321C86.2959 53.321 87.6959 53.915 88.6859 54.994C89.9579 56.379 90.5229 58.081 90.2769 59.784C90.1599 60.595 89.8889 61.322 89.4839 61.995C90.3379 62.686 90.9669 63.648 91.2709 64.805C91.5089 65.712 91.7529 67.601 90.4789 69.547C90.5599 69.674 90.6359 69.806 90.7069 69.941C91.4729 71.395 91.5219 73.038 90.8459 74.568C89.8209 76.887 87.2739 78.714 82.3279 80.675C79.2509 81.895 76.4359 82.675 76.4109 82.682C72.3429 83.737 68.6639 84.273 65.4789 84.273C59.6249 84.273 55.4339 82.48 53.0219 78.944C49.1399 73.25 49.6949 68.042 54.7179 63.022C57.4979 60.244 59.3459 56.148 59.7309 55.249C60.5069 52.587 62.5589 49.628 65.9699 49.628H65.9709C66.2579 49.628 66.5479 49.651 66.8339 49.696C68.3279 49.931 69.6339 50.791 70.5669 52.085C71.5739 50.833 72.5519 49.837 73.4369 49.275C74.7709 48.429 76.1039 48 77.3999 48ZM77.3999 52C76.8899 52 76.2669 52.217 75.5799 52.653C73.4469 54.006 69.3309 61.081 67.8239 63.833C67.3189 64.755 66.4559 65.145 65.6789 65.145C64.1369 65.145 62.9329 63.612 65.5379 61.664C69.4549 58.733 68.0809 53.942 66.2109 53.647C66.1289 53.634 66.0479 53.628 65.9699 53.628C64.2699 53.628 63.5199 56.558 63.5199 56.558C63.5199 56.558 61.3219 62.078 57.5459 65.851C53.7699 69.625 53.5749 72.654 56.3269 76.69C58.2039 79.442 61.7969 80.273 65.4789 80.273C69.2979 80.273 73.2129 79.379 75.4069 78.81C75.5149 78.782 88.8579 75.013 87.1679 71.805C86.8839 71.266 86.4159 71.05 85.8269 71.05C83.4469 71.05 79.1179 74.592 77.2569 74.592C76.8409 74.592 76.5479 74.415 76.4279 73.983C75.6349 71.138 88.4849 69.942 87.4019 65.821C87.2109 65.092 86.6929 64.796 85.9649 64.797C82.8199 64.797 75.7639 70.328 74.2849 70.328C74.1719 70.328 74.0909 70.295 74.0469 70.225C73.3059 69.029 73.7119 68.194 78.9349 65.033C84.1579 61.871 87.8239 59.969 85.7389 57.699C85.4989 57.437 85.1589 57.321 84.7459 57.321C81.5749 57.322 74.0829 64.14 74.0829 64.14C74.0829 64.14 72.0609 66.243 70.8379 66.243C70.5569 66.243 70.3179 66.132 70.1559 65.858C69.2889 64.396 78.2089 57.636 78.7119 54.847C79.0529 52.957 78.4729 52 77.3999 52Z" fill="#FF9D0B"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M56.3271 76.6898C53.5751 72.6538 53.7701 69.6248 57.5461 65.8508C61.3221 62.0778 63.5201 56.5578 63.5201 56.5578C63.5201 56.5578 64.3411 53.3518 66.2111 53.6468C68.0811 53.9418 69.4541 58.7328 65.5371 61.6638C61.6201 64.5938 66.3171 66.5848 67.8241 63.8328C69.3311 61.0808 73.4461 54.0058 75.5801 52.6528C77.7131 51.2998 79.2151 52.0578 78.7121 54.8468C78.2091 57.6358 69.2881 64.3958 70.1561 65.8588C71.0241 67.3208 74.0831 64.1398 74.0831 64.1398C74.0831 64.1398 83.6551 55.4288 85.7391 57.6988C87.8231 59.9688 84.1581 61.8708 78.9351 65.0328C73.7111 68.1938 73.3061 69.0288 74.0471 70.2248C74.7891 71.4208 86.3191 61.6998 87.4021 65.8208C88.4841 69.9418 75.6351 71.1378 76.4281 73.9828C77.2211 76.8288 85.4791 68.5978 87.1681 71.8048C88.8581 75.0128 75.5151 78.7818 75.4071 78.8098C71.0971 79.9278 60.1511 82.2968 56.3271 76.6898Z" fill="#FFD21E"></path></svg></a>
		<div class="max-md:mt-8! font-semibold text-black md:hidden">Website</div>

		<a class="hover:underline" href="/models">Models</a>
		<a class="hover:underline" href="/datasets">Datasets</a>
		<a class="hover:underline" href="/spaces">Spaces</a>
		<a class="hover:underline" href="/pricing">Pricing</a>
		<a class="hover:underline" href="/docs">Docs</a></nav></footer></div>
		<script>
			 import("\/front\/build\/kube-aaf1f7b\/index.js"); window.moonSha = "kube-aaf1f7b\/"; window.__hf_deferred =
			{};
		</script>
		 <!-- Stripe -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				const script = document.createElement("script");
				script.src = "https://js.stripe.com/v3/";
				script.async = true;
				document.head.appendChild(script);
			}
		</script>

	</body>

</html>

