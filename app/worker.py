import uuid
import meilisearch
from celery import Celery
import logging
import os
import json
import asyncio

from .config import get_settings
from .pipeline.ocr_module import OCRModule
from .pipeline.classification_module import DocumentClassifier
from .logger_config import setup_logging
from .pipeline.client import LLMClient
from .pipeline import llm_tasks, guards
from qdrant_client import QdrantClient, models

setup_logging()
log = logging.getLogger(__name__)

settings = get_settings()
celery_app = Celery("tasks", broker=settings.REDIS_BROKER_URL, backend=settings.REDIS_BROKER_URL)
meili_client = meilisearch.Client(url=settings.MEILI_HOST_URL)
qdrant_client = QdrantClient(host=settings.QDRANT_HOST, port=settings.QDRANT_PORT)
QDRANT_COLLECTION_NAME = "documents_collection"

log.info("AI ëª¨ë¸(OCR/Classifier)ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•©ë‹ˆë‹¤...")
try:
    ocr_model = OCRModule(lang='en')
    classifier_model = DocumentClassifier()
    MODEL_PATH = os.getenv("MODEL_PATH", "distilbert-base-uncased")

    # --- ğŸš¨ í•«í”½ìŠ¤ 1/2: ëª¨ë¸ ë¡œë“œ ì£¼ì„ ì²˜ë¦¬ ---
    # classifier_model.load_model(MODEL_PATH) # <-- í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ì–´ ì¶©ëŒ ë°œìƒ!
    log.warning(f"!!! í•«í”½ìŠ¤ ì ìš©: classifier_model.load_model({MODEL_PATH}) ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤!!!")
    # --- í•«í”½ìŠ¤ ë ---

    log.info(f"AI ëª¨ë¸ ({MODEL_PATH}) ë¡œë“œ ì™„ë£Œ.")
    log.info("LLM í´ë¼ì´ì–¸íŠ¸ ë° ìŠ¤í‚¤ë§ˆë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    llm_client = LLMClient(model=settings.LLM_MODEL_NAME, base=settings.OLLAMA_BASE_URL)
    invoice_schema = json.loads(llm_tasks.read("app/pipeline/schemas/invoice_v1.json"))
    receipt_schema = json.loads(llm_tasks.read("app/pipeline/schemas/receipt_v1.json"))
    log.info("LLM í´ë¼ì´ì–¸íŠ¸ ë° ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì™„ë£Œ.")
except Exception as e:
    log.error(f"AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
    # í•«í”½ìŠ¤ ê¸°ê°„ì—ëŠ” ë¡œë“œ ì‹¤íŒ¨ê°€ ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ raiseë¥¼ ì£¼ì„ ì²˜ë¦¬
    # raise e


@celery_app.task(
    bind=True,
    autoretry_for=(Exception,),
    retry_kwargs={'max_retries': 3},
    retry_backoff=True,
    retry_backoff_max=60
)
async def process_document(self, filename: str, file_content: bytes):
    doc_id = str(uuid.uuid4())
    log.info(f"'{filename}' (ID: {doc_id}) AI íŒŒì´í”„ë¼ì¸(Phase 2) ì²˜ë¦¬ ì‹œì‘... (ì‹œë„: {self.request.retries + 1})")

    temp_dir = "/tmp/hackathon_uploads"
    os.makedirs(temp_dir, exist_ok=True)
    temp_file_path = os.path.join(temp_dir, f"{doc_id}_{filename}")

    try:
        with open(temp_file_path, "wb") as f:
            f.write(file_content)

        log.info(f"--- 1. PaddleOCR Step Start (ID: {doc_id}) ---")
        ocr_result = ocr_model.extract_text(temp_file_path)
        extracted_text = ocr_result.get('text', '')

        if not extracted_text:
            log.warning(f"'{filename}' (ID: {doc_id}) í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨.")
            return {
                "id": doc_id, "filename": filename, "error": "Failed to extract text (OCR)",
                "classification": {}, "extracted_data": {}, "summary": "", "pii_detected": [],
                "vector_indexed": False
            }

        log.info(f"--- 2. Classification Step Start (ID: {doc_id}) ---")

        # --- ğŸš¨ í•«í”½ìŠ¤ 2/2: ë¶„ë¥˜ê¸° í˜¸ì¶œ ëŒ€ì‹  'unknown'ìœ¼ë¡œ ê³ ì • ---
        # classification_result = classifier_model.classify(extracted_text) # <-- ëª¨ë¸ì´ Noneì´ë¼ ì¶©ëŒ ë°œìƒ!
        log.warning("!!! í•«í”½ìŠ¤ ì ìš©: classifier.classify() ëŒ€ì‹  'unknown' ë°˜í™˜ !!!")
        classification_result = {"doc_type": "unknown", "confidence": 0.0}
        # --- í•«í”½ìŠ¤ ë ---

        doc_type = classification_result.get('doc_type', 'unknown')
        doc_confidence = classification_result.get('confidence', 0.0)
        log.info(f"'{filename}' (ID: {doc_id}) ë¶„ë¥˜ ê²°ê³¼: {doc_type} (ì‹ ë¢°ë„: {doc_confidence:.2%})")

        log.info(f"--- 3a. LLM Extraction Step Start (ID: {doc_id}, Type: {doc_type}) ---")
        extracted_data = {}
        if doc_type == "invoice":
            extracted_data = await llm_tasks.extract_invoice(extracted_text, llm_client, invoice_schema) or {}
        elif doc_type == "receipt":
            extracted_data = await llm_tasks.extract_receipt(extracted_text, llm_client, receipt_schema) or {}
        log.info(f"LLM (ID: {doc_id}) ì¶”ì¶œ ì™„ë£Œ: {extracted_data}")

        log.info(f"--- 3b. LLM Summarization Step Start (ID: {doc_id}) ---")
        summary = await llm_tasks.summarize(extracted_text, llm_client)
        log.info(f"LLM (ID: {doc_id}) ìš”ì•½ ì™„ë£Œ: {summary[:50]}...")

        log.info(f"--- 3c. LLM PII Detection Step Start (ID: {doc_id}) ---")
        pii_results = await llm_tasks.detect_pii(extracted_text, llm_client)
        log.info(f"LLM (ID: {doc_id}) PII íƒì§€ ì™„ë£Œ: {len(pii_results)}ê°œ")

        log.info(f"--- 4. MeiliSearch Indexing Step Start (ID: {doc_id}) ---")
        document_payload = {
            "id": doc_id,
            "filename": filename,
            "content": extracted_text,
            "doc_type": doc_type,
            "doc_confidence": doc_confidence,
            "extracted_data": extracted_data,
            "summary": summary,
            "pii_count": len(pii_results),
        }
        meili_client.index("documents").add_documents([document_payload])
        log.info(f"'{filename}' (ID: {doc_id}) MeiliSearch ì¸ë±ì‹± ì™„ë£Œ.")

        log.info(f"--- 5. Qdrant Indexing Step Start (ID: {doc_id}) ---")
        vector_indexed = False

        vector = await llm_tasks.get_embedding(
            extracted_text,
            llm_client,
            settings.EMBEDDING_MODEL_NAME
        )

        if not vector:
            log.warning(f"'{filename}' (ID: {doc_id})ì˜ ì„ë² ë”© ë²¡í„° ìƒì„± ì‹¤íŒ¨. Qdrant ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            qdrant_payload = {
                "filename": filename,
                "doc_type": doc_type,
                "summary": summary,
                "meili_id": doc_id
            }

            qdrant_client.upsert(
                collection_name=QDRANT_COLLECTION_NAME,
                points=[
                    models.PointStruct(
                        id=doc_id,
                        vector=vector,
                        payload=qdrant_payload
                    )
                ]
            )
            vector_indexed = True
            log.info(f"'{filename}' (ID: {doc_id}) Qdrant ì¸ë±ì‹± ì™„ë£Œ.")

        result_summary = f"'{filename}' (Phase 2) ì²˜ë¦¬ ì™„ë£Œ (ID: {doc_id}, Type: {doc_type}, Vector: {vector_indexed})"
        log.info(result_summary)

        return {
            "id": doc_id,
            "filename": filename,
            "classification": classification_result,
            "extracted_data": extracted_data,
            "summary": summary,
            "pii_detected": pii_results,
            "vector_indexed": vector_indexed
        }

    except Exception as e:
        log.error(f"'{filename}' (ID: {doc_id}) ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ (ì‹œë„: {self.request.retries + 1}): {e}", exc_info=True)
        raise
    finally:
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
            log.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_file_path}")