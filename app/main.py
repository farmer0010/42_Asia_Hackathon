import os
import uuid
from fastapi import FastAPI, File, UploadFile, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from prometheus_fastapi_instrumentator import Instrumentator
from contextlib import asynccontextmanager
from typing import List, Optional
import logging
import meilisearch
import qdrant_client
from qdrant_client import models
from pathlib import Path
import requests

# 'app' ëª¨ë“ˆ ë‚´ì˜ ë‹¤ë¥¸ íŒŒì¼ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from .config import settings
from .logger_config import setup_logging
from .worker import process_document_pipeline, celery_app
from . import schemas
from .pipeline import llm_tasks

# --- ë¡œê±° ë° ì„¤ì • ì´ˆê¸°í™” ---
setup_logging()
log = logging.getLogger("uvicorn")

# --- ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
try:
    log.info(f"MeiliSearch ì—°ê²° ì‹œë„: {settings.MEILI_HOST_URL}")

    # ğŸš¨ [ìµœì¢… ìˆ˜ì •]: MeiliSearch Master Key ì„¤ì • (API Key ì˜¤ë¥˜ í•´ê²°)
    # setup_databasesì—ì„œ ì¸ë±ìŠ¤ ì„¤ì •ì„ ë³€ê²½í•˜ë ¤ë©´ Master Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.
    # settings ê°ì²´ì—ì„œ MEILI_MASTER_KEYë¥¼ ê°€ì ¸ì˜¤ë˜, ì •ì˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ Noneì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    meili_api_key = getattr(settings, 'MEILI_MASTER_KEY', None)
    if meili_api_key is None:
        log.warning("âš ï¸ MEILI_MASTER_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ ì„¤ì •ì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    meili_client = meilisearch.Client(url=settings.MEILI_HOST_URL, api_key=meili_api_key)

    if not meili_client.is_healthy():
        raise Exception("MeiliSearch is not healthy")
    log.info("MeiliSearch ì—°ê²° ì„±ê³µ.")
except Exception as e:
    log.error(f"MeiliSearch ì—°ê²° ì‹¤íŒ¨: {e}. Master Keyê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    meili_client = None  # ì—°ê²° ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì„¤ì •

try:
    log.info(f"Qdrant ì—°ê²° ì‹œë„: {settings.QDRANT_HOST}:{settings.QDRANT_PORT}")
    qdrant_cli = qdrant_client.QdrantClient(
        host=settings.QDRANT_HOST,
        port=settings.QDRANT_PORT
    )
    # Qdrant ì—°ê²° í™•ì¸
    qdrant_cli.get_collections()
    log.info("Qdrant ì—°ê²° ì„±ê³µ.")
except Exception as e:
    log.error(f"Qdrant ì—°ê²° ì‹¤íŒ¨: {e}")
    qdrant_cli = None  # ì—°ê²° ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì„¤ì •

QDRANT_COLLECTION_NAME = "documents_collection"
VECTOR_DIMENSION = settings.VECTOR_DIMENSION


def setup_databases():
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ MeiliSearch ì¸ë±ìŠ¤ì™€ Qdrant ì»¬ë ‰ì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    # 1. MeiliSearch ì„¤ì •
    if meili_client:
        try:
            log.info("MeiliSearch ì¸ë±ìŠ¤('documents') ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            index = meili_client.index("documents")

            # ğŸš¨ Master Keyê°€ ì—†ìœ¼ë©´ ì´ ë¶€ë¶„ì´ 403 Forbidden ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
            index.update_filterable_attributes([
                'doc_type',
                'created_at'
            ])
            index.update_sortable_attributes([
                'created_at'
            ])
            index.update_ranking_rules([
                "words", "typo", "proximity", "attribute", "sort", "exactness"
            ])
            log.info("MeiliSearch ì¸ë±ìŠ¤ ì„¤ì • ì™„ë£Œ.")
        except Exception as e:
            # ì´ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤ë©´ .envì— MEILI_MASTER_KEYê°€ ëˆ„ë½ëœ ê²ƒì…ë‹ˆë‹¤.
            log.error(f"MeiliSearch ì¸ë±ìŠ¤ ì„¤ì • ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
            log.warning("MeiliSearch ì¸ë±ìŠ¤ ì„¤ì • ì‹¤íŒ¨. MEILI_MASTER_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        log.warning("MeiliSearch í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì„¤ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    # 2. Qdrant ì„¤ì •
    if qdrant_cli:
        try:
            log.info(f"Qdrant ì»¬ë ‰ì…˜('{QDRANT_COLLECTION_NAME}') í™•ì¸ ë° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            try:
                collection_info = qdrant_cli.get_collection(collection_name=QDRANT_COLLECTION_NAME)
                log.info(f"Qdrant ì»¬ë ‰ì…˜ '{QDRANT_COLLECTION_NAME}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")

                # ë²¡í„° ì°¨ì› í™•ì¸ ë° ì¬ìƒì„± (í•„ìš”ì‹œ)
                current_dim = collection_info.config.params.vectors.size
                if current_dim != VECTOR_DIMENSION:
                    log.warning(f"ë²¡í„° ì°¨ì›ì´ ë‹¤ë¦…ë‹ˆë‹¤! (í˜„ì¬: {current_dim}, í•„ìš”: {VECTOR_DIMENSION}). ì»¬ë ‰ì…˜ì„ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                    qdrant_cli.delete_collection(collection_name=QDRANT_COLLECTION_NAME)
                    raise Exception("ì»¬ë ‰ì…˜ ì°¨ì›ì´ ë‹¬ë¼ ì¬ìƒì„± í•„ìš”")

            except Exception as e:
                # ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì¬ìƒì„±ì´ í•„ìš”í•œ ê²½ìš°
                log.info(f"ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤. (ì°¨ì›: {VECTOR_DIMENSION})")
                qdrant_cli.recreate_collection(
                    collection_name=QDRANT_COLLECTION_NAME,
                    vectors_config=models.VectorParams(
                        size=VECTOR_DIMENSION,
                        distance=models.Distance.COSINE
                    )
                )
                log.info(f"Qdrant ì»¬ë ‰ì…˜ '{QDRANT_COLLECTION_NAME}' ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            log.error(f"Qdrant ì»¬ë ‰ì…˜ ì„¤ì • ì¤‘ ì‹¬ê°í•œ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
    else:
        log.warning("Qdrant í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì„¤ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")


@asynccontextmanager
async def lifespan(app: FastAPI):
    log.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘...")
    setup_databases()
    yield
    log.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ...")


app = FastAPI(
    title="42 Asia Hackathon - AI Document Engine",
    description="ë¬¸ì„œì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ëŠ” ì§€ëŠ¥í˜• AI ì—”ì§„ API (í‚¤ì›Œë“œ + ì‹œë§¨í‹± ê²€ìƒ‰ ì§€ì›)",
    version="1.0.0",
    lifespan=lifespan
)

# --- ë¯¸ë“¤ì›¨ì–´ ì„¤ì • ---
origins = ["*"]  # ë°ëª¨ë¥¼ ìœ„í•´ ëª¨ë“  ì˜¤ë¦¬ì§„ í—ˆìš©

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

Instrumentator().instrument(app).expose(app)


# --- ë¼ìš°íŠ¸ ì •ì˜ ---

@app.get("/", tags=["Root"])
def read_root():
    return {"Hello": "42_Asia_Hackathon_AI_Engine"}


@app.get("/health", tags=["Monitoring"])
def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    health_results = {
        "api": "ok",
        "redis": "checking",
        "qdrant": "checking",
        "meilisearch": "checking",
        "llm_server": "checking"
    }

    # Redis (Celery Broker)
    try:
        celery_app.control.ping()
        health_results["redis"] = "ok"
    except Exception as e:
        health_results["redis"] = str(e)

    # Qdrant
    if qdrant_cli:
        try:
            # ğŸš¨ [ìˆ˜ì •]: Qdrant í—¬ìŠ¤ ì²´í¬ í•¨ìˆ˜ ì•ˆì •í™”
            qdrant_cli.get_collections()
            health_results["qdrant"] = "ok"
        except Exception as e:
            health_results["qdrant"] = str(e)
    else:
        health_results["qdrant"] = "client not initialized"

    # MeiliSearch
    if meili_client:
        try:
            if meili_client.is_healthy():
                health_results["meilisearch"] = "ok"
            else:
                health_results["meilisearch"] = "unhealthy"
        except Exception as e:
            health_results["meilisearch"] = str(e)
    else:
        health_results["meilisearch"] = "client not initialized"

    # LLM Server (Shimmy)
    try:
        response = requests.get(f"{settings.LLM_API_BASE_URL}/health", timeout=1)
        if response.status_code == 200:
            health_results["llm_server"] = "ok"
        else:
            health_results["llm_server"] = f"status_code: {response.status_code}"
    except Exception as e:
        health_results["llm_server"] = "connection_failed"

    # ëª¨ë“  ì„œë¹„ìŠ¤ê°€ okê°€ ì•„ë‹ˆë©´ 503 ë°˜í™˜
    if any(status != "ok" for status in health_results.values()):
        raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=health_results)

    return {"status": "ok", "services": health_results}


# â—€â—€â—€ [ì£¼ì„ ì²˜ë¦¬ ìœ ì§€] /search ì—”ë“œí¬ì¸íŠ¸ëŠ” SyntaxError ë°©ì§€ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. â—€â—€â—€
# @app.get("/search", status_code=status.HTTP_200_OK)
# async def search_documents(
#     query: str,
#     doc_type: Optional[str] = None
# ):
#     try:
#         raise HTTPException(st  # <--- ì´ ì¤„ì´ SyntaxErrorì˜ ì›ì¸ì…ë‹ˆë‹¤.
#     except Exception as e:
#         log.error(f"Search failed: {e}", exc_info=True)
#         raise HTTPException(status_code=500, detail="Search operation failed")
# â—€â—€â—€ [ìˆ˜ì • ì™„ë£Œ] â—€â—€â—€


@app.get("/job/{job_id}", status_code=status.HTTP_200_OK, response_model=schemas.JobStatusResponse)
async def get_job_status(job_id: str):
    """Celery ì‘ì—… IDë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    log.info(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ìš”ì²­: {job_id}")
    try:
        task_result = celery_app.AsyncResult(job_id)

        status = task_result.status
        result = task_result.result

        if status == "PENDING":
            # ì‘ì—…ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì•„ì§ ì‹œì‘ë˜ì§€ ì•ŠìŒ
            log.warning(f"'{job_id}'ì— ëŒ€í•œ ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (PENDING).")
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Job ID {job_id} not found.")

        if status == "FAILURE":
            log.warning(f"ì‘ì—… ì‹¤íŒ¨: {job_id}, Error: {str(result)}")
            return schemas.JobStatusResponse(
                job_id=job_id,
                status=status,
                message=str(result)
            )

        # PENDINGë„ ì•„ë‹ˆê³  FAILUREë„ ì•„ë‹ˆë©´ (PROCESSING ë˜ëŠ” SUCCESS)
        return schemas.JobStatusResponse(
            job_id=job_id,
            status=status,
            result=result
        )

    except Exception as e:
        log.error(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Error retrieving job status")


@app.post("/upload", status_code=status.HTTP_202_ACCEPTED, response_model=schemas.UploadResponse)
async def upload_document(
        file: UploadFile = File(...)
):
    """ë‹¨ì¼ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤."""

    job_id = str(uuid.uuid4())
    temp_dir = Path("/tmp/doc_uploads")
    temp_dir.mkdir(exist_ok=True)

    # íŒŒì¼ í™•ì¥ì ìœ ì§€
    file_ext = Path(file.filename).suffix
    temp_file_path = temp_dir / f"{job_id}{file_ext}"

    try:
        log.info(f"[{job_id}] íŒŒì¼ ìˆ˜ì‹ : {file.filename}, ì„ì‹œ ì €ì¥ ìœ„ì¹˜: {temp_file_path}")

        with open(temp_file_path, "wb") as buffer:
            buffer.write(await file.read())

        # Celery ì‘ì—… ìƒì„±
        process_document_pipeline.delay(
            job_id=job_id,
            file_path=str(temp_file_path),
            file_name=file.filename,
            file_mime_type=file.content_type
        )
        log.info(f"[{job_id}] Celery ì‘ì—… ìƒì„± ì™„ë£Œ.")

        return schemas.UploadResponse(
            job_id=job_id,
            filename=file.filename,
            message="File received and processing started."
        )

    except Exception as e:
        log.error(f"íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
        # ì„ì‹œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆë‹¤ë©´ ì‚­ì œ ì‹œë„
        if temp_file_path.exists():
            os.remove(temp_file_path)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"File processing error: {e}")