# D:\42_asia-hackathon\app\main.py

import os
import uuid
from fastapi import FastAPI, File, UploadFile, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from prometheus_fastapi_instrumentator import Instrumentator
from contextlib import asynccontextmanager
from typing import List, Optional
import logging
import meilisearch
import qdrant_client
from qdrant_client import models
from pathlib import Path
import requests

# ğŸš¨ [ìˆ˜ì • 6]: ëª¨ë“  ëª¨ë“ˆì´ configì™€ schemasì˜ ìƒˆ ì´ë¦„ì„ ì‚¬ìš©í•˜ë„ë¡ í•¨
from .config import settings
from .logger_config import setup_logging
from .worker import process_document_pipeline, celery_app
from . import schemas  # ìˆ˜ì •ëœ schemas.py ì„í¬íŠ¸
from .pipeline import llm_tasks

setup_logging()
log = logging.getLogger("uvicorn")

# --- ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
meili_client = None
qdrant_cli = None

try:
    log.info(f"MeiliSearch ì—°ê²° ì‹œë„: {settings.MEILI_HOST_URL}")
    meili_client = meilisearch.Client(url=settings.MEILI_HOST_URL, api_key=settings.MEILI_MASTER_KEY)
    if not meili_client.is_healthy():
        raise Exception("MeiliSearch is not healthy")
    log.info("MeiliSearch ì—°ê²° ì„±ê³µ.")
except Exception as e:
    log.error(f"MeiliSearch ì—°ê²° ì‹¤íŒ¨: {e}")

try:
    log.info(f"Qdrant ì—°ê²° ì‹œë„: {settings.QDRANT_HOST}:{settings.QDRANT_PORT}")
    qdrant_cli = qdrant_client.QdrantClient(
        host=settings.QDRANT_HOST,
        port=settings.QDRANT_PORT
    )
    qdrant_cli.get_collections()  # í—¬ìŠ¤ ì²´í¬ ëŒ€ìš©
    log.info("Qdrant ì—°ê²° ì„±ê³µ.")
except Exception as e:
    log.error(f"Qdrant ì—°ê²° ì‹¤íŒ¨: {e}")

QDRANT_COLLECTION_NAME = "documents_collection"
VECTOR_DIMENSION = settings.VECTOR_DIMENSION  # config.pyì˜ VECTOR_DIMENSION ì‚¬ìš©


def setup_databases():
    if meili_client:
        try:
            log.info("MeiliSearch ì¸ë±ìŠ¤('documents') ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            index = meili_client.index("documents")
            index.update_filterable_attributes(['doc_type', 'created_at'])
            index.update_sortable_attributes(['created_at'])
            index.update_ranking_rules(["words", "typo", "proximity", "attribute", "sort", "exactness"])
            log.info("MeiliSearch ì¸ë±ìŠ¤ ì„¤ì • ì™„ë£Œ.")
        except Exception as e:
            log.error(f"MeiliSearch ì¸ë±ìŠ¤ ì„¤ì • ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
    else:
        log.warning("MeiliSearch í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì„¤ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    if qdrant_cli:
        try:
            log.info(f"Qdrant ì»¬ë ‰ì…˜('{QDRANT_COLLECTION_NAME}') í™•ì¸ ë° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            try:
                collection_info = qdrant_cli.get_collection(collection_name=QDRANT_COLLECTION_NAME)
                log.info(f"Qdrant ì»¬ë ‰ì…˜ '{QDRANT_COLLECTION_NAME}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                current_dim = collection_info.config.params.vectors.size
                if current_dim != VECTOR_DIMENSION:
                    log.warning(f"ë²¡í„° ì°¨ì›ì´ ë‹¤ë¦…ë‹ˆë‹¤! (í˜„ì¬: {current_dim}, í•„ìš”: {VECTOR_DIMENSION}). ì»¬ë ‰ì…˜ì„ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                    qdrant_cli.delete_collection(collection_name=QDRANT_COLLECTION_NAME)
                    raise Exception("ì»¬ë ‰ì…˜ ì°¨ì›ì´ ë‹¬ë¼ ì¬ìƒì„± í•„ìš”")
            except Exception as e:
                log.info(f"ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤. (ì°¨ì›: {VECTOR_DIMENSION})")
                qdrant_cli.recreate_collection(
                    collection_name=QDRANT_COLLECTION_NAME,
                    vectors_config=models.VectorParams(
                        size=VECTOR_DIMENSION,
                        distance=models.Distance.COSINE
                    )
                )
                log.info(f"Qdrant ì»¬ë ‰ì…˜ '{QDRANT_COLLECTION_NAME}' ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            log.error(f"Qdrant ì»¬ë ‰ì…˜ ì„¤ì • ì¤‘ ì‹¬ê°í•œ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
    else:
        log.warning("Qdrant í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì„¤ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")


@asynccontextmanager
async def lifespan(app: FastAPI):
    log.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘...")
    setup_databases()
    yield
    log.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ...")


app = FastAPI(title="42 Asia Hackathon - AI Document Engine", lifespan=lifespan)
origins = ["*"]
app.add_middleware(CORSMiddleware, allow_origins=origins, allow_credentials=True, allow_methods=["*"],
                   allow_headers=["*"])
Instrumentator().instrument(app).expose(app)


@app.get("/", tags=["Root"])
def read_root():
    return {"Hello": "42_Asia_Hackathon_AI_Engine"}


@app.get("/health", tags=["Monitoring"], response_model=schemas.HealthCheck)
def health_check():
    health_results = {"api": "ok", "redis": "checking", "qdrant": "checking", "meilisearch": "checking",
                      "llm_server": "checking"}
    try:
        celery_app.control.ping()
        health_results["redis"] = "ok"
    except Exception as e:
        health_results["redis"] = str(e)
    if qdrant_cli:
        try:
            qdrant_cli.get_collections()  # health_check() ëŒ€ì‹ 
            health_results["qdrant"] = "ok"
        except Exception as e:
            health_results["qdrant"] = str(e)
    else:
        health_results["qdrant"] = "client not initialized"
    if meili_client:
        try:
            if meili_client.is_healthy():
                health_results["meilisearch"] = "ok"
            else:
                health_results["meilisearch"] = "unhealthy"
        except Exception as e:
            health_results["meilisearch"] = str(e)
    else:
        health_results["meilisearch"] = "client not initialized"
    try:
        response = requests.get(f"{settings.LLM_API_BASE_URL}/health", timeout=1)  # settings.LLM_API_BASE_URL ì‚¬ìš©
        if response.status_code == 200:
            health_results["llm_server"] = "ok"
        else:
            health_results["llm_server"] = f"status_code: {response.status_code}"
    except Exception as e:
        health_results["llm_server"] = "connection_failed"

    if any(status != "ok" for status in health_results.values()):
        return schemas.HealthCheck(status="error", services=health_results)
    return schemas.HealthCheck(status="ok", services=health_results)


# ... (ì£¼ì„ ì²˜ë¦¬ëœ /search ì—”ë“œí¬ì¸íŠ¸) ...

@app.get("/job/{job_id}", status_code=status.HTTP_200_OK, response_model=schemas.JobStatusResponse)  # ğŸš¨ [ìˆ˜ì •] ìŠ¤í‚¤ë§ˆ ì´ë¦„ ë³€ê²½
async def get_job_status(job_id: str):
    log.info(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ìš”ì²­: {job_id}")
    try:
        task_result = celery_app.AsyncResult(job_id)
        status = task_result.status
        result = task_result.result
        if status == "PENDING":
            log.warning(f"'{job_id}'ì— ëŒ€í•œ ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (PENDING).")
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Job ID {job_id} not found.")
        if status == "FAILURE":
            log.warning(f"ì‘ì—… ì‹¤íŒ¨: {job_id}, Error: {str(result)}")
            return schemas.JobStatusResponse(job_id=job_id, status=status, message=str(result))
        return schemas.JobStatusResponse(job_id=job_id, status=status, result=result)
    except Exception as e:
        log.error(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Error retrieving job status")


@app.post("/upload", status_code=status.HTTP_202_ACCEPTED, response_model=schemas.UploadResponse)  # ğŸš¨ [ìˆ˜ì •] ìŠ¤í‚¤ë§ˆ ì´ë¦„ ë³€ê²½
async def upload_document(file: UploadFile = File(...)):
    job_id = str(uuid.uuid4())
    temp_dir = Path("/tmp/doc_uploads")
    temp_dir.mkdir(exist_ok=True)
    file_ext = Path(file.filename).suffix
    temp_file_path = temp_dir / f"{job_id}{file_ext}"
    try:
        log.info(f"[{job_id}] íŒŒì¼ ìˆ˜ì‹ : {file.filename}, ì„ì‹œ ì €ì¥ ìœ„ì¹˜: {temp_file_path}")
        with open(temp_file_path, "wb") as buffer:
            buffer.write(await file.read())
        process_document_pipeline.delay(
            job_id=job_id,
            file_path=str(temp_file_path),
            file_name=file.filename,
            file_mime_type=file.content_type
        )
        log.info(f"[{job_id}] Celery ì‘ì—… ìƒì„± ì™„ë£Œ.")
        return schemas.UploadResponse(job_id=job_id, filename=file.filename)
    except Exception as e:
        log.error(f"íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
        if temp_file_path.exists():
            os.remove(temp_file_path)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"File processing error: {e}")