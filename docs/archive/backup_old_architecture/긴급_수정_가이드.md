# 해커톤 당일 긴급 수정 가이드

## 목적
labels.csv가 예상과 다를 경우 5-10분 안에 빠르게 대응하는 방법

---

## 시나리오 1: 문서 타입이 다른 경우

### 문제 상황
```csv
# 예상: invoice, receipt, resume, report, contract
# 실제 labels.csv:
filename,doc_type
doc_001.pdf,tax_invoice
doc_002.jpg,sales_receipt
doc_003.pdf,employment_contract
doc_004.pdf,financial_report
doc_005.pdf,job_application
```

### 해결 방법 (2분)

**파일:** `src/classification_module.py`
**위치:** Line 17

**수정 전:**
```python
self.labels = ['invoice', 'receipt', 'resume', 'report', 'contract']
```

**수정 후:**
```python
# labels.csv 보고 직접 수정
self.labels = ['tax_invoice', 'sales_receipt', 'employment_contract', 
               'financial_report', 'job_application']
```

**또는 완전 자동화 (5분):**
```python
# Line 17-19를 이렇게 변경:
self.labels = None  # train()에서 자동 설정
self.label_to_id = None
self.id_to_label = None

# train() 함수 첫 부분에 추가:
def train(self, labels_csv_path, ocr_results_path, output_dir='models/classifier'):
    df = pd.read_csv(labels_csv_path)
    
    # 자동으로 doc_types 파악
    self.labels = sorted(df['doc_type'].unique().tolist())
    self.label_to_id = {label: i for i, label in enumerate(self.labels)}
    self.id_to_label = {i: label for i, label in enumerate(self.labels)}
    
    print(f"Auto-detected document types: {self.labels}")
    # 나머지 학습 코드...
```

---

## 시나리오 2: 추출 필드가 다른 경우

### 문제 상황
```csv
# 예상: vendor, invoice_date, total_amount, currency
# 실제 labels.csv:
filename,doc_type,company_name,issue_date,grand_total,payment_method
inv_001.pdf,invoice,ABC Corp,2025-08-19,1500.00,Wire Transfer
```

### 해결 방법 (자동, 수정 불필요!)

**파일:** `src/extraction_module.py`

**올바른 설계 (미리 이렇게 작성):**
```python
class DataExtractor:
    def train(self, labels_csv_path, ocr_results_path):
        df = pd.read_csv(labels_csv_path)
        
        # 자동으로 필드 컬럼 파악
        field_columns = [col for col in df.columns 
                         if col not in ['filename', 'doc_type']]
        
        print(f"Auto-detected extraction fields: {field_columns}")
        # ['company_name', 'issue_date', 'grand_total', 'payment_method']
        
        # 자동으로 entity types 생성
        self.entity_types = [col.upper().replace('_', '-') 
                            for col in field_columns]
        # ['COMPANY-NAME', 'ISSUE-DATE', 'GRAND-TOTAL', 'PAYMENT-METHOD']
        
        # BIO 태그 자동 생성
        labels = ['O']
        for entity in self.entity_types:
            labels.extend([f'B-{entity}', f'I-{entity}'])
        
        # 나머지 학습...
```

**→ 수정 불필요! 완전 자동화!**

---

## 시나리오 3: 문서 타입 개수가 다른 경우

### 문제 상황 A: 3개만 있음
```csv
filename,doc_type
doc_001.pdf,invoice
doc_002.jpg,receipt
doc_003.pdf,contract
```

### 해결 방법 (자동)

**classification_module.py가 자동화되어 있다면:**
```python
# train() 함수가 자동 파악
self.labels = sorted(df['doc_type'].unique().tolist())
# ['contract', 'invoice', 'receipt']  # 3개만!

# 모델 초기화도 자동
self.model = DistilBertForSequenceClassification.from_pretrained(
    self.model_name,
    num_labels=len(self.labels),  # 3으로 자동 설정!
    id2label=self.id_to_label,
    label2id=self.label_to_id
)
```

**수동으로 수정해야 한다면 (2분):**
```python
# Line 17:
self.labels = ['invoice', 'receipt', 'contract']  # 3개만

# Line 77 (테스트 코드):
num_labels=3  # 5 → 3으로 변경
```

### 문제 상황 B: 7개 있음
```csv
doc_type: invoice, receipt, resume, report, contract, application, license
```

**수정:**
```python
# Line 17:
self.labels = ['invoice', 'receipt', 'resume', 'report', 'contract', 
               'application', 'license']  # 7개

# Line 77:
num_labels=7  # 5 → 7로 변경
```

---

## 시나리오 4: 추출 대상 타입이 다른 경우

### 문제 상황
```csv
# 예상: invoice, receipt에 필드 있음
# 실제: resume, report에 필드 있음

filename,doc_type,name,experience_years,education,skills
resume_001.pdf,resume,John Doe,5,MIT,Python
resume_002.pdf,resume,Jane Smith,3,Stanford,Java
report_001.pdf,report,,,
invoice_001.pdf,invoice,,,
```

### 해결 방법 (자동!)

**extraction_module.py가 자동화되어 있다면:**
```python
def train(self, labels_csv_path, ocr_results_path):
    df = pd.read_csv(labels_csv_path)
    
    # 1. 필드 컬럼 자동 파악
    field_columns = [col for col in df.columns 
                     if col not in ['filename', 'doc_type']]
    # ['name', 'experience_years', 'education', 'skills']
    
    # 2. 어느 doc_type이 필드를 가지는지 자동 파악
    doc_types_with_fields = []
    for doc_type in df['doc_type'].unique():
        subset = df[df['doc_type'] == doc_type]
        if subset[field_columns].notna().any().any():
            doc_types_with_fields.append(doc_type)
    
    print(f"Extraction targets: {doc_types_with_fields}")
    # ['resume']  # resume만 필드 있음!
    
    # 3. 해당 타입만 학습 데이터 생성
    # ...
```

**→ 완전 자동! 수정 불필요!**

---

## 빠른 대응 체크리스트

### Step 1: labels.csv 확인 (5분)

```bash
cd hackathon_dataset/training_set

# 1. 파일 헤더 확인
head -1 labels.csv
# filename,doc_type,vendor,invoice_date,total_amount,currency

# 2. doc_type 종류 확인
cut -d',' -f2 labels.csv | sort | uniq
# invoice
# receipt
# resume
# report
# contract

# 3. 샘플 데이터 확인
head -5 labels.csv
```

### Step 2: 수정 판단 (1분)

**질문 1: doc_type이 5개 맞나?**
```
YES → classification_module.py 수정 불필요 ✓
NO → classification_module.py Line 17 수정 필요
```

**질문 2: doc_type 이름이 정확히 일치하나?**
```
YES → 수정 불필요 ✓
NO → Line 17의 이름 변경
```

**질문 3: 추출 필드가 예상과 다른가?**
```
자동화 되어있으면 → 수정 불필요 ✓
아니면 → extraction_module.py 수정
```

### Step 3: 긴급 수정 (5분)

**필요한 경우에만:**

**A. 문서 타입 이름 다름**
```python
# classification_module.py Line 17
self.labels = ['실제', '이름', '리스트']
```

**B. 개수 다름**
```python
# Line 17
self.labels = [...개수만큼...]

# Line 77 (테스트 코드)
num_labels=개수
```

---

## 예상 시나리오별 대응 시간

```
시나리오 1: 모든 게 예상대로
→ 수정 시간: 0분 ✓

시나리오 2: 문서 타입 이름만 다름
→ 수정: Line 17만 (2분)

시나리오 3: 문서 타입 개수 다름
→ 수정: Line 17, 77 (3분)

시나리오 4: 추출 필드 다름
→ 수정: 자동화되어있으면 0분 (5분)

시나리오 5: 완전히 다른 구조
→ 수정: 10-15분 (최악)
```

---

## 긴급 백업 플랜

### Plan A: 자동화 (현재 목표)
```python
# extraction_module.py
def train():
    자동으로 필드 파악
    자동으로 학습
```
- 시간: 0분
- 리스크: 없음

### Plan B: 수동 수정 (백업)
```python
# 자동화 실패 시
if labels.csv가 이상하면:
    10분 안에 수동 수정
    하드코딩
```
- 시간: 10분
- 리스크: 낮음

### Plan C: Rule-based (최후의 수단)
```python
# AI 학습 포기
# 정규표현식으로 대체
if 시간 없으면:
    re.search(r'Total.*?(\d+)', text)
```
- 시간: 30분
- 리스크: 중간
- 정확도: 70-80% (낮음)

---

## 핵심 파일별 수정 위치 요약

### classification_module.py
```
수정 위치: Line 17
수정 내용: self.labels = [실제 타입들]
소요 시간: 2분
```

### extraction_module.py (미작성)
```
수정 위치: train() 함수 내부
수정 내용: 자동화 코드 (권장)
소요 시간: 0분 (자동) 또는 5분 (수동)
```

### batch_ocr.py
```
수정 필요: 없음 ✓
이유: 완전 자동화됨
```

### ocr_module.py
```
수정 필요: 없음 ✓
이유: 텍스트만 추출 (범용적)
```

---

## 당일 체크리스트

```
□ 9:00 - labels.csv 받기
□ 9:01 - head -5 labels.csv 확인
□ 9:02 - doc_type 확인 (cut -d',' -f2 | uniq)
□ 9:03 - 예상과 일치? 
    YES → 바로 진행
    NO → 이 가이드 참고, 2-5분 수정
□ 9:05 - OCR 시작
```

---

## 마지막 팁

### 테스트 코드 활용
```python
# 당일 labels.csv 받자마자 테스트:
python -c "
import pandas as pd
df = pd.read_csv('labels.csv')
print('Doc types:', df['doc_type'].unique())
print('Columns:', df.columns.tolist())
"

# 예상과 비교
# 다르면 이 가이드 보고 수정
# 같으면 바로 진행!
```

### 시간 절약 팁
```
긴급할 때:
1. 자동화 시도 (extraction_module.py)
2. 실패하면 수동 수정 (classification_module.py Line 17)
3. 그래도 안 되면 Rule-based (정규표현식)

우선순위:
분류 > 추출
→ 분류라도 성공하면 부분 점수!
```

---

## 연락처 (팀원)

```
백엔드 파트: [연락처]
LLM 파트: [연락처]

긴급 상황 시 즉시 공유!
```

---

## 참고: 자동화 vs 수동 수정 비교

```
자동화 (권장):
- 수정 시간: 0분
- 리스크: 낮음
- 코드: extraction_module.py에 구현

수동 (백업):
- 수정 시간: 2-5분
- 리스크: 중간
- 위치: Line 17, entity_types 등

Rule-based (최후):
- 수정 시간: 30분
- 리스크: 높음
- 정확도: 70-80%
```

