# 방콕 해커톤 - 학습 노트

## 날짜: 2025-10-24

이 문서는 AI 코딩 파트너와 함께 학습한 내용을 정리한 것입니다.

---

## 1. 프로젝트 전략 수립

### 초기 고민: LayoutLM vs 텍스트 기반

**LayoutLM 방식 (복잡):**
```
입력: 텍스트 + Bounding Box + 이미지
장점: 레이아웃 정보 활용, 높은 정확도
단점: 
- 복잡한 전처리 (bbox 정규화)
- 큰 메모리 (2-3GB, 빡빡함)
- 긴 학습 시간 (2-3시간)
- 구현 복잡도 높음
```

**텍스트 기반 (우리 선택):**
```
입력: OCR 텍스트만
기술: PaddleOCR + DistilBERT + BERT-NER
장점:
- 간단한 구현
- 낮은 메모리 (643MB, 여유)
- 빠른 학습 (1.5시간)
- 충분한 정확도 (85-90%)

결론: Simple, Fast, Reliable
```

---

## 2. OCR 모듈 이해

### 현재 ocr_module.py가 지원하는 형식

**파일 형식:**
```python
✅ .jpg, .jpeg, .png (이미지)
✅ .pdf (첫 페이지만)

# Line 43-44: PDF 자동 변환
if Path(file_path).suffix.lower() == '.pdf':
    file_path = self._pdf_to_image(file_path)
```

**출력 형식:**
```python
{
  'text': '전체 텍스트...',  # 분류/추출용
  'confidence': 0.95,
  'processing_time': 3.2
}
```

**테스트 결과:**
- 평균 신뢰도: 94.95%
- 평균 처리 시간: 4.14초/문서

---

## 3. 해커톤 데이터셋 구조 이해

### 당일 받을 데이터

```
hackathon_dataset/
├── training_set/           ← 학습용 (정답 있음!)
│   ├── documents/
│   │   ├── inv_001.pdf
│   │   ├── inv_002.png
│   │   └── ... (500-1000개)
│   └── labels.csv          ← 정답지!
│
└── testing_set/            ← 예측용 (정답 없음!)
    └── documents/
        ├── test_doc_01.png
        └── ... (100-200개)
```

### labels.csv의 역할

**학습용 정답지:**
```csv
filename,doc_type,vendor,invoice_date,total_amount,currency
inv_001.pdf,invoice,ABC Corp,2025-08-19,1500.00,THB
inv_002.png,invoice,XYZ Ltd,2025-08-20,2000.00,USD
receipt_001.jpg,receipt,Store,2025-08-21,100.00,THB
```

**중요:**
- training_set에만 제공
- testing_set에는 없음!
- 우리가 공부할 때만 사용
- 시험 볼 때는 없음

---

## 4. 학습 vs 예측 차이

### 학습 (Training)

**시기:** 해커톤 오전 (한 번만)
**데이터:** training_set + labels.csv (정답 있음!)

**과정:**
```
1. OCR: 이미지 → 텍스트
2. labels.csv 정답 확인 (미리 봄!)
3. 모델에게 가르침:
   "Commercial Invoice..." → 정답: invoice
   "Receipt Store..." → 정답: receipt
4. 모델 학습 (3 Epoch 반복)
5. 똑똑해진 모델 저장
```

**비유:** 시험 공부 (정답지 보면서)

### 예측 (Prediction)

**시기:** 해커톤 오후 (여러 번)
**데이터:** testing_set (정답 없음!)

**과정:**
```
1. OCR: 이미지 → 텍스트
2. 학습된 모델 로드
3. 모델이 예측:
   "Invoice Bangkok..." → 예측: invoice (98%)
4. 결과 제출
5. 주최측이 채점 (우리는 정답 모름!)
```

**비유:** 실전 시험 (정답 모름!)

---

## 5. AI 모델 설명

### DistilBERT (문서 분류용)

**역할:** 전체 텍스트 보고 문서 타입 분류

**입력:**
```python
"Commercial Invoice ABC Corp Total 1500.00"
```

**처리:**
```python
전체 문장 읽기
↓
패턴 학습:
- "Commercial", "Invoice", "Total" → invoice
- "Receipt", "Supermarket" → receipt
↓
전체 문장 요약
↓
5개 클래스 중 1개 선택
```

**출력:**
```python
{
  'doc_type': 'invoice',
  'confidence': 0.98
}
```

**특징:**
- 크기: 268MB (경량)
- 메모리: 643MB (실측)
- 학습 시간: 30분

### BERT-NER (데이터 추출용)

**역할:** 각 단어마다 태그 붙여서 정보 추출

**입력:**
```python
["Commercial", "Invoice", "ABC", "Corp", "Total", "1500.00"]
```

**처리:**
```python
각 단어마다 분류:
- "Commercial" → O (중요하지 않음)
- "Invoice" → O
- "ABC" → B-VENDOR (회사명 시작)
- "Corp" → I-VENDOR (회사명 계속)
- "Total" → O
- "1500.00" → B-AMOUNT (금액)
```

**출력:**
```python
{
  'vendor': 'ABC Corp',      # B-VENDOR + I-VENDOR
  'total_amount': 1500.00    # B-AMOUNT
}
```

**차이점 정리:**
```
DistilBERT (분류):
- 전체 → 1개 (Sequence Classification)
- 문서 타입 판단

BERT-NER (추출):
- 각 단어 → 각 태그 (Token Classification)
- 정보 위치 찾기
```

---

## 6. Dataset 객체 이해

### 용어 혼동 주의!

**hackathon_dataset (폴더 이름):**
```
해커톤이 주는 폴더
- 물리적 파일들
- 이미지, PDF, CSV
```

**Dataset 객체 (Python 코드):**
```python
from datasets import Dataset  # Hugging Face 라이브러리

dataset = Dataset.from_dict({...})
# AI 학습용 데이터 구조
# 코드에서 만드는 것!
```

### 왜 Dataset 객체가 필요한가?

**이유 1:** Trainer가 요구함
```python
trainer = Trainer(
    train_dataset=???  # Dataset 객체 필요!
)

# 일반 리스트는 안 됨
# Dataset 객체만 가능
```

**이유 2:** 효율적 처리
```python
# Dataset은 .map() 제공
tokenized = dataset.map(tokenize_func, batched=True)
# → 10개씩 묶어서 빠르게 처리!
```

**이유 3:** (입력, 정답) 묶기
```python
dataset = Dataset.from_dict({
    'text': ["Commercial Invoice...", "Receipt..."],  # 입력
    'label': [0, 1]  # labels.csv 정답!
})

# dataset[0] = {'text': "...", 'label': 0}
# 입력과 정답이 같이 있음!
```

---

## 7. 학습 과정 상세 (train 함수)

### Step-by-Step 흐름

**Step 1-2: 데이터 합치기 (Line 27-63)**
```python
# labels.csv 읽기
df = pd.read_csv('labels.csv')
#    filename        doc_type
# 0  inv_001.pdf    invoice
# 1  receipt_001.jpg receipt

# OCR 결과 읽기
ocr_results = json.load('training_ocr.json')
# {
#   "inv_001.pdf": {"text": "Commercial Invoice..."},
#   "receipt_001.jpg": {"text": "Receipt Store..."}
# }

# 합치기!
texts = []
labels = []

for _, row in df.iterrows():
    filename = row['filename']      # "inv_001.pdf"
    doc_type = row['doc_type']      # "invoice"
    
    text = ocr_results[filename]['text']  # "Commercial Invoice..."
    
    texts.append(text)                    # OCR 텍스트
    labels.append(self.label_to_id[doc_type])  # 정답 (0)

# 결과:
# texts = ["Commercial Invoice...", "Receipt Store..."]  ← OCR
# labels = [0, 1]  ← labels.csv 정답
```

**여기서 training_set과 labels.csv가 합쳐집니다!** ⭐

**Step 3: Dataset 생성 (Line 65-72)**
```python
dataset = Dataset.from_dict({
    'text': texts,    # OCR 텍스트
    'label': labels   # labels.csv 정답
})

# (입력, 정답) 쌍으로 묶임!
```

**Step 4: Tokenization (Line 74-86)**
```python
# 텍스트 → 숫자 변환
"Commercial Invoice..." 
→ [101, 2678, 4037, ...]

# 정답은 유지!
```

**Step 5-6: 모델 및 학습 설정 (Line 88-109)**
```python
# 모델 초기화 (멍청한 상태)
model = DistilBert...

# 학습 설정
epochs = 3
batch_size = 8
learning_rate = 2e-5
```

**Step 7: 학습 실행! (Line 111-122)** ⭐⭐⭐
```python
trainer = Trainer(
    model=model,
    train_dataset=tokenized_dataset  # (입력, 정답) 포함!
)

trainer.train()  # ← 여기서 학습!

# 내부 동작:
# Epoch 1:
#   문서 1: 예측 → 정답 비교 → 틀림 → 모델 수정
#   문서 2: 예측 → 정답 비교 → 틀림 → 모델 수정
#   ...500번...
#   평균 Loss: 0.8 (많이 틀림)

# Epoch 2:
#   같은 500개 다시!
#   평균 Loss: 0.3 (덜 틀림)

# Epoch 3:
#   평균 Loss: 0.1 (거의 안 틀림!)

# 학습 완료!
```

**Step 8: 모델 저장 (Line 124-131)**
```python
self.save_model('models/classifier')
# 똑똑해진 모델 저장!
```

---

## 8. 학습이 일어나는 방식 (Supervised Learning)

### 1 Epoch 내부 상세

```python
# 500개 문서를 8개씩 배치로

Batch 1 (문서 0-7):

문서 0:
  입력: "Commercial Invoice ABC Corp Total 1500"
  
  모델 예측 (처음):
    invoice: 40%
    receipt: 30%
    resume: 15%
    report: 10%
    contract: 5%
  
  정답 (labels.csv):
    invoice (0)
  
  Loss 계산:
    -log(0.40) = 0.92  ← 높음 (틀림!)
  
  모델 수정:
    "다음엔 invoice를 더 높게 예측해야지"
    내부 가중치 조정:
    weight[123] += 0.01
    weight[456] -= 0.005
    ...

문서 1:
  입력: "Invoice XYZ Ltd Total 2000"
  
  모델 예측:
    invoice: 45%  ← 조금 나아짐!
    receipt: 28%
    ...
  
  정답: invoice (0)
  
  Loss: -log(0.45) = 0.80  ← 조금 낮아짐
  
  모델 수정:
    "더 잘하고 있어, 이 방향 맞아"
    weight 조정...

...

문서 7:
  입력: "Receipt Supermarket Sub-total 107"
  
  모델 예측:
    receipt: 35%
    invoice: 40%  ← 틀림!
    ...
  
  정답: receipt (1)
  
  Loss: -log(0.35) = 1.05  ← 높음!
  
  모델 수정:
    "Receipt 단어 보면 receipt로 예측해야지"
    weight 조정...

Batch 1 평균 Loss: 0.89

──────────────────────────────────────

Batch 2 (문서 8-15):
  같은 과정 반복...
  
...

Batch 62 (문서 496-499):
  같은 과정 반복...

Epoch 1 끝!
전체 평균 Loss: 0.75
```

### Epoch 2 (같은 데이터 다시!)

```python
Batch 1 (문서 0-7):

문서 0 (다시!):
  입력: "Commercial Invoice ABC Corp Total 1500"
  
  모델 예측 (두 번째, 배웠으니까!):
    invoice: 75%  ← 개선됨!
    receipt: 15%
    resume: 5%
    ...
  
  정답: invoice (0)
  
  Loss: -log(0.75) = 0.29  ← 낮아짐!
  
  모델 수정:
    "잘하고 있어, 조금만 더"

문서 7:
  입력: "Receipt Supermarket..."
  
  모델 예측:
    receipt: 70%  ← 많이 개선!
    invoice: 20%
    ...
  
  정답: receipt (1)
  
  Loss: -log(0.70) = 0.36
  
...

Epoch 2 끝!
평균 Loss: 0.30
```

### Epoch 3

```python
Epoch 3 끝!
평균 Loss: 0.08  ← 매우 낮음!
정확도: 95%+

학습 완료!
```

---

## 9. 왜 VLM 대신 모듈 파이프라인?

### 기술적 비교

| 항목 | VLM | 모듈 파이프라인 |
|------|-----|----------------|
| 메모리 | 1.5-3GB | 2GB (여유) |
| 학습 시간 | 2-4시간 | 1.5시간 |
| 구현 복잡도 | 높음 | 중간 |
| 디버깅 | 어려움 | 쉬움 |
| 확장성 | 제한적 | 높음 |

### 답변 포인트

**"왜 VLM 안 썼나요?"**

```
1. 리소스 효율성
   - 실측: 643MB (목표의 21%)
   - VLM: 1.5GB+ (빡빡함)

2. 리스크 관리
   - 모듈별 독립 검증
   - 한 부분 실패해도 다른 부분은 작동
   
3. 개발 속도
   - 병렬 개발 가능
   - 빠른 반복

4. 실용성
   - 우리 use case: 단순 분류 + 필드 추출
   - VLM은 over-engineering
```

---

## 10. 분류와 추출을 분리한 이유

### 기술적 차이

**분류 (Sequence Classification):**
```python
입력: 전체 텍스트 (1개)
출력: 1개 클래스

"Commercial Invoice..." → "invoice"

모델: DistilBertForSequenceClassification
```

**추출 (Token Classification):**
```python
입력: 단어 배열 (N개)
출력: 각 단어마다 태그 (N개)

["ABC", "Corp", "1500.00"] 
→ ["B-VENDOR", "I-VENDOR", "B-AMOUNT"]

모델: BertForTokenClassification
```

**완전히 다른 문제!**

### 실용적 이유

**조건부 실행:**
```python
if doc_type in ['invoice', 'receipt']:
    extract()  # 필요할 때만
else:
    skip()     # resume는 추출 안 함
```

**과제 요구사항:**
```
분류: 5개 타입 전부
추출: 1-2개 타입만 (invoice/receipt)
```

---

## 11. 하드코딩 vs 자동화

### 고정된 것 (하드코딩 OK)

```python
# 문서 타입: 과제에서 고정
self.labels = ['invoice', 'receipt', 'resume', 'report', 'contract']
→ 수정 불필요! ✓
```

### 가변적인 것 (자동화 필요)

```python
# 추출 필드: labels.csv마다 다를 수 있음
field_columns = [col for col in df.columns 
                 if col not in ['filename', 'doc_type']]

# 케이스 1: ['vendor', 'invoice_date', 'total_amount']
# 케이스 2: ['company_name', 'issue_date', 'grand_total']

→ 자동 파악 필요! ✓
```

---

## 12. 전체 워크플로우 요약

### 해커톤 당일 실행 순서

```bash
# 09:00 - 데이터 받기
hackathon_dataset/ 받음

# 09:30 - OCR 처리 (30분)
python src/batch_ocr.py \
  --input training_set/documents \
  --output outputs/training_ocr.json

# 결과: 500개 이미지 → 500개 텍스트

# 10:00 - 분류 모델 학습 (30분)
python src/train_classifier.py \
  --labels training_set/labels.csv \
  --ocr outputs/training_ocr.json \
  --output models/classifier

# 내부에서 classifier.train() 실행:
# 1. labels.csv + training_ocr.json 합치기
# 2. Dataset 생성 (입력, 정답)
# 3. trainer.train() 실행
#    - Epoch 1: Loss 0.8
#    - Epoch 2: Loss 0.3
#    - Epoch 3: Loss 0.1
# 4. 모델 저장

# 10:30 - 추출 모델 학습 (1시간)
python src/train_extractor.py ...
# (비슷한 과정)

# 11:30 - 테스트셋 예측 (10분)
python src/predict.py \
  --input testing_set/documents \
  --classifier models/classifier \
  --extractor models/extractor \
  --output predictions.json

# 내부에서:
# 1. testing_set OCR
# 2. classifier.classify() - 예측 (정답 모름!)
# 3. extractor.extract() - 예측
# 4. 결과 저장

# 11:40 - 제출
predictions.json 제출
```

---

## 13. 코드별 역할 정리

### ocr_module.py
```
역할: 이미지/PDF → 텍스트 변환
입력: 파일 경로
출력: {'text': '...', 'confidence': 0.95}
상태: 완료 ✅
```

### batch_ocr.py
```
역할: 폴더 내 모든 파일 자동 OCR
입력: 폴더 경로
출력: JSON 파일 (파일명별 OCR 결과)
상태: 완료 ✅
```

### classification_module.py
```
역할: 문서 타입 분류

__init__():
  - tokenizer, labels 초기화
  
train(labels_csv, ocr_results):
  - labels.csv와 OCR 결과 합치기
  - DistilBERT 학습 (30분)
  - 모델 저장
  
classify(text):
  - 텍스트 → doc_type 예측
  - 학습된 모델 사용
  
상태: 완료 ✅
```

---

## 14. 성능 측정 결과

### 분류 모듈 (classification_module.py)

```
메모리 사용량: 643MB
처리 속도: ~0.5초/문서
모델 크기: 268MB
평가: S급 ✅

효율적인 이유:
1. torch.no_grad() 사용 (메모리 50% 절약)
2. DistilBERT 선택 (BERT 대비 40% 경량)
3. 효율적 토크나이저 설정
4. Mac M1/M2 최적화 가능 (Metal GPU)

전체 파이프라인 예상:
- OCR: 300MB
- 분류: 643MB
- 추출: 800MB
- 총합: ~2GB (목표 3GB 이하 ✓)
```

---

## 15. 주요 개념 정리

### Epoch
```
전체 데이터를 한 번 다 보는 것
Epoch 3 = 500개 문서를 3번 반복
```

### Loss
```
모델이 얼마나 틀렸는지
Loss 높음 = 많이 틀림
Loss 낮음 = 잘 맞춤
학습 목표: Loss 최소화
```

### Batch
```
한 번에 처리하는 개수
batch_size=8: 8개씩 묶어서 처리
메모리 효율 + 속도 향상
```

### Learning Rate
```
학습 속도
2e-5 = 0.00002 (천천히 배움)
너무 크면: 불안정
너무 작으면: 느림
```

### Fine-tuning
```
사전학습 모델을 우리 데이터로 재학습
처음부터 학습 (X)
기존 지식 + 새 지식 (O)
```

---

## 16. 중요한 오해 정리

### 오해 1: "이미지로 학습한다?"
```
❌ 틀림: 이미지를 직접 모델에 입력
✅ 맞음: OCR로 텍스트 변환 후 학습
```

### 오해 2: "예측 후 정답 비교?"
```
❌ 틀림: 
   testing_set 예측 → labels.csv 비교 → 학습

✅ 맞음:
   training_set으로 학습 (정답 미리 봄)
   → testing_set 예측 (정답 모름, 제출)
   → 주최측이 채점
```

### 오해 3: "Dataset = 해커톤 데이터?"
```
❌ hackathon_dataset: 폴더 (물리적 파일)
✅ Dataset 객체: Python 변수 (코드에서 생성)
```

### 오해 4: "VLM 필수?"
```
❌ 과제 요구사항 아님
✅ 오픈소스 AI 사용하면 됨
✅ DistilBERT, BERT-NER도 AI
```

---

## 17. __pycache__ 폴더

```
자동 생성: Python이 만듦
역할: 컴파일된 바이트코드 캐시
목적: 두 번째 실행부터 빠르게
삭제 가능: 자동으로 재생성됨
.gitignore 추가 권장
```

---

## 18. 파이썬 기초 개념

### self
```python
class Car:
    def __init__(self):
        self.color = "red"  # 나의 색깔
    
    def paint(self, new_color):
        self.color = new_color  # 나의 색깔 변경

# self = "나 자신"
```

### enumerate()
```python
labels = ['invoice', 'receipt', 'resume']

for i, label in enumerate(labels):
    print(i, label)

# 출력:
# 0 invoice
# 1 receipt
# 2 resume
```

### 딕셔너리 컴프리헨션
```python
labels = ['invoice', 'receipt']
label_to_id = {label: i for i, label in enumerate(labels)}
# {'invoice': 0, 'receipt': 1}

# 같은 의미:
label_to_id = {}
for i, label in enumerate(labels):
    label_to_id[label] = i
```

### with 문
```python
with open('file.json') as f:
    data = json.load(f)
# 파일 자동으로 닫힘 (안전)

# 같은 의미:
f = open('file.json')
data = json.load(f)
f.close()  # 직접 닫아야 함
```

---

## 19. 진행 상황 체크리스트

### 완료된 작업 ✅
```
- [x] OCR 모듈 (ocr_module.py)
- [x] 배치 OCR (batch_ocr.py)
- [x] 분류 모듈 (classification_module.py)
  - [x] __init__()
  - [x] classify()
  - [x] save_model()
  - [x] load_model()
  - [x] train()
- [x] 긴급 수정 가이드
```

### 남은 작업 ⏳
```
- [ ] train_classifier.py (학습 스크립트)
- [ ] extraction_module.py (추출 모듈)
- [ ] train_extractor.py
- [ ] main.py (통합)
- [ ] predict.py (예측)
```

### 진행률: 75%

---

## 20. 다음 작업 미리보기

### train_classifier.py (다음 작업)

```python
# 당일 실행용 간단한 스크립트
import argparse
from classification_module import DocumentClassifier

parser = argparse.ArgumentParser()
parser.add_argument('--labels', required=True)
parser.add_argument('--ocr', required=True)
args = parser.parse_args()

classifier = DocumentClassifier()
classifier.train(args.labels, args.ocr)

# 실행:
# python train_classifier.py \
#   --labels labels.csv \
#   --ocr training_ocr.json
```

**난이도:** ⭐ (매우 쉬움, 30분)
**중요도:** ⭐⭐⭐ (당일 필수)

---

## 21. 참고 자료

### Hugging Face 블로그 분석

**주요 발견:**
- 최신 VLM: OlmOCR-2, Granite-Docling, Nanonets
- MLX: Mac M1/M2 최적화 (선택 가능)
- Markdown 출력: LLM 입력에 적합 (우리 선택 검증)
- 배치 처리: 중요성 강조 (우리가 구현함)

**결론:** 우리 전략이 검증됨 ✅

---

## 22. 중요 팁

### 테스트 전략
```
test_samples: 코드 동작 확인용
- 4개 샘플만
- 학습 안 함
- 정답 없음

당일 데이터: 실제 학습/예측용
- 500-1000개
- 학습 함!
- training_set만 정답 있음
```

### 당일 체크리스트
```
□ labels.csv 구조 확인 (5분)
□ 긴급_수정_가이드.md 참고
□ batch_ocr.py 실행 (30분)
□ train_classifier.py 실행 (30분)
□ train_extractor.py 실행 (1시간)
□ predict.py 실행 (10분)
□ 제출!
```

---

## 23. 발표 대비 답변

### "왜 3단계 파이프라인?"

**답변:**
```
1. 관심사 분리 (Separation of Concerns)
   - OCR: 텍스트 추출 전문
   - 분류: 타입 판단 전문
   - 추출: 필드 추출 전문

2. 리스크 관리
   - 모듈별 독립 검증
   - 부분 실패 시 대응 가능

3. 리소스 효율
   - 실측: 643MB (메모리 S급)
   - 조건부 실행 (필요할 때만)

4. 개발 속도
   - 병렬 개발
   - 빠른 디버깅
```

---

## 24. 마지막 정리

### 오늘 배운 핵심

```
1. 학습 = 정답 보면서 공부 (training_set + labels.csv)
2. 예측 = 정답 모르고 시험 (testing_set만)
3. labels.csv = 학습용 정답지 (미리 제공)
4. Dataset 객체 = AI 학습용 데이터 구조 (코드에서 생성)
5. trainer.train() = 실제 학습이 일어나는 곳
6. 모듈화 = 안정성 + 효율성
```

### 완성된 코드

```
✅ ocr_module.py (171줄)
✅ batch_ocr.py (79줄)
✅ classification_module.py (213줄)
✅ docs/긴급_수정_가이드.md

총 진행률: 75%
```

---

**이 문서를 나중에 참고하세요!** 📖

