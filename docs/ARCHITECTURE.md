# ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ğŸ“

## ğŸ“‹ ëª©ì°¨

1. [ì „ì²´ ë°ì´í„° íë¦„](#ì „ì²´-ë°ì´í„°-íë¦„)
2. [ëª¨ë“ˆë³„ ìƒì„¸ ì„¤ëª…](#ëª¨ë“ˆë³„-ìƒì„¸-ì„¤ëª…)
3. [í•¨ìˆ˜ë³„ ì„¤ëª…](#í•¨ìˆ˜ë³„-ì„¤ëª…)
4. [í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ](#í…ŒìŠ¤íŠ¸-ê°€ì´ë“œ)
5. [ì„±ëŠ¥ ë° ìµœì í™”](#ì„±ëŠ¥-ë°-ìµœì í™”)

---

## ğŸŒŠ ì „ì²´ ë°ì´í„° íë¦„

### ì‹œê°ì  íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë¬¸ì„œ ì´ë¯¸ì§€     â”‚ (invoice.jpg, receipt.png, ...)
â”‚  (JPG/PNG/PDF)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1ë‹¨ê³„: OCR (ocr_module.py)                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  â€¢ PaddleOCR ì‚¬ìš©                                   â”‚
â”‚  â€¢ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (íšŒìƒ‰ì¡°, ë…¸ì´ì¦ˆ ì œê±°, CLAHE)         â”‚
â”‚  â€¢ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜                                 â”‚
â”‚  â€¢ í…ìŠ¤íŠ¸ ì¶”ì¶œ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ {"text": "Invoice\nCompany: ABC...", 
         â”‚  "confidence": 0.97}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2ë‹¨ê³„: ë¶„ë¥˜ (classification_module.py)             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  â€¢ DistilBERT ì‚¬ìš©                                  â”‚
â”‚  â€¢ í…ìŠ¤íŠ¸ â†’ í† í°í™” â†’ ë²¡í„°                            â”‚
â”‚  â€¢ 5ê°€ì§€ ë¬¸ì„œ íƒ€ì… ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜                     â”‚
â”‚    (invoice, receipt, resume, report, contract)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ {"doc_type": "invoice", 
         â”‚  "confidence": 0.96}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3ë‹¨ê³„: ì¶”ì¶œ (extraction_module.py)                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  â€¢ BERT-NER ì‚¬ìš©                                    â”‚
â”‚  â€¢ ë¬¸ì„œ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ì •ë³´ ì¶”ì¶œ                    â”‚
â”‚  â€¢ invoice/receiptë§Œ êµ¬ì¡°í™” ì¶”ì¶œ                     â”‚
â”‚  â€¢ ë‚˜ë¨¸ì§€ëŠ” ë¹ˆ ê°ì²´ {}                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ {"vendor": "ABC Exports", 
         â”‚  "amount": 13000.0, 
         â”‚  "date": "2030-09-30"}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ìµœì¢… JSON ì¶œë ¥                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  {                                                  â”‚
â”‚    "filename": "invoice.jpg",                       â”‚
â”‚    "full_text_ocr": "...",                          â”‚
â”‚    "classification": {...},                         â”‚
â”‚    "extracted_data": {...}                          â”‚
â”‚  }                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ ëª¨ë“ˆë³„ ìƒì„¸ ì„¤ëª…

### 1. `ocr_module.py` - OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ

**ì—­í• **: ì´ë¯¸ì§€/PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ëƒ…ë‹ˆë‹¤

**ì‚¬ìš© ê¸°ìˆ **: PaddleOCR (ì¤‘êµ­ Baiduì—ì„œ ë§Œë“  ì˜¤í”ˆì†ŒìŠ¤ OCR)

**í•µì‹¬ í´ë˜ìŠ¤**: `OCRModule`

#### ì™œ PaddleOCR?
- âœ… CPUì—ì„œë„ ë¹ ë¦„
- âœ… ì˜ì–´ + í•œê¸€ + ì¤‘êµ­ì–´ ì§€ì›
- âœ… ì†ê¸€ì”¨ ì–´ëŠì •ë„ ì¸ì‹
- âœ… ì„¤ì¹˜ ê°„ë‹¨

#### ì²˜ë¦¬ ê³¼ì •

```python
ì…ë ¥ ì´ë¯¸ì§€ 
  â†’ íšŒìƒ‰ì¡° ë³€í™˜ (ìƒ‰ìƒ ì œê±°, í…ìŠ¤íŠ¸ ê°•ì¡°)
  â†’ ë…¸ì´ì¦ˆ ì œê±° (ì–¼ë£© ì œê±°)
  â†’ CLAHE (ëª…ì•” ëŒ€ë¹„ í–¥ìƒ)
  â†’ PaddleOCR ì‹¤í–‰
  â†’ í…ìŠ¤íŠ¸ + ì‹ ë¢°ë„ ë°˜í™˜
```

#### ì£¼ìš” í•¨ìˆ˜

**`__init__()`**
```python
def __init__(self):
    self.ocr = PaddleOCR(use_angle_cls=True, lang='en')
```
- PaddleOCR ëª¨ë¸ ì´ˆê¸°í™”
- `use_angle_cls=True`: íšŒì „ëœ í…ìŠ¤íŠ¸ë„ ì¸ì‹
- `lang='en'`: ì˜ì–´ ëª¨ë¸ ì‚¬ìš©

**`preprocess_image(image_path)`**
```python
def preprocess_image(self, image_path):
    # 1. ì´ë¯¸ì§€ ë¡œë“œ
    img = cv2.imread(image_path)
    
    # 2. íšŒìƒ‰ì¡° ë³€í™˜ (BGR â†’ Gray)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # 3. ë…¸ì´ì¦ˆ ì œê±° (ì–¼ë£© ì œê±°)
    denoised = cv2.fastNlMeansDenoising(gray)
    
    # 4. CLAHE (ëª…ì•” ëŒ€ë¹„ í–¥ìƒ)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(denoised)
    
    return enhanced
```
- **ì™œ íšŒìƒ‰ì¡°?** OCRì€ ìƒ‰ìƒì´ í•„ìš”ì—†ê³ , í‘ë°±ì´ ë” ì •í™•
- **ì™œ ë…¸ì´ì¦ˆ ì œê±°?** ìŠ¤ìº” ë¬¸ì„œì˜ ì–¼ë£©ì´ ê¸€ìë¡œ ì˜¤ì¸ë  ìˆ˜ ìˆìŒ
- **CLAHEê°€ ë­ì§€?** Contrast Limited Adaptive Histogram Equalization - ì–´ë‘ìš´ ë¶€ë¶„ì„ ë°ê²Œ, ë°ì€ ë¶€ë¶„ì„ ì–´ë‘¡ê²Œ í•´ì„œ í…ìŠ¤íŠ¸ ëª…í™•í•˜ê²Œ

**`extract_text(file_path)`** (í•µì‹¬!)
```python
def extract_text(self, file_path):
    # PDFë©´ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    if file_path.endswith('.pdf'):
        img = self.pdf_to_image(file_path)
    else:
        img = self.preprocess_image(file_path)
    
    # OCR ì‹¤í–‰
    result = self.ocr.ocr(img, cls=False)
    
    # ê²°ê³¼ íŒŒì‹±
    lines = []
    confidences = []
    for line in result[0]:
        bbox, (text, conf) = line
        lines.append(text)
        confidences.append(conf)
    
    return {
        'text': '\n'.join(lines),
        'confidence': avg(confidences),
        'processing_time': elapsed_time
    }
```

**ë°˜í™˜ ì˜ˆì‹œ**:
```json
{
  "text": "Commercial Invoice\nCompany: ABC...",
  "confidence": 0.97,
  "processing_time": 2.3
}
```

---

### 2. `classification_module.py` - ë¬¸ì„œ ë¶„ë¥˜

**ì—­í• **: OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ë¬¸ì„œ ì¢…ë¥˜ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤

**ì‚¬ìš© ê¸°ìˆ **: DistilBERT (BERTì˜ ê²½ëŸ‰í™” ë²„ì „)

**í•µì‹¬ í´ë˜ìŠ¤**: `DocumentClassifier`

#### ì™œ DistilBERT?
- âœ… BERTë³´ë‹¤ 40% ë¹ ë¦„
- âœ… ë©”ëª¨ë¦¬ 60% ì ˆì•½
- âœ… ì •í™•ë„ëŠ” BERTì˜ 97% ìœ ì§€
- âœ… CPUì—ì„œë„ ì‹¤ìš©ì 

#### AI í•™ìŠµ ì›ë¦¬ (ì´ˆë³´ììš© ì„¤ëª…)

**ë¹„ìœ **: ê°•ì•„ì§€ vs ê³ ì–‘ì´ êµ¬ë¶„ í•™ìŠµ

```
í•™ìŠµ ì „:
ì‚¬ì§„ ë³´ì—¬ì£¼ë©´ â†’ "ëª¨ë¥´ê² ì–´ìš”..." ğŸ˜µ

í•™ìŠµ ë°ì´í„°:
[ì‚¬ì§„1, "ê°•ì•„ì§€"] â† ì •ë‹µ ì•Œë ¤ì¤Œ
[ì‚¬ì§„2, "ê³ ì–‘ì´"]
[ì‚¬ì§„3, "ê°•ì•„ì§€"]
... 1000ë²ˆ ë°˜ë³µ ...

í•™ìŠµ í›„:
ìƒˆë¡œìš´ ì‚¬ì§„ ë³´ì—¬ì£¼ë©´ â†’ "ì´ê±´ ê°•ì•„ì§€! (95% í™•ì‹ )" ğŸ¯
```

**ìš°ë¦¬ í”„ë¡œì íŠ¸**:
```
í•™ìŠµ ë°ì´í„°:
["Invoice text...", "invoice"] â† labels.csvì˜ ì •ë‹µ
["Receipt text...", "receipt"]
... 500-1000ê°œ ...

í•™ìŠµ í›„:
ìƒˆ ë¬¸ì„œ í…ìŠ¤íŠ¸ ë³´ì—¬ì£¼ë©´ â†’ "invoiceì…ë‹ˆë‹¤! (96% í™•ì‹ )"
```

#### ì£¼ìš” í•¨ìˆ˜

**`__init__()`**
```python
def __init__(self):
    self.model_name = 'distilbert-base-uncased'
    self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
    self.labels = ['invoice', 'receipt', 'resume', 'report', 'contract']
    self.model = None  # í•™ìŠµ or ë¡œë“œ ì „ê¹Œì§€ None
```

**`train(labels_csv_path, ocr_results_path, output_dir)`** (ì¤‘ìš”!)

ì´ í•¨ìˆ˜ê°€ AIë¥¼ í•™ìŠµì‹œí‚µë‹ˆë‹¤!

```python
def train(self, labels_csv, ocr_results, output_dir):
    # Step 1: ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(labels_csv)  # ì •ë‹µ ë ˆì´ë¸”
    ocr = json.load(ocr_results)  # OCR í…ìŠ¤íŠ¸
    
    # Step 2: í•™ìŠµ ë°ì´í„° ì¤€ë¹„
    texts = []
    labels = []
    for _, row in df.iterrows():
        filename = row['filename']
        doc_type = row['doc_type']
        text = ocr[filename]['text']
        
        texts.append(text)
        labels.append(self.label_to_id[doc_type])
    
    # Step 3: Dataset ìƒì„± (AIê°€ ì½ì„ ìˆ˜ ìˆëŠ” í˜•ì‹)
    dataset = Dataset.from_dict({
        'text': texts,
        'label': labels
    })
    
    # Step 4: Tokenization (ë‹¨ì–´ â†’ ìˆ«ì)
    def tokenize_function(examples):
        return self.tokenizer(
            examples['text'],
            padding='max_length',
            truncation=True,
            max_length=512
        )
    tokenized_dataset = dataset.map(tokenize_function, batched=True)
    
    # Step 5: ëª¨ë¸ ì´ˆê¸°í™”
    self.model = DistilBertForSequenceClassification.from_pretrained(
        self.model_name,
        num_labels=5  # 5ê°€ì§€ ë¬¸ì„œ íƒ€ì…
    )
    
    # Step 6: í•™ìŠµ ì„¤ì •
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=3,      # ì „ì²´ ë°ì´í„° 3ë²ˆ ë°˜ë³µ
        per_device_train_batch_size=8,  # í•œë²ˆì— 8ê°œì”©
        learning_rate=2e-5,      # í•™ìŠµ ì†ë„
    )
    
    # Step 7: í•™ìŠµ ì‹¤í–‰! (30-60ë¶„)
    trainer = Trainer(
        model=self.model,
        args=training_args,
        train_dataset=tokenized_dataset,
    )
    trainer.train()  # ì‹¤ì œ í•™ìŠµ ì‹œì‘
    
    # Step 8: ëª¨ë¸ ì €ì¥
    self.save_model(output_dir)
```

**í•™ìŠµ ê³¼ì • ì„¤ëª…**:

1. **Epoch 1 (1ë²ˆì§¸ ë°˜ë³µ)**
   - ëª¨ë¸: "InvoiceëŠ” ì•„ë§ˆ 'invoice' ì¼ê¹Œ?" (60% í™•ì‹ )
   - ì •ë‹µ: "ë§ì•„!" â†’ ëª¨ë¸ ì¡°ê¸ˆ ê°œì„ 

2. **Epoch 2 (2ë²ˆì§¸ ë°˜ë³µ)**
   - ëª¨ë¸: "InvoiceëŠ” 'invoice'!" (85% í™•ì‹ )
   - ì •ë‹µ: "ë§ì•„!" â†’ ëª¨ë¸ ë” ê°œì„ 

3. **Epoch 3 (3ë²ˆì§¸ ë°˜ë³µ)**
   - ëª¨ë¸: "InvoiceëŠ” 'invoice'!" (96% í™•ì‹ )
   - ì •ë‹µ: "ë§ì•„!" â†’ í•™ìŠµ ì™„ë£Œ!

**`classify(text)`** (ì˜ˆì¸¡!)

í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆ ë¬¸ì„œ ë¶„ë¥˜:

```python
def classify(self, text):
    # 1. í…ìŠ¤íŠ¸ â†’ ìˆ«ì (í† í°í™”)
    inputs = self.tokenizer(text, return_tensors='pt', 
                            truncation=True, max_length=512)
    
    # 2. ëª¨ë¸ ì‹¤í–‰
    with torch.no_grad():
        outputs = self.model(**inputs)
    
    # 3. ê²°ê³¼ í•´ì„
    logits = outputs.logits[0]
    probabilities = torch.nn.functional.softmax(logits, dim=0)
    
    # 4. ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ
    predicted_id = torch.argmax(probabilities).item()
    confidence = probabilities[predicted_id].item()
    
    return {
        'doc_type': self.id_to_label[predicted_id],
        'confidence': confidence
    }
```

**ì˜ˆì‹œ**:
```python
text = "Commercial Invoice\nCompany: ABC..."
result = classifier.classify(text)
# {"doc_type": "invoice", "confidence": 0.96}
```

---

### 3. `extraction_module.py` - êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ

**ì—­í• **: í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì •ë³´(ê¸ˆì•¡, ë‚ ì§œ, íšŒì‚¬ëª… ë“±)ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤

**ì‚¬ìš© ê¸°ìˆ **: BERT-NER (Named Entity Recognition)

**í•µì‹¬ í´ë˜ìŠ¤**: `DataExtractor`

#### NERì´ ë­”ê°€ìš”?

**ë¹„ìœ **: í˜•ê´‘íœìœ¼ë¡œ ì¤‘ìš” ë¶€ë¶„ í‘œì‹œí•˜ê¸°

```
í…ìŠ¤íŠ¸: "John Smith works at Apple in New York."

ì‚¬ëŒì´ ë³´ë©´:
- "John Smith" â†’ ì‚¬ëŒ ì´ë¦„
- "Apple" â†’ íšŒì‚¬
- "New York" â†’ ì¥ì†Œ

NER ëª¨ë¸:
- "John Smith" â†’ [PER] (Person)
- "Apple" â†’ [ORG] (Organization)
- "New York" â†’ [LOC] (Location)
```

#### ì£¼ìš” í•¨ìˆ˜

**`configure_from_labels(labels_csv)`** (í•µì‹¬!)

labels.csvë¥¼ ë³´ê³  ë¬´ì—‡ì„ ì¶”ì¶œí• ì§€ ìë™ìœ¼ë¡œ íŒŒì•…:

```python
def configure_from_labels(self, labels_csv):
    df = pd.read_csv(labels_csv)
    
    # labels.csv ì˜ˆì‹œ:
    # filename, doc_type, vendor, amount, date
    # inv1.pdf, invoice, ABC, 1500, 2025-01-01
    
    for doc_type in df['doc_type'].unique():
        # 'filename', 'doc_type' ì œì™¸í•œ ë‚˜ë¨¸ì§€ê°€ ì¶”ì¶œí•  í•„ë“œ
        fields = [col for col in df.columns 
                  if col not in ['filename', 'doc_type']]
        
        self.extraction_config[doc_type] = fields
    
    # ê²°ê³¼:
    # self.extraction_config = {
    #     'invoice': ['vendor', 'amount', 'date'],
    #     'receipt': ['store', 'total', 'date']
    # }
```

**ì™œ ë™ì ìœ¼ë¡œ?**
- í•´ì»¤í†¤ ë‹¹ì¼ labels.csvê°€ ì–´ë–»ê²Œ ë‚˜ì˜¬ì§€ ëª¨ë¦„
- invoiceê°€ ì•„ë‹ˆë¼ resumeì¼ ìˆ˜ë„ ìˆìŒ
- í•„ë“œê°€ 'vendor'ê°€ ì•„ë‹ˆë¼ 'company'ì¼ ìˆ˜ë„ ìˆìŒ
- â†’ ìë™ìœ¼ë¡œ ì ì‘!

**`_run_ner(text)`** (NER ì‹¤í–‰)

```python
def _run_ner(self, text):
    # 1. BERT ëª¨ë¸ì— í…ìŠ¤íŠ¸ ì…ë ¥
    tokens = self.tokenizer(text, return_tensors='pt')
    outputs = self.model(**tokens)
    
    # 2. ê° ë‹¨ì–´ì— ë ˆì´ë¸” ì˜ˆì¸¡
    predictions = torch.argmax(outputs.logits, dim=2)
    
    # 3. ì—”í‹°í‹° ë¶„ë¥˜
    entities = {'PER': [], 'ORG': [], 'LOC': [], 'MISC': []}
    
    for token, label in zip(tokens, predictions):
        if label == 'B-PER':  # Person ì‹œì‘
            entities['PER'].append(token)
        elif label == 'B-ORG':  # Organization ì‹œì‘
            entities['ORG'].append(token)
        # ...
    
    return entities
    # {'PER': ['John Smith'], 'ORG': ['ABC Exports'], ...}
```

**`extract(text, doc_type)`** (ìµœì¢… ì¶”ì¶œ)

```python
def extract(self, text, doc_type):
    # ì´ ë¬¸ì„œ íƒ€ì…ì€ ì¶”ì¶œ ì•ˆ í•¨ (resume, report ë“±)
    if doc_type not in self.extraction_config:
        return {}
    
    # NERë¡œ ì—”í‹°í‹° ì°¾ê¸°
    entities = self._run_ner(text)
    # {'PER': [], 'ORG': ['ABC Exports'], ...}
    
    # ì •ê·œì‹ìœ¼ë¡œ ë‚ ì§œ/ê¸ˆì•¡ íŒ¨í„´ ì°¾ê¸°
    patterns = self._extract_patterns(text)
    # {'dates': ['2030-09-30'], 'amounts': ['$13,000'], ...}
    
    # í•„ë“œë³„ë¡œ ì ì ˆí•œ ê°’ ë§¤ì¹­
    result = {}
    for field in self.extraction_config[doc_type]:
        # 'vendor' í•„ë“œ â†’ ORG ì—”í‹°í‹° ì‚¬ìš©
        # 'amount' í•„ë“œ â†’ íŒ¨í„´ì—ì„œ ê°€ì¥ í° ê¸ˆì•¡
        # 'date' í•„ë“œ â†’ íŒ¨í„´ì—ì„œ ì²« ë‚ ì§œ
        result[field] = self._match_field(field, entities, patterns)
    
    return result
    # {'vendor': 'ABC Exports', 'amount': 13000, 'date': '2030-09-30'}
```

---

### 4. `batch_ocr.py` - ì¼ê´„ OCR ì²˜ë¦¬

**ì—­í• **: í´ë” ì•ˆì˜ ëª¨ë“  ë¬¸ì„œë¥¼ í•œë²ˆì— OCR ì²˜ë¦¬

**ì–¸ì œ ì‚¬ìš©?**: í•´ì»¤í†¤ ë‹¹ì¼ training_set/testing_set ë°›ì•˜ì„ ë•Œ

```python
python src/batch_ocr.py \
  --input training_set/documents \
  --output outputs/training_ocr.json
```

**ë™ì‘**:
```python
# 1. í´ë” ìŠ¤ìº”
files = ['doc1.jpg', 'doc2.png', 'doc3.pdf', ...]

# 2. ê° íŒŒì¼ OCR (ì§„í–‰ë°” í‘œì‹œ)
for file in tqdm(files):
    result = ocr.extract_text(file)
    results[file.name] = result

# 3. JSON ì €ì¥
# {
#   "doc1.jpg": {"text": "...", "confidence": 0.97},
#   "doc2.png": {"text": "...", "confidence": 0.95},
#   ...
# }
```

---

### 5. `train_classifier.py` - ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ

**ì—­í• **: DocumentClassifier.train()ì„ ëª…ë ¹ì¤„ì—ì„œ ì‹¤í–‰

```python
python src/train_classifier.py \
  --labels training_set/labels.csv \
  --ocr outputs/training_ocr.json \
  --output models/classifier
```

**ë‚´ë¶€ ë™ì‘**:
```python
classifier = DocumentClassifier()
classifier.train(
    labels_csv_path=args.labels,
    ocr_results_path=args.ocr,
    output_dir=args.output
)
```

---

### 6. `main.py` - í†µí•© íŒŒì´í”„ë¼ì¸ (ë‹¨ì¼ ë¬¸ì„œ)

**ì—­í• **: OCR + ë¶„ë¥˜ + ì¶”ì¶œì„ í•œë²ˆì— ì‹¤í–‰

```python
python src/main.py \
  --input invoice.jpg \
  --classifier models/classifier \
  --output result.json
```

**í•µì‹¬ í•¨ìˆ˜**: `process_document()`

```python
def process_document(image_path, ocr, classifier, extractor):
    # Step 1: OCR
    ocr_result = ocr.extract_text(image_path)
    
    # Step 2: ë¶„ë¥˜
    classification = classifier.classify(ocr_result['text'])
    
    # Step 3: ì¶”ì¶œ
    extracted_data = {}
    if extractor:
        extracted_data = extractor.extract(
            ocr_result['text'],
            classification['doc_type']
        )
    
    # Step 4: ê²°ê³¼ ì¡°í•©
    return {
        'filename': filename,
        'full_text_ocr': ocr_result['text'],
        'classification': classification,
        'extracted_data': extracted_data
    }
```

---

### 7. `predict.py` - ì¼ê´„ ì˜ˆì¸¡ (ì œì¶œìš©)

**ì—­í• **: testing_set ì „ì²´ë¥¼ ì²˜ë¦¬í•´ì„œ predictions.json ìƒì„±

```python
python src/predict.py \
  --input testing_set/documents \
  --classifier models/classifier \
  --labels training_set/labels.csv \
  --output predictions.json
```

**ë™ì‘**:
```python
# 1. ëª¨ë“ˆ ì´ˆê¸°í™”
ocr = OCRModule()
classifier = DocumentClassifier()
classifier.load_model(args.classifier)
extractor = DataExtractor()
extractor.configure_from_labels(args.labels)

# 2. ëª¨ë“  ë¬¸ì„œ ì²˜ë¦¬
results = []
for file in files:
    result = process_document(file, ocr, classifier, extractor)
    results.append(result)

# 3. JSON ì €ì¥
json.dump(results, open(args.output, 'w'))
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### í…ŒìŠ¤íŠ¸ 1: OCRë§Œ í…ŒìŠ¤íŠ¸

```bash
python -c "
from src.ocr_module import OCRModule
ocr = OCRModule()
result = ocr.extract_text('test_samples/sample1.jpg')
print(result)
"
```

**ì˜ˆìƒ ì¶œë ¥**:
```json
{
  "text": "Commercial Invoice\nCompany: ABC Exports...",
  "confidence": 0.97,
  "processing_time": 2.3
}
```

**í•´ì„**:
- `confidence: 0.97` â†’ 97% ì‹ ë¢°ë„, ë§¤ìš° ì¢‹ìŒ!
- `processing_time: 2.3` â†’ 2.3ì´ˆ ê±¸ë¦¼

---

### í…ŒìŠ¤íŠ¸ 2: ì¶”ì¶œ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸

```bash
python quick_test.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```
============================================================
Testing Extraction Module
============================================================

[Step 1] Initializing...
Loading NER model...
âœ“ Success!

[Step 2] Testing NER...
Entities found:
  ORG: ['ABC Exports Ltd']

[Step 3] Testing patterns...
  Dates: []
  Amounts: ['$13,000.00']
  Currency: USD

============================================================
âœ“ All tests passed!
============================================================
```

**í•´ì„**:
- `ORG: ['ABC Exports Ltd']` â†’ íšŒì‚¬ëª… ì°¾ìŒ!
- `Amounts: ['$13,000.00']` â†’ ê¸ˆì•¡ ì°¾ìŒ!
- `Currency: USD` â†’ í†µí™” ê°ì§€!

---

### í…ŒìŠ¤íŠ¸ 3: ì‹¤ì œ OCR ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸

```bash
python test_with_ocr.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```
ğŸ“„ sample1.jpg
   Text length: 1022 chars
   Confidence: 97.04%

   Entities found:
   â†’ Organizations: ['ABC Exports Ltd', 'XYZ Importers Inc']
   â†’ Persons: []
   â†’ Locations: ['Export City', 'Import City']

   Patterns found:
   â†’ Dates: ['2030-09-30']
   â†’ Amounts: ['$5,000.00', '$4,500.00', '$13,000.00']
   â†’ Currency: USD
```

**í•´ì„**:
- **Text length**: OCRë¡œ ì¶”ì¶œí•œ ê¸€ì ìˆ˜
- **Confidence**: OCR ì‹ ë¢°ë„ (90% ì´ìƒ ì¢‹ìŒ)
- **Organizations**: NERì´ ì°¾ì€ íšŒì‚¬ëª…
- **Amounts**: ì •ê·œì‹ìœ¼ë¡œ ì°¾ì€ ëª¨ë“  ê¸ˆì•¡
- **ê°€ì¥ í° ê¸ˆì•¡** ($13,000)ì´ ìµœì¢… 'total_amount'ê°€ ë¨

---

## ğŸ“Š ì„±ëŠ¥ ë° ìµœì í™”

### í˜„ì¬ ì„±ëŠ¥ (M1 Mac ê¸°ì¤€)

| ì‘ì—… | ì‹œê°„ | ë©”ëª¨ë¦¬ |
|------|------|--------|
| OCR (ë‹¨ì¼ ë¬¸ì„œ) | 2-5ì´ˆ | 200MB |
| ë¶„ë¥˜ (ì˜ˆì¸¡) | 0.3ì´ˆ | 643MB |
| ì¶”ì¶œ (ì˜ˆì¸¡) | 0.2ì´ˆ | 433MB |
| **ì „ì²´ íŒŒì´í”„ë¼ì¸** | **3-6ì´ˆ** | **~1GB** |

### ëŒ€ëŸ‰ ì²˜ë¦¬ (1000ê°œ ë¬¸ì„œ)

| ì‘ì—… | ì˜ˆìƒ ì‹œê°„ |
|------|-----------|
| OCR (1000ê°œ) | 40-80ë¶„ |
| ë¶„ë¥˜ í•™ìŠµ (500-1000ê°œ) | 30-60ë¶„ |
| ì˜ˆì¸¡ (100ê°œ) | 10-15ë¶„ |
| **ì „ì²´ (OCR+í•™ìŠµ+ì˜ˆì¸¡)** | **80-155ë¶„ (1.3-2.6ì‹œê°„)** |

### ìµœì í™” íŒ

1. **OCR ë³‘ë ¬ ì²˜ë¦¬**: 4ê°œ ì½”ì–´ ì‚¬ìš©ì‹œ 4ë°° ë¹ ë¦„
2. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: GPU ìˆìœ¼ë©´ batch_size 16ìœ¼ë¡œ ì¦ê°€
3. **Epoch ì¤„ì´ê¸°**: ì‹œê°„ ë¶€ì¡±ì‹œ 3 â†’ 2ë¡œ ê°ì†Œ (ì •í™•ë„ ì•½ê°„ í•˜ë½)

---

## ğŸ› ìì£¼ ë°œìƒí•˜ëŠ” ì´ìŠˆ

### 1. OCR ì‹ ë¢°ë„ ë‚®ìŒ (< 80%)

**ì›ì¸**: ì´ë¯¸ì§€ í’ˆì§ˆ ë¬¸ì œ
- íë¦¿í•¨
- íšŒì „ë¨
- ë„ˆë¬´ ì‘ìŒ

**í•´ê²°**: 
```python
# ocr_module.pyì—ì„œ ì „ì²˜ë¦¬ ê°•í™”
# CLAHE íŒŒë¼ë¯¸í„° ì¡°ì •
clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(16,16))
```

### 2. ë¶„ë¥˜ ì •í™•ë„ ë‚®ìŒ (< 85%)

**ì›ì¸**: í•™ìŠµ ë°ì´í„° ë¶€ì¡± ë˜ëŠ” í’ˆì§ˆ ë¬¸ì œ

**í•´ê²°**:
- Epoch ì¦ê°€: 3 â†’ 5
- learning_rate ê°ì†Œ: 2e-5 â†’ 5e-6
- ë°ì´í„° í™•ì¸: labels.csvì— ì˜¤ë¥˜ ì—†ëŠ”ì§€ ì²´í¬

### 3. ì¶”ì¶œ ê²°ê³¼ê°€ None

**ì›ì¸**: NERì´ ì—”í‹°í‹°ë¥¼ ëª» ì°¾ìŒ

**í•´ê²°**:
- ì •ê·œì‹ íŒ¨í„´ ì¶”ê°€
- _match_field()ì— íœ´ë¦¬ìŠ¤í‹± ì¶”ê°€

---

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

### AI ì´ˆë³´ì
- [DistilBERT ë…¼ë¬¸ ì‰¬ìš´ ì„¤ëª…](https://medium.com/@...)
- [NERì´ë€ ë¬´ì—‡ì¸ê°€](https://en.wikipedia.org/wiki/Named-entity_recognition)

### ì½”ë“œ ê°œì„ í•˜ê³  ì‹¶ë‹¤ë©´
- Hugging Face Transformers ë¬¸ì„œ
- PaddleOCR GitHub

---

**ë‹¤ìŒ ë‹¨ê³„**: [HACKATHON_WORKFLOW.md](./HACKATHON_WORKFLOW.md)ì—ì„œ í•´ì»¤í†¤ ë‹¹ì¼ ì‹¤í–‰ ê°€ì´ë“œ í™•ì¸ â†’

