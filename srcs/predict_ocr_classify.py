import sys
sys.path.append('srcs')

from ocr_vl_module import OCRVLModule
from pathlib import Path
import json
import argparse
from tqdm import tqdm

def prepare_classification_input(ocr_result):
    """
    OCR-VL ê²°ê³¼ë¥¼ ë¶„ë¥˜ ì…ë ¥ìœ¼ë¡œ ë³€í™˜
    ë ˆì´ì•„ì›ƒ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ì— ì¶”ê°€
    """
    text = ocr_result['full_text']
    layout = ocr_result['layout']
    
    layout_info = f"""
[LAYOUT_INFO]
Title: {layout.get('title', 'None')}
Has_Table: {layout['features']['has_table']}
Key_Value_Pairs: {layout['features']['num_key_value_pairs']}
Text_Density: {layout['features']['text_density']:.2f}
Total_Lines: {layout['features']['total_lines']}
[END_LAYOUT_INFO]
"""
    
    # í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ë§Œ + ë ˆì´ì•„ì›ƒ ì •ë³´
    return text[:2000] + "\n\n" + layout_info


def process_single_document(image_path, ocr_vl, classifier=None):
    """
    ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬: OCR-VL + ë¶„ë¥˜(ì„ íƒ)
    """
    # Step 1: OCR-VL
    ocr_result = ocr_vl.process_document(str(image_path))
    
    if 'error' in ocr_result:
        print(f"  âŒ OCR error: {ocr_result['error']}")
        return None
    
    # Step 2: ë¶„ë¥˜ (ëª¨ë¸ì´ ìˆìœ¼ë©´)
    if classifier:
        enhanced_text = prepare_classification_input(ocr_result)
        classification = classifier.classify(enhanced_text)
    else:
        # ë¶„ë¥˜ ëª¨ë¸ ì—†ìœ¼ë©´ None
        classification = {
            "doc_type": "unknown",
            "confidence": 0.0
        }
    
    # Step 3: ìµœì¢… JSON (LLM íŒ€ì—ê²Œ ì „ë‹¬)
    result = {
        "filename": Path(image_path).name,
        "full_text_ocr": ocr_result['full_text'],
        "ocr_confidence": ocr_result['confidence'],
        "layout": ocr_result['layout'],
        "classification": classification,
        "processing_time": ocr_result['processing_time']
    }
    
    return result


def main():
    parser = argparse.ArgumentParser(description='OCR-VL + Classification pipeline')
    parser.add_argument('--input', required=True, help='Input directory')
    parser.add_argument('--classifier', help='Path to trained classifier model (optional)')
    parser.add_argument('--output', required=True, help='Output JSON file')
    parser.add_argument('--gpu', action='store_true', help='Use GPU')
    args = parser.parse_args()
    
    # OCR-VL ì´ˆê¸°í™”
    print("Initializing OCR-VL...")
    ocr_vl = OCRVLModule(use_gpu=args.gpu)
    
    # ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™” (ìˆìœ¼ë©´)
    classifier = None
    if args.classifier:
        print(f"Loading classifier from {args.classifier}...")
        sys.path.append('src_backup')  # classification_module ìœ„ì¹˜
        from classification_module import DocumentClassifier
        classifier = DocumentClassifier()
        classifier.load_model(args.classifier)
        print("Classifier loaded!")
    else:
        print("âš ï¸  No classifier specified. Will skip classification.")
    
    print("Modules ready!\n")
    
    # íŒŒì¼ ìˆ˜ì§‘
    input_dir = Path(args.input)
    files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.pdf']:
        files.extend(input_dir.glob(ext))
    
    print(f"Found {len(files)} files\n")
    
    if not files:
        print("No files found!")
        return
    
    # ë°°ì¹˜ ì²˜ë¦¬
    results = []
    errors = []
    
    for file_path in tqdm(files, desc="Processing"):
        try:
            result = process_single_document(file_path, ocr_vl, classifier)
            
            if result:
                results.append(result)
            else:
                errors.append(file_path.name)
        
        except Exception as e:
            print(f"\nâŒ Error processing {file_path.name}: {e}")
            errors.append(file_path.name)
    
    # ê²°ê³¼ ì €ì¥
    output_path = Path(args.output)
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # í†µê³„
    print("\n" + "="*60)
    print("Processing Complete!")
    print("="*60)
    print(f"Total files: {len(files)}")
    print(f"Successful: {len(results)}")
    print(f"Errors: {len(errors)}")
    
    if results:
        # OCR í†µê³„
        avg_ocr_conf = sum(r['ocr_confidence'] for r in results) / len(results)
        avg_time = sum(r['processing_time'] for r in results) / len(results)
        print(f"\nAverage OCR confidence: {avg_ocr_conf:.2%}")
        print(f"Average processing time: {avg_time:.2f}s")
        
        # ë¶„ë¥˜ í†µê³„ (ë¶„ë¥˜ ëª¨ë¸ì´ ìˆìœ¼ë©´)
        if classifier:
            from collections import Counter
            types = [r['classification']['doc_type'] for r in results]
            print(f"\nDocument types:")
            for dtype, count in Counter(types).items():
                print(f"  {dtype}: {count}")
            
            avg_class_conf = sum(r['classification']['confidence'] for r in results) / len(results)
            print(f"\nAverage classification confidence: {avg_class_conf:.2%}")
    
    print(f"\nâœ“ Results saved to: {output_path}")
    print("\nğŸ’¡ Next step:")
    if classifier:
        print("  â†’ ì´ íŒŒì¼ì„ LLM íŒ€ì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”!")
    else:
        print("  â†’ ë‚˜ì¤‘ì— --classifier ì˜µì…˜ìœ¼ë¡œ ë¶„ë¥˜ ëª¨ë¸ì„ ì¶”ê°€í•˜ì„¸ìš”")
        print("  â†’ ì§€ê¸ˆì€ OCR ê²°ê³¼ë§Œ ì €ì¥ë¨")
    print("="*60)


if __name__ == "__main__":
    main()